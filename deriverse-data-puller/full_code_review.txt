

===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\configs\analytics.yaml =====

# Path to the normalized events generated by mock data
events_path: "data/normalized/events.jsonl"

# Where analytics output should go
output_path: "data/analytics_output"

# Any additional options your analytics scripts might use
compute_drawdowns: true
compute_exposure: true
compute_win_rate: true
compute_fees: true
time_bucket: "daily"


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\configs\ingestion.yaml =====

# ============================
# Ingestion configuration
# ============================

# Path to raw mock protocol events (single file ingestion)
raw_data_path: configs/mock_data.json

# Append-only normalized output (JSONL)
normalized_output_path: data/normalized/events.jsonl

# Watermark / checkpoint store for incremental ingestion
checkpoint_path: data/checkpoints/watermark.json

# Allowed lateness for event-time processing (seconds)
allowed_lateness_seconds: 0

# ============================
# Optional controls (future-safe)
# ============================

markets: []
traders: []
max_events_per_run: null


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\configs\loader.py =====

import yaml
from pathlib import Path

def load_config(filename):
    path = Path(__file__).parent / filename
    with open(path) as f:
        return yaml.safe_load(f)


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\configs\mock_data.json =====

[
  {
    "event_id": "spot_001",
    "product_type": "spot",
    "event_type": "trade",
    "timestamp": 1707216000,
    "market": "SOL/USDC",
    "trader_id": "trader_A",
    "side": "buy",
    "price": 98.5,
    "size": 10,
    "fee": 0.25
  },
  {
    "event_id": "spot_002",
    "product_type": "spot",
    "event_type": "trade",
    "timestamp": 1707216300,
    "market": "SOL/USDC",
    "trader_id": "trader_B",
    "side": "sell",
    "price": 99.2,
    "size": 5,
    "fee": 0.12
  },
  {
    "event_id": "perp_001",
    "product_type": "perp",
    "event_type": "open",
    "timestamp": 1707216600,
    "market": "SOL-PERP",
    "trader_id": "trader_A",
    "side": "long",
    "price": 100.0,
    "size": 20,
    "fee": 0.4,
    "funding_rate": 0.0001
  },
  {
    "event_id": "perp_002",
    "product_type": "perp",
    "event_type": "close",
    "timestamp": 1707217200,
    "market": "SOL-PERP",
    "trader_id": "trader_A",
    "side": "long",
    "price": 103.0,
    "size": 20,
    "fee": 0.4,
    "pnl": 60.0
  },
  {
    "event_id": "option_001",
    "product_type": "option",
    "event_type": "open",
    "timestamp": 1707217800,
    "market": "SOL-OPTION-110-C",
    "trader_id": "trader_C",
    "side": "buy",
    "price": 4.5,
    "size": 5,
    "option_type": "call",
    "strike": 110,
    "expiry": 1709817600,
    "premium": 22.5,
    "fee": 0.15
  },
  {
    "event_id": "option_002",
    "product_type": "option",
    "event_type": "exercise",
    "timestamp": 1709820000,
    "market": "SOL-OPTION-110-C",
    "trader_id": "trader_C",
    "side": "buy",
    "price": 120,
    "size": 5,
    "option_type": "call",
    "strike": 110,
    "expiry": 1709817600,
    "exercise_pnl": 50.0
  }
]


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\configs\mock_data.yaml =====

market:
  name: "DemoMarket"
  tick_size: 0.01

trader:
  name: "DemoTrader"
  max_order_size: 10

storage:
  type: "file"
  path: "mock_events.json"


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\configs\__init__.py =====



===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\dashboards\app.py =====

import streamlit as st
import json

st.title("Deriverse Mock Trading Dashboard")

try:
    with open("mock_events.json", "r") as f:
        events = json.load(f)
except FileNotFoundError:
    st.warning("No mock events found. Run `generate_mock_data.py` first.")
    events = []

if events:
    st.write(f"Total events: {len(events)}")
    st.dataframe(events)


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\dashboards\__init__.py =====



===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\scripts\build_trades_table.py =====

# scripts/build_trades_table.py

import json
import pandas as pd
from src.analytics.etl.trade_normalizer import normalize_trades

RAW_PATH = "data/raw/raw_events.json"
OUT_PATH = "data/processed/trades.csv"

def main():
    with open(RAW_PATH, "r") as f:
        raw_events = json.load(f)

    events_df = pd.DataFrame(raw_events)

    trades_df = normalize_trades(events_df)

    trades_df.to_csv(OUT_PATH, index=False)
    print(f"âœ… {OUT_PATH} created ({len(trades_df)} trades)")

if __name__ == "__main__":
    main()


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\scripts\generate_mock_data.py =====

import random
import uuid
import json
from datetime import datetime, timedelta
from pathlib import Path

OUT = Path("data/raw")
OUT.mkdir(exist_ok=True)

MARKETS = [
    {"market_id": "SOL-PERP", "base": "SOL"},
    {"market_id": "BTC-PERP", "base": "BTC"},
]

TRADERS = [f"trader_{i:03d}" for i in range(1, 21)]

START = datetime(2026, 2, 1)
EVENTS = []

prices = {
    "SOL-PERP": 100.0,
    "BTC-PERP": 42000.0,
}

positions = {}

def ts(i):
    return (START + timedelta(minutes=i)).isoformat() + "Z"

for i in range(500):
    market = random.choice(MARKETS)
    trader = random.choice(TRADERS)
    side = random.choice(["buy", "sell"])

    price_move = random.uniform(-0.5, 0.5)
    prices[market["market_id"]] += price_move

    size = round(random.uniform(0.1, 2.0), 3)
    fee = abs(size * prices[market["market_id"]] * 0.0005)

    trade = {
        "event_type": "trade",
        "ts": ts(i),
        "market_id": market["market_id"],
        "trader_id": trader,
        "side": side,
        "price": round(prices[market["market_id"]], 2),
        "size": size,
        "fee": round(fee, 4),
        "trade_id": str(uuid.uuid4())
    }

    EVENTS.append(trade)

    # occasionally settle pnl
    if i % 20 == 0:
        pnl = random.uniform(-20, 30)
        EVENTS.append({
            "event_type": "settle_pnl",
            "ts": ts(i),
            "market_id": market["market_id"],
            "trader_id": trader,
            "realized_pnl": round(pnl, 2),
            "cumulative_pnl": round(random.uniform(-200, 500), 2)
        })

    # funding
    if i % 50 == 0:
        EVENTS.append({
            "event_type": "funding",
            "ts": ts(i),
            "market_id": market["market_id"],
            "trader_id": trader,
            "funding_rate": 0.0001,
            "payment": round(random.uniform(-5, 5), 2)
        })

    # rare liquidation
    if random.random() < 0.01:
        victim = random.choice(TRADERS)
        EVENTS.append({
            "event_type": "liquidation",
            "ts": ts(i),
            "market_id": market["market_id"],
            "liquidated_trader": victim,
            "liquidator": trader,
            "price": round(prices[market["market_id"]], 2),
            "position_size": round(random.uniform(1, 5), 2),
            "penalty": round(random.uniform(5, 20), 2)
        })

with open(OUT / "raw_events.json", "w") as f:
    json.dump(EVENTS, f, indent=2)

print(f"Generated {len(EVENTS)} protocol events")


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\scripts\launch_dashboard.py =====

# scripts/launch_dashboard.py

import streamlit as st
from dashboards.app import run_app
from src.common.logging import get_logger
from configs.loader import load_config

logger = get_logger(__name__)


def main():
    config = load_config("configs/dashboard.yaml")

    logger.info("Launching analytics dashboard")

    st.set_page_config(
        page_title="Deriverse Trading Analytics",
        layout="wide"
    )

    run_app(config)


if __name__ == "__main__":
    main()


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\scripts\run_analytics.py =====

# scripts/run_analytics.py

from src.analytics.trades import build_trades
from src.analytics.pnl import build_pnl
from src.analytics.win_rate import build_win_rate
from src.analytics.drawdown import build_drawdowns
from src.analytics.exposure import build_exposure
from src.analytics.fees import build_fees
from src.analytics.time_based import build_time_metrics
from src.common.logging import get_logger
from configs.loader import load_config

logger = get_logger(__name__)


def main():
    config = load_config("analytics.yaml")

    logger.info("Starting analytics computation")

    build_trades(config)
    build_pnl(config)
    build_win_rate(config)
    build_drawdowns(config)
    build_exposure(config)
    build_fees(config)
    build_time_metrics(config)

    logger.info("Analytics tables successfully built")


if __name__ == "__main__":
    main()
import json
from pathlib import Path

from src.analytics.pnl import compute_pnl
from src.analytics.win_rate import compute_win_rate
from src.analytics.drawdown import compute_max_drawdown
from src.analytics.fees import compute_total_fees


RAW_DIR = Path("data/raw_events")
OUT_DIR = Path("data/analytics")
OUT_DIR.mkdir(parents=True, exist_ok=True)


def load_events():
    events = []
    for f in RAW_DIR.glob("*.jsonl"):
        with open(f) as fh:
            for line in fh:
                events.append(json.loads(line))
    return events


def run():
    events = load_events()

    settles = [e for e in events if e["type"] == "SettlePnlRecord"]

    pnl_series = [s["pnl"] for s in settles]

    metrics = {
        "total_pnl": compute_pnl(settles),
        "win_rate": compute_win_rate(settles),
        "max_drawdown": compute_max_drawdown(pnl_series),
        "total_fees": compute_total_fees(events),
    }

    with open(OUT_DIR / "summary.json", "w") as f:
        json.dump(metrics, f, indent=2)


if __name__ == "__main__":
    run()


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\scripts\run_ingestion.py =====

# scripts/run_ingestion.py
from configs.loader import load_config
from src.ingestion.pipelines import IngestionPipeline
from src.common.logging import get_logger

log = get_logger(__name__)

def main():
    log.info("Starting incremental ingestion")

    config = load_config("ingestion.yaml")

    pipeline = IngestionPipeline(
        raw_path=config["raw_data_path"],
        output_path=config["normalized_output_path"],
        checkpoint_path=config["checkpoint_path"],
    )

    count = pipeline.run()
    log.info(f"Ingested {count} new events")

if __name__ == "__main__":
    main()


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\analytics\etl\trade_normalizer.py =====

import pandas as pd

def normalize_trades(events_df: pd.DataFrame) -> pd.DataFrame:
    trades = events_df[events_df["event_type"] == "trade"].copy()

    trades["trade_date"] = pd.to_datetime(trades["ts"]).dt.date

    trades["entry_price"] = trades["price"]
    trades["exit_price"] = trades["price"]  # placeholder
    trades["fees"] = trades["fee"].fillna(0)

    def infer_product(market_id: str) -> str:
        m = market_id.lower()
        if "perp" in m:
            return "perp"
        if "option" in m:
            return "option"
        return "spot"

    trades["product_type"] = trades["market_id"].apply(infer_product)

    return trades[
        [
            "trade_date",
            "trader_id",
            "product_type",
            "entry_price",
            "exit_price",
            "size",
            "side",
            "fees"
        ]
    ]


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\analytics\metrics\activity.py =====

from collections import defaultdict
import json

def activity_by_product(events_path: str):
    stats = defaultdict(lambda: {
        "trades": 0,
        "volume": 0.0,
        "fees": 0.0
    })

    with open(events_path) as f:
        for line in f:
            e = json.loads(line)
            p = e["product_type"]

            stats[p]["trades"] += 1
            stats[p]["volume"] += abs(e["price"] * e["size"])
            stats[p]["fees"] += e.get("fee", 0.0)

    return stats


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\analytics\metrics\options_pnl.py =====

from collections import defaultdict
import json

def options_trader_pnl(events_path: str):
    pnl = defaultdict(float)

    with open(events_path) as f:
        for line in f:
            e = json.loads(line)

            if e["product_type"] != "option":
                continue

            trader = e["trader_id"]

            pnl[trader] -= e.get("premium", 0.0)
            pnl[trader] += e.get("exercise_pnl", 0.0)

    return pnl


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\analytics\pnl\drawdown.py =====

import pandas as pd


def compute_drawdown(cumulative_pnl: pd.Series) -> pd.Series:
    """
    Compute drawdown from cumulative PnL.
    """
    rolling_max = cumulative_pnl.cummax()
    drawdown = cumulative_pnl - rolling_max
    return drawdown


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\analytics\pnl\pnl_calculator.py =====

def calculate_trade_pnl(row):
    if row["product_type"] == "option":
        return row["exercise_pnl"] - row["premium"] - row["fees"]

    direction = 1 if row["side"].lower() == "long" else -1
    gross_pnl = (row["exit_price"] - row["entry_price"]) * row["size"] * direction
    return gross_pnl - row["fees"]


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\analytics\pnl\pnl_timeseries.py =====

import pandas as pd
from .pnl_calculator import calculate_trade_pnl


def build_pnl_timeseries(trades_df: pd.DataFrame) -> pd.DataFrame:
    """
    Build daily and cumulative PnL series.
    """
    trades_df["pnl"] = trades_df.apply(calculate_trade_pnl, axis=1)

    daily_pnl = (
        trades_df
        .groupby("trade_date", as_index=False)["pnl"]
        .sum()
        .sort_values("trade_date")
    )

    daily_pnl["cumulative_pnl"] = daily_pnl["pnl"].cumsum()
    return daily_pnl


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\analytics\pnl\__init__.py =====



===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\analytics\reports\pnl_overview.py =====

import os
import json
import pandas as pd
import matplotlib.pyplot as plt

from src.analytics.pnl.pnl_timeseries import build_pnl_timeseries
from src.analytics.pnl.drawdown import compute_drawdown


DATA_PATH = "data/processed/trades.csv"
REPORT_DIR = "data/reports"


def main():
    os.makedirs(REPORT_DIR, exist_ok=True)

    # Load trades
    trades_df = pd.read_csv(DATA_PATH, parse_dates=["trade_date"])

    # Build PnL series
    pnl_df = build_pnl_timeseries(trades_df)
    pnl_df["drawdown"] = compute_drawdown(pnl_df["cumulative_pnl"])

    # Save outputs
    pnl_df.to_csv(f"{REPORT_DIR}/pnl_timeseries.csv", index=False)
    pnl_df.to_json(f"{REPORT_DIR}/pnl_timeseries.json", orient="records")

    summary = {
        "total_pnl": round(pnl_df["pnl"].sum(), 2),
        "max_drawdown": round(pnl_df["drawdown"].min(), 2),
        "trading_days": int(pnl_df.shape[0])
    }

    with open(f"{REPORT_DIR}/pnl_summary.json", "w") as f:
        json.dump(summary, f, indent=2)

    # Plot (saved, no blocking)
    plt.figure(figsize=(10, 5))
    plt.plot(pnl_df["trade_date"], pnl_df["cumulative_pnl"], label="Cumulative PnL")
    plt.fill_between(
        pnl_df["trade_date"],
        pnl_df["drawdown"],
        0,
        alpha=0.3,
        label="Drawdown"
    )
    plt.title("Protocol PnL Performance")
    plt.xlabel("Date")
    plt.ylabel("PnL")
    plt.legend()
    plt.tight_layout()
    plt.savefig(f"{REPORT_DIR}/pnl_curve.png")
    plt.close()

    print("âœ… PnL analytics generated successfully")
    print(summary)


if __name__ == "__main__":
    main()


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\analytics\reports\protocol_overview.py =====

import pandas as pd
import matplotlib.pyplot as plt
import os
import json
import numpy as np

# ---------------------------
# Paths
# ---------------------------
RAW_EVENTS_PATH = "configs/mock_data.json"
REPORT_CSV_PATH = "data/reports/protocol_overview.csv"
REPORT_JSON_PATH = "data/reports/protocol_overview.json"

os.makedirs("data/reports", exist_ok=True)

# ---------------------------
# Load events
# ---------------------------
with open(RAW_EVENTS_PATH, "r") as f:
    events = json.load(f)

df = pd.DataFrame(events)

# ---------------------------
# Calculate volume correctly per product type
# ---------------------------
# Volume definition:
# - Option: premium
# - Spot/Perp: price * size
df["volume"] = np.where(
    df["product_type"] == "option",
    df["premium"].fillna(0),
    (df["price"].fillna(0) * df["size"].fillna(0))
)

# ---------------------------
# Summary statistics
# ---------------------------
summary = (
    df.groupby("product_type")
      .agg(
          volume=("volume", "sum"),
          unique_traders=("trader_id", "nunique")
      )
      .reset_index()
)

# Add volume share percentage to summary
summary["volume_share_pct"] = (
    summary["volume"] / summary["volume"].sum() * 100
).round(2)

# ---------------------------
# Save report
# ---------------------------
summary.to_csv(REPORT_CSV_PATH, index=False)
summary.to_json(REPORT_JSON_PATH, orient='records', indent=4)

print("âœ… Protocol overview saved to:")
print(f"- {REPORT_CSV_PATH}")
print(f"- {REPORT_JSON_PATH}")
print("\nðŸ“Š Summary:")
print(summary.to_string(index=False))

# ---------------------------
# Plot volume per product type
# ---------------------------
plt.figure(figsize=(8, 5))
colors = ['#1f77b4', '#ff7f0e', '#2ca02c']  # Spot, Perp, Option
plt.bar(summary['product_type'], summary['volume'], color=colors[:len(summary)])
plt.title("Trading Volume by Product Type")
plt.xlabel("Product Type")
plt.ylabel("Volume")
plt.tight_layout()
plt.savefig("data/reports/volume_by_product.png", dpi=150)
plt.close()  # Close to prevent blocking

# ---------------------------
# Plot unique traders per product type
# ---------------------------
plt.figure(figsize=(8, 5))
plt.bar(summary['product_type'], summary['unique_traders'], color=colors[:len(summary)])
plt.title("Unique Traders by Product Type")
plt.xlabel("Product Type")
plt.ylabel("Number of Unique Traders")
plt.tight_layout()
plt.savefig("data/reports/traders_by_product.png", dpi=150)
plt.close()  

print("\nðŸ“Š Charts saved to:")
print("- data/reports/volume_by_product.png")
print("- data/reports/traders_by_product.png")


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\analytics\contract.py =====

PRODUCT_TYPES = {"spot", "perp", "option"}

REQUIRED_FIELDS = {
    "event_id": str,
    "product_type": str,    # spot | perp | option
    "event_type": str,      # trade, open, close, exercise, expiry
    "timestamp": int,

    "market": str,
    "trader_id": str,

    "side": str,            # buy/sell OR long/short
    "price": float,
    "size": float,
}

OPTIONAL_FIELDS = {
    # common
    "fee": float,

    # perp-specific
    "pnl": float,
    "funding_rate": float,

    # option-specific
    "option_type": str,     # call / put
    "strike": float,
    "expiry": int,
    "premium": float,
    "exercise_pnl": float,
}


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\analytics\debug.py =====

import pandas as pd

df = pd.read_json("data/normalized/events.jsonl", lines=True)
print(df.columns)
print(df.head(5))


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\analytics\drawdown.py =====

from collections import defaultdict

def build_drawdowns(pnl_records: list[dict]) -> dict:
    """
    Compute max drawdown per trader from a list of pnl records.
    """
    equity = defaultdict(float)
    peak = defaultdict(float)
    drawdown = defaultdict(float)

    for r in pnl_records:
        trader = r["trader"]
        equity[trader] += r["pnl"]

        if equity[trader] > peak[trader]:
            peak[trader] = equity[trader]

        dd = peak[trader] - equity[trader]
        drawdown[trader] = max(drawdown[trader], dd)

    return dict(drawdown)


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\analytics\exposure.py =====

import json
from pathlib import Path
from collections import defaultdict

EVENTS = Path("data/normalized/events.jsonl")

def build_exposure():
    """
    Compute long vs short exposure per market.
    """
    exposure = defaultdict(lambda: {"long": 0, "short": 0})

    for line in EVENTS.read_text().splitlines():
        e = json.loads(line)
        if e["event_type"] == "trade":
            side = "long" if e["side"] == "buy" else "short"
            exposure[e["market_id"]][side] += e["size"]

    return dict(exposure)


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\analytics\fees.py =====

from typing import List, Dict
from collections import defaultdict

def build_fees(trades: List[Dict], fee_rate=0.0005):
    trader_fees = defaultdict(float)
    market_fees = defaultdict(float)

    for t in trades:
        fee = abs(t["price"] * t["size"]) * fee_rate
        trader_fees[t["trader"]] += fee
        market_fees[t["market"]] += fee

    return dict(trader_fees), dict(market_fees)


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\analytics\pnl.py =====

from typing import List, Dict

def build_pnl(trades: List[Dict]) -> List[Dict]:
    pnl = []

    for t in trades:
        direction = 1 if t["side"] == "buy" else -1

        pnl.append({
            "trade_id": t["trade_id"],
            "trader": t["trader"],
            "market": t["market"],
            "timestamp": t["timestamp"],
            "pnl": direction * t["price"] * t["size"] * 0.001
        })

    return pnl


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\analytics\time_based.py =====

from collections import defaultdict
from typing import List, Dict

def build_time_metrics(pnls: List[Dict]) -> Dict:
    out = defaultdict(float)

    for p in pnls:
        day = p["timestamp"][:10]  # YYYY-MM-DD
        out[day] += p["pnl"]

    return dict(out)


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\analytics\trades.py =====

from typing import List, Dict

def build_trades(events: List[Dict]) -> List[Dict]:
    """
    Convert raw protocol events into normalized trade records.
    """
    trades = []

    for e in events:
        if e["event_type"] != "trade":
            continue

        trades.append({
            "trade_id": e["event_id"],
            "timestamp": e["timestamp"],
            "trader": e["trader"],
            "market": e["market"],
            "side": e["side"],
            "price": e["price"],
            "size": e["size"],
        })

    return trades


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\analytics\win_rate.py =====

from typing import List, Dict
from collections import defaultdict

def build_win_rate(pnls: List[Dict]) -> Dict[str, float]:
    wins = defaultdict(int)
    total = defaultdict(int)

    for p in pnls:
        trader = p["trader"]
        total[trader] += 1
        if p["pnl"] > 0:
            wins[trader] += 1

    return {
        t: wins[t] / total[t] if total[t] else 0
        for t in total
    }


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\analytics\__init__.py =====



===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\common\logging.py =====

import logging

def get_logger(name):
    logger = logging.getLogger(name)
    if not logger.handlers:
        handler = logging.StreamHandler()
        formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        logger.setLevel(logging.INFO)
    return logger


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\common\__init__.py =====



===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\ingestion\pipelines.py =====

# src/ingestion/pipelines.py
import json
import hashlib
from pathlib import Path
from typing import List, Dict
from src.ingestion.watermark import WatermarkStore

class IngestionPipeline:
    def __init__(self, raw_path, output_path, checkpoint_path):
        self.raw_path = Path(raw_path)
        self.output_path = Path(output_path)
        self.watermark = WatermarkStore(checkpoint_path)

    def run(self) -> int:
        events = json.loads(self.raw_path.read_text())

        new_events = []
        
        for idx, e in enumerate(events):
            # Derive a stable event_id if missing
            event_id = e.get("event_id")

            if event_id is None:
                raw = f"{e.get('event_type')}|{e.get('timestamp')}|{e.get('trader')}|{e.get('market')}|{idx}"
                event_id = hashlib.sha256(raw.encode()).hexdigest()
                e["event_id"] = event_id

            if self.watermark.is_new(event_id):
                new_events.append(e)
                self.watermark.mark(event_id)

        self.output_path.parent.mkdir(parents=True, exist_ok=True)
        with self.output_path.open("a") as f:
            for e in new_events:
                f.write(json.dumps(e) + "\n")

        return len(new_events)


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\ingestion\watermark.py =====

# src/ingestion/watermark.py
import json
from pathlib import Path
from typing import Set

class WatermarkStore:
    """
    Persistent watermark store to prevent reprocessing events.
    """

    def __init__(self, path: str):
        self.path = Path(path)
        self.seen: Set[str] = set()
        self._load()

    def _load(self):
        if self.path.exists():
            with open(self.path, "r") as f:
                self.seen = set(json.load(f))

    def _save(self):
        self.path.parent.mkdir(parents=True, exist_ok=True)
        with open(self.path, "w") as f:
            json.dump(list(self.seen), f)

    def is_new(self, event_id: str) -> bool:
        return event_id not in self.seen

    def mark(self, event_id: str):
        self.seen.add(event_id)
        self._save()


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\ingestion\__init__.py =====



===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\mock\market_simulator.py =====

import random

class MarketSimulator:
    def __init__(self, name: str, tick_size: float):
        self.name = name
        self.tick_size = tick_size
        self.price = 100.0  # starting price

    def step(self):
        """Simulate a single market tick"""
        move = random.choice([-1, 1]) * self.tick_size
        self.price += move
        return round(self.price, 2)


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\mock\trader_simulator.py =====

class TraderSimulator:
    def __init__(self, config):
        self.config = config

    def simulate_trade(self, market_data):
        # Example: random trade based on market price
        import random
        trade = {
            "price": market_data["price"],
            "side": random.choice(["buy", "sell"]),
            "quantity": round(random.uniform(1, 10), 2),
            "timestamp": market_data["timestamp"]
        }
        return trade


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\mock\__init__.py =====



===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\storage\writer.py =====

class EventWriter:
    def __init__(self, config):
        self.config = config

    def write(self, events):
        # Example: write to a local JSON file
        import json
        with open("mock_events.json", "w") as f:
            json.dump(events, f, indent=2)


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\storage\__init__.py =====



===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\__init__.py =====



===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\main.py =====

def main():
    print("Hello from deriverse-data-puller!")


if __name__ == "__main__":
    main()


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\pyproject.toml =====

[project]
name = "deriverse-data-puller"
version = "0.1.0"
description = "Mock on-chain trading analytics system for Deriverse"
readme = "README.md"
requires-python = ">=3.10"

dependencies = [
    "matplotlib>=3.10.8",
    "pandas>=2.3.3",
    "pyyaml",
    "requests>=2.32.5",
    "streamlit",
]



===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\README.md =====

