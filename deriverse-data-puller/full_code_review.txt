

===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\.vscode\settings.json =====

{
    "python.defaultInterpreterPath": "${workspaceFolder}/.venv/Scripts/python.exe",
    "python.analysis.extraPaths": ["./"],
    "python.autoComplete.extraPaths": [
        "${workspaceFolder}/.venv/Lib/site-packages"
    ]
}


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\configs\analytics.yaml =====

# Path to the normalized events generated by mock data
events_path: "data/normalized/events.jsonl"

# Where analytics output should go
output_path: "data/analytics_output"

# Any additional options your analytics scripts might use
compute_drawdowns: true
compute_exposure: true
compute_win_rate: true
compute_fees: true
time_bucket: "daily"


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\configs\ingestion.yaml =====

raw_data_path: configs/mock_data.json
normalized_output_path: data/normalized/events.jsonl
checkpoint_path: data/checkpoints/watermark.json
allowed_lateness_seconds: 0


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\configs\loader.py =====

import yaml
from pathlib import Path

def load_config(filename):
    path = Path(__file__).parent / filename
    with open(path) as f:
        return yaml.safe_load(f)


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\configs\mock_data.json =====

[
  {
    "event_id": "f404de6d-ed5e-4bdb-8661-5be3e38ae9bb",
    "event_type": "close",
    "timestamp": "2026-02-07T18:59:28.583826+00:00",
    "trader_id": "trader_B",
    "market_id": "SOL-PERP",
    "product_type": "perp",
    "fee": 0.34,
    "side": "long",
    "price": 12903.37,
    "size": 14,
    "pnl": -49.38
  },
  {
    "event_id": "c4a2a6d4-54d0-48ab-8429-cdd345a28185",
    "event_type": "open",
    "timestamp": "2026-02-07T19:04:28.583826+00:00",
    "trader_id": "trader_C",
    "market_id": "SOL-OPT",
    "product_type": "option",
    "fee": 0.75,
    "side": "long",
    "price": 19297.04,
    "size": 8,
    "pnl": null
  },
  {
    "event_id": "2153b0af-702b-4994-82db-39731f76ee02",
    "event_type": "close",
    "timestamp": "2026-02-07T19:09:28.583826+00:00",
    "trader_id": "trader_A",
    "market_id": "SOL/USDC",
    "product_type": "spot",
    "fee": 0.16,
    "side": "long",
    "price": 25390.79,
    "size": 4,
    "pnl": 6.36
  },
  {
    "event_id": "2acbf947-d0bd-4599-b09f-89fc8f1fd007",
    "event_type": "open",
    "timestamp": "2026-02-07T19:14:28.583826+00:00",
    "trader_id": "trader_D",
    "market_id": "BTC-PERP",
    "product_type": "perp",
    "fee": 0.94,
    "side": "short",
    "price": 21115.43,
    "size": 19,
    "pnl": null
  },
  {
    "event_id": "b05f7188-3c38-4ff4-9e75-49bdb65979bd",
    "event_type": "open",
    "timestamp": "2026-02-07T19:19:28.583826+00:00",
    "trader_id": "trader_A",
    "market_id": "SOL/USDC",
    "product_type": "spot",
    "fee": 0.24,
    "side": "long",
    "price": 18632.27,
    "size": 1,
    "pnl": null
  },
  {
    "event_id": "d491fcd9-1882-4128-99b3-124f1bd528e3",
    "event_type": "open",
    "timestamp": "2026-02-07T19:24:28.583826+00:00",
    "trader_id": "trader_A",
    "market_id": "SOL/USDC",
    "product_type": "spot",
    "fee": 0.76,
    "side": "long",
    "price": 19553.83,
    "size": 8,
    "pnl": null
  },
  {
    "event_id": "9055b96a-8ad9-4ff3-a4bd-937148eff16d",
    "event_type": "trade",
    "timestamp": "2026-02-07T19:29:28.583826+00:00",
    "trader_id": "trader_A",
    "market_id": "BTC-PERP",
    "product_type": "perp",
    "fee": 0.2,
    "side": "sell",
    "price": 11080.09,
    "size": 5
  },
  {
    "event_id": "7238e8e7-8330-4cfd-905d-64f9d3a8c44d",
    "event_type": "trade",
    "timestamp": "2026-02-07T19:34:28.583826+00:00",
    "trader_id": "trader_A",
    "market_id": "SOL-OPT",
    "product_type": "option",
    "fee": 0.62,
    "side": "buy",
    "price": 1825.89,
    "size": 6
  },
  {
    "event_id": "4efa4e37-d71f-4029-8a53-9e998a385ff6",
    "event_type": "open",
    "timestamp": "2026-02-07T19:39:28.583826+00:00",
    "trader_id": "trader_A",
    "market_id": "SOL-OPT",
    "product_type": "option",
    "fee": 0.39,
    "side": "short",
    "price": 2152.75,
    "size": 11,
    "pnl": null
  },
  {
    "event_id": "c5f6859e-2a1b-4ca7-ac26-a6a8d7bba5fa",
    "event_type": "open",
    "timestamp": "2026-02-07T19:44:28.583826+00:00",
    "trader_id": "trader_C",
    "market_id": "BTC-PERP",
    "product_type": "perp",
    "fee": 0.4,
    "side": "long",
    "price": 19822.82,
    "size": 18,
    "pnl": null
  },
  {
    "event_id": "2f404d6f-b2fd-4946-9093-7445cf161449",
    "event_type": "open",
    "timestamp": "2026-02-07T19:49:28.583826+00:00",
    "trader_id": "trader_A",
    "market_id": "SOL-PERP",
    "product_type": "perp",
    "fee": 0.47,
    "side": "long",
    "price": 4122.88,
    "size": 3,
    "pnl": null
  },
  {
    "event_id": "5ac12a4b-7893-42e6-938a-e4bb16c99ca8",
    "event_type": "close",
    "timestamp": "2026-02-07T19:54:28.583826+00:00",
    "trader_id": "trader_B",
    "market_id": "SOL/USDC",
    "product_type": "spot",
    "fee": 0.12,
    "side": "long",
    "price": 9722.55,
    "size": 11,
    "pnl": 174.42
  }
]


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\configs\mock_data.yaml =====

market:
  name: "DemoMarket"
  tick_size: 0.01

trader:
  name: "DemoTrader"
  max_order_size: 10

storage:
  type: "file"
  path: "mock_events.json"


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\configs\__init__.py =====



===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\dashboards\app.py =====

import streamlit as st
import pandas as pd
from pathlib import Path

DATA = Path("data/analytics_output")

st.set_page_config(layout="wide")
st.title("Deriverse Trading Analytics")

equity = pd.read_csv(DATA / "equity_curve.csv", parse_dates=["timestamp"])
win_rate = pd.read_csv(DATA / "win_rate.csv")
fees = pd.read_csv(DATA / "fees.csv")

trader = st.selectbox("Select trader", equity["trader_id"].unique())

col1, col2, col3 = st.columns(3)

with col1:
    st.metric(
        "Total PnL",
        f"{equity[equity.trader_id == trader].cumulative_pnl.iloc[-1]:.2f}"
    )

with col2:
    st.metric(
        "Win Rate",
        f"{win_rate[win_rate.trader_id == trader].win_rate.iloc[0]*100:.1f}%"
    )

with col3:
    st.metric(
        "Total Fees",
        f"{fees[fees.trader_id == trader].total_fees.iloc[0]:.2f}"
    )

st.subheader("Equity Curve")
st.line_chart(
    equity[equity.trader_id == trader]
    .set_index("timestamp")["cumulative_pnl"]
)


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\dashboards\__init__.py =====



===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\scripts\build_trades_table.py =====

# scripts/build_trades_table.py

import json
import pandas as pd
from src.analytics.etl.trade_normalizer import normalize_trades

RAW_PATH = "data/raw/raw_events.json"
OUT_PATH = "data/processed/trades.csv"

def main():
    with open(RAW_PATH, "r") as f:
        raw_events = json.load(f)

    events_df = pd.DataFrame(raw_events)

    trades_df = normalize_trades(events_df)

    trades_df.to_csv(OUT_PATH, index=False)
    print(f"âœ… {OUT_PATH} created ({len(trades_df)} trades)")

if __name__ == "__main__":
    main()


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\scripts\generate_mock_data.py =====

# scripts/generate_mock_data.py
from datetime import datetime, timedelta, timezone
import random
import uuid
import json
from pathlib import Path

MOCK_PATH = Path("configs/mock_data.json")

def iso_ts(dt):
    return dt.replace(tzinfo=timezone.utc).isoformat()

def generate_mock_events(n=12, start_time=None):
    """
    Generate mock events for testing.
    Event types: open, trade, close ONLY (no exercise/option_exercise).
    Product types: spot, perp, option (all allowed).
    """
    if start_time is None:
        start_time = datetime.now(timezone.utc)
        
    events = []
    # âœ… Keep all markets including SOL-OPT
    markets = ["SOL/USDC", "SOL-PERP", "BTC-PERP", "SOL-OPT"]
    product_map = {
        "SOL/USDC": "spot",
        "SOL-PERP": "perp",
        "BTC-PERP": "perp",
        "SOL-OPT": "option",  # âœ… Keep option product type
    }
    
    for i in range(n):
        market = random.choice(markets)
        product_type = product_map[market]
        
        # âœ… ONLY GENERATE: open, trade, close (removed exercise/option_exercise)
        event_type = random.choice(["trade", "open", "close"])
        
        base = {
            "event_id": str(uuid.uuid4()),
            "event_type": event_type,
            "timestamp": iso_ts(start_time + timedelta(minutes=5 * i)),
            "trader_id": f"trader_{random.choice(['A','B','C','D'])}",
            "market_id": market,
            "product_type": product_type,
            "fee": round(random.uniform(0.05, 1.0), 2),
        }
        
        if event_type == "trade":
            base.update({
                "side": random.choice(["buy", "sell"]),
                "price": round(random.uniform(90, 26000), 2),
                "size": random.randint(1, 20),
            })
        elif event_type in ["open", "close"]:
            base.update({
                "side": random.choice(["long", "short"]),
                "price": round(random.uniform(90, 26000), 2),
                "size": random.randint(1, 20),
                "pnl": round(random.uniform(-50, 200), 2) if event_type == "close" else None,
            })
        
        events.append(base)
    
    return events

def write_mock_data(n=12):
    """Generate and write mock events to configs/mock_data.json"""
    events = generate_mock_events(n=n)
    MOCK_PATH.parent.mkdir(exist_ok=True)
    with open(MOCK_PATH, "w") as f:
        json.dump(events, f, indent=2)
    return len(events)

if __name__ == "__main__":
    count = write_mock_data()
    print(f"âœ… Generated {count} mock events (open, trade, close only)")


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\scripts\launch_dashboard.py =====

# scripts/launch_dashboard.py

import streamlit as st
from dashboards.app import run_app
from src.common.logging import get_logger
from configs.loader import load_config

logger = get_logger(__name__)


def main():
    config = load_config("configs/dashboard.yaml")

    logger.info("Launching analytics dashboard")

    st.set_page_config(
        page_title="Deriverse Trading Analytics",
        layout="wide"
    )

    run_app(config)


if __name__ == "__main__":
    main()


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\scripts\run_analytics.py =====

# scripts/run_analytics.py

from pathlib import Path
import pandas as pd

from configs.loader import load_config
from src.analytics.pnl.realised_pnl import build_realised_pnl
from src.analytics.pnl.funding import build_funding
from src.analytics.pnl.equity_curve import build_equity_curve
from src.analytics.trades.activity import build_trade_activity
from src.analytics.metrics.win_rate import build_win_rate
from src.analytics.metrics.drawdown import build_drawdowns
from src.analytics.metrics.exposure import build_exposure
from src.analytics.metrics.fees import build_fees

def main():
    config = load_config("analytics.yaml")

    events_path = config["events_path"]
    out = Path(config["output_path"])
    out.mkdir(parents=True, exist_ok=True)

    # -----------------------------
    # Trade activity (diagnostic)
    # -----------------------------
    trades = build_trade_activity(events_path)
    trades.to_csv(out / "trade_activity.csv", index=False)

    # -----------------------------
    # Protocol-truth realised PnL
    # -----------------------------
    realised = build_realised_pnl(events_path)
    realised.to_csv(out / "realised_pnl.csv", index=False)

    # -----------------------------
    # Funding
    # -----------------------------
    funding = build_funding(events_path)
    funding.to_csv(out / "funding.csv", index=False)

    # -----------------------------
    # Equity curve
    # -----------------------------
    equity = build_equity_curve(realised, funding)
    equity.to_csv(out / "equity_curve.csv", index=False)

    # -----------------------------
    # Risk & performance metrics
    # -----------------------------
    win_rate = build_win_rate(realised)
    win_rate.to_csv(out / "win_rate.csv", index=False)

    drawdowns = build_drawdowns(equity)
    drawdowns.to_csv(out / "drawdowns.csv", index=False)

    exposure = build_exposure(events_path)
    pd.DataFrame.from_dict(exposure, orient="index").to_csv(
        out / "exposure.csv"
    )

    fees = build_fees(trades)
    fees.to_csv(out / "fees.csv", index=False)

    print("âœ… Analytics pipeline completed successfully")

if __name__ == "__main__":
    main()


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\scripts\run_ingestion.py =====


# scripts/run_ingestion.py
import logging
from src.ingestion.pipelines import IngestionPipeline
from configs.loader import load_config

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def main():
    logger.info("Starting incremental ingestion")

    config = load_config("ingestion.yaml")

    pipeline = IngestionPipeline(
        raw_path=config["raw_data_path"],
        output_path=config["normalized_output_path"],
        checkpoint_path=config["checkpoint_path"],
    )

    count = pipeline.run()
    logger.info(f"Ingested {count} new events")


if __name__ == "__main__":
    main()


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\etl\trade_normalizer.py =====

import pandas as pd

def normalize_trades(events_df: pd.DataFrame) -> pd.DataFrame:
    trades = events_df[events_df["event_type"] == "trade"].copy()

    trades["trade_date"] = pd.to_datetime(trades["ts"]).dt.date

    trades["entry_price"] = trades["price"]
    trades["exit_price"] = trades["price"]  # placeholder
    trades["fees"] = trades["fee"].fillna(0)

    def infer_product(market_id: str) -> str:
        m = market_id.lower()
        if "perp" in m:
            return "perp"
        if "option" in m:
            return "option"
        return "spot"

    trades["product_type"] = trades["market_id"].apply(infer_product)

    return trades[
        [
            "trade_date",
            "trader_id",
            "product_type",
            "entry_price",
            "exit_price",
            "size",
            "side",
            "fees"
        ]
    ]


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\metrics\activity.py =====

from collections import defaultdict
import json

def activity_by_product(events_path: str):
    stats = defaultdict(lambda: {
        "trades": 0,
        "volume": 0.0,
        "fees": 0.0
    })

    with open(events_path) as f:
        for line in f:
            e = json.loads(line)
            p = e["product_type"]

            stats[p]["trades"] += 1
            stats[p]["volume"] += abs(e["price"] * e["size"])
            stats[p]["fees"] += e.get("fee", 0.0)

    return stats


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\metrics\drawdown.py =====

import pandas as pd

def build_drawdowns(equity_df: pd.DataFrame) -> pd.DataFrame:
    out = []

    for trader, df in equity_df.groupby("trader_id"):
        df = df.sort_values("timestamp")
        peak = df["cumulative_pnl"].cummax()
        drawdown = df["cumulative_pnl"] - peak

        out.append({
            "trader_id": trader,
            "max_drawdown": drawdown.min()
        })

    return pd.DataFrame(out)


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\metrics\exposure.py =====

import json
from collections import defaultdict

def build_exposure(events_path: str):
    exposure = defaultdict(lambda: {"long": 0.0, "short": 0.0})

    with open(events_path) as f:
        for line in f:
            e = json.loads(line)
            if e["event_type"] != "trade":
                continue

            side = "long" if e["side"] in ("buy", "long") else "short"
            exposure[e["market"]][side] += abs(e["size"])

    return dict(exposure)


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\metrics\fees.py =====

def build_fees(trades_df):
    return (
        trades_df
        .groupby("trader_id")["fee"]
        .sum()
        .reset_index(name="total_fees")
    )


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\metrics\options_pnl.py =====

from collections import defaultdict
import json

def options_trader_pnl(events_path: str):
    pnl = defaultdict(float)

    with open(events_path) as f:
        for line in f:
            e = json.loads(line)

            if e["product_type"] != "option":
                continue

            trader = e["trader_id"]

            pnl[trader] -= e.get("premium", 0.0)
            pnl[trader] += e.get("exercise_pnl", 0.0)

    return pnl


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\metrics\win_rate.py =====

from typing import List, Dict
from collections import defaultdict

def build_win_rate(realised_df):
    return (
        realised_df
        .assign(win=lambda x: x["realised_pnl"] > 0)
        .groupby("trader_id")["win"]
        .mean()
        .reset_index(name="win_rate")
    )


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\metrics\__init__.py =====



===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\pnl\equity_curve.py =====

def build_equity_curve(realised_df, funding_df):
    df = realised_df.copy()
    df["funding_payment"] = 0.0

    if not funding_df.empty:
        funding_agg = (
            funding_df
            .groupby(["timestamp", "trader_id"])["funding_payment"]
            .sum()
            .reset_index()
        )
        df = df.merge(
            funding_agg,
            on=["timestamp", "trader_id"],
            how="left",
            suffixes=("", "_fund")
        )
        df["funding_payment"] = df["funding_payment_fund"].fillna(0)
        df.drop(columns=["funding_payment_fund"], inplace=True)

    df["net_realised_pnl"] = df["realised_pnl"] + df["funding_payment"]
    df["cumulative_pnl"] = df.groupby("trader_id")["net_realised_pnl"].cumsum()
    return df


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\pnl\funding.py =====

import pandas as pd
import numpy as np
import json

def build_funding(events_path: str) -> pd.DataFrame:
    rows = []

    with open(events_path) as f:
        for line in f:
            e = json.loads(line)
            if e["event_type"] != "funding":
                continue

            rows.append({
                "timestamp": e["ts"],
                "trader_id": e["trader_id"],
                "market": e["market"],
                "funding_payment": e["funding_payment"],
            })

    return pd.DataFrame(rows)


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\pnl\pnl_calculator.py =====

def calculate_trade_pnl(row):
    if row["product_type"] == "option":
        return row["exercise_pnl"] - row["premium"] - row["fees"]

    direction = 1 if row["side"].lower() == "long" else -1
    gross_pnl = (row["exit_price"] - row["entry_price"]) * row["size"] * direction
    return gross_pnl - row["fees"]


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\pnl\pnl_timeseries.py =====

import pandas as pd
from .pnl_calculator import calculate_trade_pnl


def build_pnl_timeseries(trades_df: pd.DataFrame) -> pd.DataFrame:
    """
    Build daily and cumulative PnL series.
    """
    trades_df["pnl"] = trades_df.apply(calculate_trade_pnl, axis=1)

    daily_pnl = (
        trades_df
        .groupby("trade_date", as_index=False)["pnl"]
        .sum()
        .sort_values("trade_date")
    )

    daily_pnl["cumulative_pnl"] = daily_pnl["pnl"].cumsum()
    return daily_pnl


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\pnl\realised_pnl.py =====

import json
import pandas as pd

def build_realised_pnl(events_path: str) -> pd.DataFrame:
    rows = []

    with open(events_path) as f:
        for line in f:
            e = json.loads(line)
            if e["event_type"] != "settle_pnl":
                continue

            rows.append({
                "timestamp": e["ts"],
                "trader_id": e["trader_id"],
                "market": e["market"],
                "realised_pnl": e["realised_pnl"],
            })

    df = pd.DataFrame(rows)
    df["timestamp"] = pd.to_datetime(df["timestamp"])
    return df.sort_values("timestamp")


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\pnl\__init__.py =====



===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\reports\pnl_overview.py =====

import os
import json
import pandas as pd
import matplotlib.pyplot as plt

from src.analytics.pnl.pnl_timeseries import build_pnl_timeseries
from src.analytics.pnl.drawdown import compute_drawdown


DATA_PATH = "data/processed/trades.csv"
REPORT_DIR = "data/reports"


def main():
    os.makedirs(REPORT_DIR, exist_ok=True)

    # Load trades
    trades_df = pd.read_csv(DATA_PATH, parse_dates=["trade_date"])

    # Build PnL series
    pnl_df = build_pnl_timeseries(trades_df)
    pnl_df["drawdown"] = compute_drawdown(pnl_df["cumulative_pnl"])

    # Save outputs
    pnl_df.to_csv(f"{REPORT_DIR}/pnl_timeseries.csv", index=False)
    pnl_df.to_json(f"{REPORT_DIR}/pnl_timeseries.json", orient="records")

    summary = {
        "total_pnl": round(pnl_df["pnl"].sum(), 2),
        "max_drawdown": round(pnl_df["drawdown"].min(), 2),
        "trading_days": int(pnl_df.shape[0])
    }

    with open(f"{REPORT_DIR}/pnl_summary.json", "w") as f:
        json.dump(summary, f, indent=2)

    # Plot (saved, no blocking)
    plt.figure(figsize=(10, 5))
    plt.plot(pnl_df["trade_date"], pnl_df["cumulative_pnl"], label="Cumulative PnL")
    plt.fill_between(
        pnl_df["trade_date"],
        pnl_df["drawdown"],
        0,
        alpha=0.3,
        label="Drawdown"
    )
    plt.title("Protocol PnL Performance")
    plt.xlabel("Date")
    plt.ylabel("PnL")
    plt.legend()
    plt.tight_layout()
    plt.savefig(f"{REPORT_DIR}/pnl_curve.png")
    plt.close()

    print("âœ… PnL analytics generated successfully")
    print(summary)


if __name__ == "__main__":
    main()


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\reports\protocol_overview.py =====

import pandas as pd
import matplotlib.pyplot as plt
import os
import json
import numpy as np

# ---------------------------
# Paths
# ---------------------------
RAW_EVENTS_PATH = "configs/mock_data.json"
REPORT_CSV_PATH = "data/reports/protocol_overview.csv"
REPORT_JSON_PATH = "data/reports/protocol_overview.json"

os.makedirs("data/reports", exist_ok=True)

# ---------------------------
# Load events
# ---------------------------
with open(RAW_EVENTS_PATH, "r") as f:
    events = json.load(f)

df = pd.DataFrame(events)

# ---------------------------
# Calculate volume correctly per product type
# ---------------------------
# Volume definition:
# - Option: premium
# - Spot/Perp: price * size
df["volume"] = np.where(
    df["product_type"] == "option",
    df["premium"].fillna(0),
    (df["price"].fillna(0) * df["size"].fillna(0))
)

# ---------------------------
# Summary statistics
# ---------------------------
summary = (
    df.groupby("product_type")
      .agg(
          volume=("volume", "sum"),
          unique_traders=("trader_id", "nunique")
      )
      .reset_index()
)

# Add volume share percentage to summary
summary["volume_share_pct"] = (
    summary["volume"] / summary["volume"].sum() * 100
).round(2)

# ---------------------------
# Save report
# ---------------------------
summary.to_csv(REPORT_CSV_PATH, index=False)
summary.to_json(REPORT_JSON_PATH, orient='records', indent=4)

print("âœ… Protocol overview saved to:")
print(f"- {REPORT_CSV_PATH}")
print(f"- {REPORT_JSON_PATH}")
print("\nðŸ“Š Summary:")
print(summary.to_string(index=False))

# ---------------------------
# Plot volume per product type
# ---------------------------
plt.figure(figsize=(8, 5))
colors = ['#1f77b4', '#ff7f0e', '#2ca02c']  # Spot, Perp, Option
plt.bar(summary['product_type'], summary['volume'], color=colors[:len(summary)])
plt.title("Trading Volume by Product Type")
plt.xlabel("Product Type")
plt.ylabel("Volume")
plt.tight_layout()
plt.savefig("data/reports/volume_by_product.png", dpi=150)
plt.close()  # Close to prevent blocking

# ---------------------------
# Plot unique traders per product type
# ---------------------------
plt.figure(figsize=(8, 5))
plt.bar(summary['product_type'], summary['unique_traders'], color=colors[:len(summary)])
plt.title("Unique Traders by Product Type")
plt.xlabel("Product Type")
plt.ylabel("Number of Unique Traders")
plt.tight_layout()
plt.savefig("data/reports/traders_by_product.png", dpi=150)
plt.close()  

print("\nðŸ“Š Charts saved to:")
print("- data/reports/volume_by_product.png")
print("- data/reports/traders_by_product.png")


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\trades\activity.py =====


import pandas as pd
import json

def build_trade_activity(events_path: str):
    rows = []

    with open(events_path) as f:
        for line in f:
            e = json.loads(line)
            if e["event_type"] != "trade":
                continue

            rows.append({
                "timestamp": e["ts"],
                "trader_id": e["trader_id"],
                "market": e["market"],
                "side": e["side"],
                "price": e["price"],
                "size": e["size"],
                "fee": e["fee"],
            })

    return pd.DataFrame(rows)


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\trades\__init__.py =====



===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\contract.py =====

PRODUCT_TYPES = {"spot", "perp", "option"}

REQUIRED_FIELDS = {
    "event_id": str,
    "product_type": str,    # spot | perp | option
    "event_type": str,      # trade, open, close, exercise, expiry
    "timestamp": int,

    "market": str,
    "trader_id": str,

    "side": str,            # buy/sell OR long/short
    "price": float,
    "size": float,
}

OPTIONAL_FIELDS = {
    # common
    "fee": float,

    # perp-specific
    "pnl": float,
    "funding_rate": float,

    # option-specific
    "option_type": str,     # call / put
    "strike": float,
    "expiry": int,
    "premium": float,
    "exercise_pnl": float,
}


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\debug.py =====

import json
from pathlib import Path
from collections import Counter

def inspect_normalized_data():
    normalized_path = Path("data/normalized/events.jsonl")

    if not normalized_path.exists():
        print("âŒ No normalized data file found.")
        return

    if normalized_path.stat().st_size == 0:
        print("âš ï¸ Normalized file exists but is empty.")
        return

    all_fields = set()
    event_types = Counter()
    sample_events = []

    with normalized_path.open() as f:
        for i, line in enumerate(f):
            event = json.loads(line)
            all_fields.update(event.keys())
            event_types[event.get("event_type")] += 1

            if i < 3:
                sample_events.append(event)

    print("\nðŸ“Š Normalized Data Overview")
    print(f"Total events: {sum(event_types.values())}")

    print("\nEvent types:")
    for et, c in event_types.items():
        print(f"  - {et}: {c}")

    print("\nColumns present:")
    for field in sorted(all_fields):
        print(f"  - {field}")

    print("\nSample events:")
    for i, ev in enumerate(sample_events, 1):
        print(f"\nEvent {i}")
        for k, v in ev.items():
            print(f"  {k}: {v}")


if __name__ == "__main__":
    inspect_normalized_data()


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\pnl.py =====

from typing import List, Dict

def build_pnl(trades: List[Dict]) -> List[Dict]:
    pnl = []

    for t in trades:
        direction = 1 if t["side"] == "buy" else -1

        pnl.append({
            "trade_id": t["trade_id"],
            "trader": t["trader"],
            "market": t["market"],
            "timestamp": t["timestamp"],
            "pnl": direction * t["price"] * t["size"] * 0.001
        })

    return pnl


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\time_based.py =====

from collections import defaultdict
from typing import List, Dict

def build_time_metrics(pnls: List[Dict]) -> Dict:
    out = defaultdict(float)

    for p in pnls:
        day = p["timestamp"][:10]  # YYYY-MM-DD
        out[day] += p["pnl"]

    return dict(out)


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\trades.py =====

from typing import List, Dict

def build_trades(events: List[Dict]) -> List[Dict]:
    """
    Convert raw protocol events into normalized trade records.
    """
    trades = []

    for e in events:
        if e["event_type"] != "trade":
            continue

        trades.append({
            "trade_id": e["event_id"],
            "timestamp": e["timestamp"],
            "trader": e["trader"],
            "market": e["market"],
            "side": e["side"],
            "price": e["price"],
            "size": e["size"],
        })

    return trades


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\validate.py =====

# src/analytics/validate.py
from typing import Dict, Any
from datetime import datetime

# --- Base required fields ---
REQUIRED_FIELDS = {
    "event_id",
    "event_type",
    "timestamp",
    "trader_id",
    "market_id",
    "product_type"
}

# --- Event type schemas (ONLY: open, trade, close) ---
EVENT_TYPE_SCHEMAS = {
    "trade": {
        "required": {"side", "price", "size", "fee"},
        "optional": {"pnl"}
    },
    "open": {
        "required": {"side", "price", "size", "fee"},
        "optional": {"pnl"}
    },
    "close": {
        "required": {"side", "price", "size", "fee"},
        "optional": {"pnl"}
    }
}

# Allowed fields = base + all event-specific fields
ALLOWED_FIELDS = REQUIRED_FIELDS | {
    field for schema in EVENT_TYPE_SCHEMAS.values()
    for field in schema["required"] | schema["optional"]
}

class EventValidationError(Exception):
    """Raised when event fails validation."""
    pass

def validate_event(event: Dict[str, Any]) -> None:
    """
    Enforce strict event contract.
    Event types: open, trade, close ONLY (no exercise/option_exercise).
    Product types: spot, perp, option (all allowed).
    """

    # 1ï¸âƒ£ Check required base fields
    missing = REQUIRED_FIELDS - event.keys()
    if missing:
        raise EventValidationError(f"Missing required fields: {missing}")

    # 2ï¸âƒ£ Check extra fields (schema drift)
    extra = set(event.keys()) - ALLOWED_FIELDS
    if extra:
        raise EventValidationError(f"Unexpected fields detected: {extra}")

    # 3ï¸âƒ£ Validate event type (removed exercise/option_exercise)
    event_type = event.get("event_type")
    if event_type not in EVENT_TYPE_SCHEMAS:
        raise EventValidationError(
            f"Unknown event_type: {event_type}. Allowed: {list(EVENT_TYPE_SCHEMAS.keys())}"
        )

    # 4ï¸âƒ£ Check event-type-specific fields
    schema = EVENT_TYPE_SCHEMAS[event_type]
    missing_required = schema["required"] - set(event.keys())
    if missing_required:
        raise EventValidationError(
            f"Event type '{event_type}' missing required fields: {missing_required}"
        )

    # 5ï¸âƒ£ Validate timestamp
    try:
        datetime.fromisoformat(event["timestamp"].replace("Z", "+00:00"))
    except (ValueError, AttributeError):
        raise EventValidationError(f"Invalid timestamp format: {event.get('timestamp')}")

    # 6ï¸âƒ£ Validate numeric fields
    numeric_fields = {"price", "size", "fee", "pnl"}
    for field in numeric_fields & event.keys():
        value = event[field]
        if value is not None and not isinstance(value, (int, float)):
            raise EventValidationError(
                f"Field '{field}' must be numeric or null, got {type(value)}"
            )

    # 7ï¸âƒ£ Validate side values
    if "side" in event:
        valid_sides = {"buy", "sell", "long", "short"}
        if event["side"] not in valid_sides:
            raise EventValidationError(
                f"Invalid side: {event['side']}. Must be one of {valid_sides}"
            )

    # 8ï¸âƒ£ Validate product_type (âœ… option is allowed)
    valid_products = {"spot", "perp", "option"}
    if event.get("product_type") not in valid_products:
        raise EventValidationError(
            f"Invalid product_type: {event.get('product_type')}. Allowed: {valid_products}"
        )


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\__init__.py =====



===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\common\logging.py =====

import logging

def get_logger(name):
    logger = logging.getLogger(name)
    if not logger.handlers:
        handler = logging.StreamHandler()
        formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        logger.setLevel(logging.INFO)
    return logger


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\common\__init__.py =====



===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\ingestion\normalizer.py =====

# src/ingestion/normalizer.py
from typing import Dict, Any
from datetime import datetime, timezone
import hashlib

def normalize_event(raw_event: Dict[str, Any]) -> Dict[str, Any]:
    """
    Normalize raw event data into canonical schema.
    - Convert keys to expected schema names
    - Convert Unix timestamps to ISO 8601
    - Ensure event_id exists
    """
    event = raw_event.copy()

    # --- Normalize timestamp ---
    ts = event.get("timestamp")
    if isinstance(ts, (int, float)):
        # Convert Unix timestamp (seconds) to ISO 8601 UTC
        event["timestamp"] = datetime.fromtimestamp(ts, tz=timezone.utc).isoformat()
    elif isinstance(ts, str):
        # Attempt to parse string timestamp and standardize
        try:
            dt = datetime.fromisoformat(ts.replace("Z", "+00:00"))
            event["timestamp"] = dt.isoformat()
        except ValueError:
            # Leave as-is; validation will catch errors
            pass

    # --- Normalize keys for backward compatibility ---
    if "trader" in event:
        event["trader_id"] = event.pop("trader")
    if "market" in event:
        event["market_id"] = event.pop("market")
    if "type" in event and "event_type" not in event:
        event["event_type"] = event.pop("type")
    if "product" in event and "product_type" not in event:
        event["product_type"] = event.pop("product")

    # --- Ensure event_id exists ---
    if "event_id" not in event:
        raw = f"{event.get('event_type')}|{event.get('timestamp')}|{event.get('trader_id')}|{event.get('market_id')}"
        event["event_id"] = hashlib.sha256(raw.encode()).hexdigest()

    return event


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\ingestion\pipelines.py =====

import json
import hashlib
from pathlib import Path
from src.ingestion.watermark import WatermarkStore
from src.ingestion.normalizer import normalize_event
from src.analytics.validate import validate_event, EventValidationError


class IngestionPipeline:
    def __init__(self, raw_path: str, output_path: str, checkpoint_path: str):
        self.raw_path = Path(raw_path)
        self.output_path = Path(output_path)
        self.watermark = WatermarkStore(checkpoint_path)

    def run(self) -> int:
        if not self.raw_path.exists():
            raise FileNotFoundError(f"Raw data source not found: {self.raw_path}")

        events = json.loads(self.raw_path.read_text())
        new_events = []
        errors = []

        for idx, raw in enumerate(events):
            try:
                # Stable deterministic event_id
                if "event_id" not in raw:
                    seed = f"{raw.get('event_type')}|{raw.get('ts')}|{raw.get('trader')}|{raw.get('market')}|{idx}"
                    raw["event_id"] = hashlib.sha256(seed.encode()).hexdigest()

                if not self.watermark.is_new(raw["event_id"]):
                    continue

                normalized = normalize_event(raw)
                validate_event(normalized)

                new_events.append(normalized)
                self.watermark.mark(raw["event_id"])

            except EventValidationError as e:
                errors.append(f"Event {idx} failed validation: {e}")

        if errors:
            print(f"âš ï¸  {len(errors)} events failed validation and were skipped:")
            for e in errors[:5]:
                print(f"   - {e}")
            if len(errors) > 5:
                print(f"   ... and {len(errors) - 5} more")

        self.output_path.parent.mkdir(parents=True, exist_ok=True)
        with self.output_path.open("a", encoding="utf-8") as f:
            for e in new_events:
                f.write(json.dumps(e) + "\n")

        print(f"âœ… Ingested {len(new_events)} valid events")
        return len(new_events)


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\ingestion\watermark.py =====

# src/ingestion/watermark.py
import json
from pathlib import Path
from typing import Set

class WatermarkStore:
    """
    Persistent watermark store to prevent reprocessing events.
    """

    def __init__(self, path: str):
        self.path = Path(path)
        self.seen: Set[str] = set()
        self._load()

    def _load(self):
        if self.path.exists():
            with open(self.path, "r") as f:
                self.seen = set(json.load(f))

    def _save(self):
        self.path.parent.mkdir(parents=True, exist_ok=True)
        with open(self.path, "w") as f:
            json.dump(list(self.seen), f)

    def is_new(self, event_id: str) -> bool:
        return event_id not in self.seen

    def mark(self, event_id: str):
        self.seen.add(event_id)
        self._save()


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\ingestion\__init__.py =====



===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\mock\market_simulator.py =====

import random

class MarketSimulator:
    def __init__(self, name: str, tick_size: float):
        self.name = name
        self.tick_size = tick_size
        self.price = 100.0  # starting price

    def step(self):
        """Simulate a single market tick"""
        move = random.choice([-1, 1]) * self.tick_size
        self.price += move
        return round(self.price, 2)


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\mock\trader_simulator.py =====

class TraderSimulator:
    def __init__(self, config):
        self.config = config

    def simulate_trade(self, market_data):
        # Example: random trade based on market price
        import random
        trade = {
            "price": market_data["price"],
            "side": random.choice(["buy", "sell"]),
            "quantity": round(random.uniform(1, 10), 2),
            "timestamp": market_data["timestamp"]
        }
        return trade


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\mock\__init__.py =====



===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\storage\writer.py =====

class EventWriter:
    def __init__(self, config):
        self.config = config

    def write(self, events):
        # Example: write to a local JSON file
        import json
        with open("mock_events.json", "w") as f:
            json.dump(events, f, indent=2)


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\storage\__init__.py =====



===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\__init__.py =====



===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\main.py =====

def main():
    print("Hello from deriverse-data-puller!")


if __name__ == "__main__":
    main()


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\pyproject.toml =====

[project]
name = "deriverse-data-puller"
version = "0.1.0"
description = "Mock on-chain trading analytics system for Deriverse"
readme = "README.md"
requires-python = ">=3.10"

dependencies = [
    "matplotlib>=3.10.8",
    "pandas>=2.3.3",
    "pyyaml",
    "requests>=2.32.5",
    "streamlit",
]

