

===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\.vscode\settings.json =====

{
    "python.defaultInterpreterPath": "${workspaceFolder}/.venv/Scripts/python.exe",
    "python.analysis.extraPaths": ["./"],
    "python.autoComplete.extraPaths": [
        "${workspaceFolder}/.venv/Lib/site-packages"
    ]
}


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\configs\ingestion.yaml =====

# configs/ingestion.yaml

# Path to raw mock protocol events (JSON array)
raw_data_path: configs/mock_data.json

# Append-only normalized output (JSONL format)
normalized_output_path: data/normalized/events.jsonl

# Watermark / checkpoint store for incremental ingestion
checkpoint_path: data/checkpoints/watermark.json

# Allowed lateness for event-time processing (seconds)
allowed_lateness_seconds: 0

# Optional controls (future-safe)
markets: []
traders: []
max_events_per_run: null


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\configs\loader.py =====

# configs/loader.py

import yaml
from pathlib import Path
import logging  # âœ… ADD THIS

logger = logging.getLogger(__name__) 

def load_config(path: str) -> dict:
    with open(Path(path), "r") as f:
        return yaml.safe_load(f)


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\configs\mock_data.json =====

[
  {
    "event_type": "open",
    "timestamp": "2026-01-17T19:59:51.195759Z",
    "trader_id": "7KNXqvHu2QWvDq8cGPGvKZhFvYnz3kQ5mL8xRt2Bp9uV",
    "market_id": "SOL/USDC",
    "product_type": "spot",
    "side": "buy",
    "price": 100,
    "size": 10,
    "fee_usd": 0.5,
    "event_id": "acb3fde9cfc316fb87622167fbb5c04f3d1999ebd4b359eb354048aa72782727",
    "tx_hash": "2hN2FJSjfSiHBGZ2ysEBHyoZtVfC8AoT5W9inQxCMUsv8MYsjP4KgsXhr3ziDtANtp2trkLjJHCxhnpryUbTJRQb",
    "position_id": "7KNXqvHu_SOL/USDC_1768679991195",
    "order_type": "stop"
  },
  {
    "event_type": "close",
    "timestamp": "2026-01-17T21:59:51.195759Z",
    "trader_id": "7KNXqvHu2QWvDq8cGPGvKZhFvYnz3kQ5mL8xRt2Bp9uV",
    "market_id": "SOL/USDC",
    "product_type": "spot",
    "side": "sell",
    "price": 110,
    "size": 10,
    "fee_usd": 0.5,
    "event_id": "2b2b25be205e32ab7e3bd359b2ccdceb7ee90db6a05126807df898fbc6233fdd",
    "tx_hash": "rEHwDEehF2ssQ2RGuTTmyZstA1P7rWg17GWdrbtXK9D5xEwiZRxxVd4K3R56hZFp8kwHodqZBvjXDFpKZxmYwsV",
    "position_id": "7KNXqvHu_SOL/USDC_1768679991195",
    "entry_price": 100,
    "order_type": "market"
  },
  {
    "event_type": "open",
    "timestamp": "2026-01-19T20:09:51.195759Z",
    "trader_id": "5FxM2nQwP4vYkL9mT3xRd8eJbWp7sN6gH2cKt9uVfXyZ",
    "market_id": "ETH/USDC",
    "product_type": "spot",
    "side": "buy",
    "price": 2000,
    "size": 5,
    "fee_usd": 1.0,
    "event_id": "9bf70df1b0dbee7ad83c193c4434ec7bf5c72ca8f62c8750801a1edd5beedcc2",
    "tx_hash": "3EnvVNrvCBtiifnZgxHnCxNhBepvudHru3JXt1hMjUoJzLULMyb97BCxjvoN3cLc62Waw6xzt7AWKeiKPsb6JKWo",
    "position_id": "5FxM2nQw_ETH/USDC_1768853391195",
    "order_type": "market"
  },
  {
    "event_type": "close",
    "timestamp": "2026-01-19T22:59:51.195759Z",
    "trader_id": "5FxM2nQwP4vYkL9mT3xRd8eJbWp7sN6gH2cKt9uVfXyZ",
    "market_id": "ETH/USDC",
    "product_type": "spot",
    "side": "sell",
    "price": 1950,
    "size": 5,
    "fee_usd": 1.0,
    "event_id": "a16e1faa9dd2351bc3c404419d5fcaed10756cf7d5df798d427a51e155772f8a",
    "tx_hash": "33HsnYpT9Rjueckxwqi6b8pbpFq1Pyrrk2QW9g3eVY5YbD5oB9TThtiyV9fSjrn1cNGwwtrbyCwVGAiNT7tMWPD9",
    "position_id": "5FxM2nQw_ETH/USDC_1768853391195",
    "entry_price": 2000,
    "order_type": "stop"
  },
  {
    "event_type": "open",
    "timestamp": "2026-01-21T20:19:51.195759Z",
    "trader_id": "9DpT3vHx5kN2qL8mR7wYfJ6bP4sE1cG9nZ5tK3uVwXyA",
    "market_id": "SOL-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 100,
    "size": 10,
    "fee_usd": 0.5,
    "event_id": "16303edcd53d2e2c7830063ee019ff2e7e9740a4cc6a7d509821d74b355fe139",
    "tx_hash": "2wjS9p1T89xFHsNhxbJwnkPxzmq749rC9KwGmGgwL5MTNNoCQgu2tt9pcqfhbDTwe5uwaVmqEx4HBZi1ANtDUziT",
    "position_id": "9DpT3vHx_SOL-PERP_1769026791195",
    "order_type": "limit"
  },
  {
    "event_type": "close",
    "timestamp": "2026-01-21T23:59:51.195759Z",
    "trader_id": "9DpT3vHx5kN2qL8mR7wYfJ6bP4sE1cG9nZ5tK3uVwXyA",
    "market_id": "SOL-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 120,
    "size": 10,
    "fee_usd": 0.5,
    "event_id": "02cfb3d5692fdd421eafd6dc9e15b41130ffdc0ca9d4e760f1505dd0ce0a83ed",
    "tx_hash": "4u38uczFdePa1azvieWieKcu6ujGAaMedLPwLmwm3t5rCNJEQsu4oNePZHPefatsmFUjpK4oVn886gbHLGPCiyY3",
    "position_id": "9DpT3vHx_SOL-PERP_1769026791195",
    "entry_price": 100,
    "order_type": "market"
  },
  {
    "event_type": "open",
    "timestamp": "2026-01-23T20:29:51.195759Z",
    "trader_id": "4MqL8vYx2kP9nT7wR5fH3bJ6sE1cG4nZ8tK2uVwXyBpQ",
    "market_id": "BTC-PERP",
    "product_type": "perp",
    "side": "short",
    "price": 50000,
    "size": 1,
    "fee_usd": 5.0,
    "event_id": "b7c2497f648b9817f48ad5b3512d41f96546c26a5a0bb1b395ddcf5bab99b7b0",
    "tx_hash": "5KL1eVmxCmx3Y6Eg7kGiRftjk7LpwD84BaMLhcR3GLNp2tc1VfX6Wkcg43mP8pHyvKT1NRgK2wXftQS3MNzbgAtP",
    "position_id": "4MqL8vYx_BTC-PERP_1769200191195",
    "order_type": "market"
  },
  {
    "event_type": "close",
    "timestamp": "2026-01-24T00:59:51.195759Z",
    "trader_id": "4MqL8vYx2kP9nT7wR5fH3bJ6sE1cG4nZ8tK2uVwXyBpQ",
    "market_id": "BTC-PERP",
    "product_type": "perp",
    "side": "short",
    "price": 48000,
    "size": 1,
    "fee_usd": 5.0,
    "event_id": "cb6ce2fa083ea0d7d29f0b89b421c0487650e64a7d433b8c5a28d96d7996c3fe",
    "tx_hash": "2KgFSDqtwr9jF7ZiiCypUDRCRcoLiKpYqecNGMLr9mDYMfNDMfDGSvWPUSAeLrr3TTsFZZfokxuihU3GvS5yZFhy",
    "position_id": "4MqL8vYx_BTC-PERP_1769200191195",
    "entry_price": 50000,
    "order_type": "market"
  },
  {
    "event_type": "open",
    "timestamp": "2026-01-24T20:39:51.195759Z",
    "trader_id": "6NrK9wZx3mQ8pU7vS4gI2dL5tF1eH7oA9yM3xVbCwRtE",
    "market_id": "ETH-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 2100,
    "size": 5,
    "fee_usd": 2.0,
    "event_id": "b653c6cd4ca7260eda01880c036124bdd4adbbcb7fa351466828739f30d57052",
    "tx_hash": "4KhRPZYuX2CGpgAkBfkAvr5APxHZmGtW44FNg2T2mEB2DkUqyiyVvxB44RGA3XHapvjgfCaAoFgoELQakZFBpSB1",
    "position_id": "6NrK9wZx_ETH-PERP_1769287191195",
    "order_type": "stop"
  },
  {
    "event_type": "close",
    "timestamp": "2026-01-25T01:59:51.195759Z",
    "trader_id": "6NrK9wZx3mQ8pU7vS4gI2dL5tF1eH7oA9yM3xVbCwRtE",
    "market_id": "ETH-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 2050,
    "size": 5,
    "fee_usd": 2.0,
    "event_id": "a120f336e296eda9f4ac5fb5d42724fb762cd41630b3acee3176200070d54526",
    "tx_hash": "52UGzLjhr6jAUuiWqGC3w9U9TnUUvphAdCKZ7p5TekoLV6UBcEGDS7tcWkbMggh7YqMMYqLpy2QMUYHjT93F6FAP",
    "position_id": "6NrK9wZx_ETH-PERP_1769287191195",
    "entry_price": 2100,
    "order_type": "market"
  },
  {
    "event_type": "open",
    "timestamp": "2026-01-26T20:59:51.195759Z",
    "trader_id": "4MqL8vYx2kP9nT7wR5fH3bJ6sE1cG4nZ8tK2uVwXyBpQ",
    "market_id": "SOL-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 105,
    "size": 50,
    "fee_usd": 5.0,
    "event_id": "084fff011144eccbbdf110b13dd6a1255607aa788eb501f1bcc5942b27ab120d",
    "tx_hash": "2P6TKhLvHaiYffVX6RjWpWWP9G21aiyMLLgBbbhaTZ3ANmTo1H3GoKmhGDUWzmUtnz2MzsY7me2UovcirbNF2mMZ",
    "position_id": "4MqL8vYx_SOL-PERP_1769461191195",
    "order_type": "market"
  },
  {
    "event_type": "liquidation",
    "timestamp": "2026-01-26T21:59:51.195759Z",
    "trader_id": "4MqL8vYx2kP9nT7wR5fH3bJ6sE1cG4nZ8tK2uVwXyBpQ",
    "market_id": "SOL-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 88,
    "size": 50,
    "fee_usd": 25.0,
    "event_id": "b9ff06e24ead38893fa5974bb665c0e8c148b0bfb91141d4f76714f6bcdfb116",
    "tx_hash": "5bAybSYXEUpqYuDs7F7ndQmwTm3XofZzxSDpd5efWY7i1NVhMQbnSS2dijdBmDqMWX5SPVS6PsRJHSJpu3MhwnSK",
    "position_id": "4MqL8vYx_SOL-PERP_1769461191195",
    "entry_price": 105,
    "order_type": "liquidation"
  },
  {
    "event_type": "open",
    "timestamp": "2026-01-28T22:59:51.195759Z",
    "trader_id": "5FxM2nQwP4vYkL9mT3xRd8eJbWp7sN6gH2cKt9uVfXyZ",
    "market_id": "ETH-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 2200,
    "size": 10,
    "fee_usd": 3.0,
    "event_id": "34282bbff789cfb973b6abce8035661c97d01780fe9770911f3402abf63f5da2",
    "tx_hash": "5xuAuYoiDQhwdFgHcEfNLnKsJgUvJpytbczceHnDonxDkam9gjRZ1QHUM5KLtpoRsSyxXTuxGxCwsvvSo2DvWS4w",
    "position_id": "5FxM2nQw_ETH-PERP_1769641191195",
    "order_type": "market"
  },
  {
    "event_type": "liquidation",
    "timestamp": "2026-01-29T03:59:51.195759Z",
    "trader_id": "5FxM2nQwP4vYkL9mT3xRd8eJbWp7sN6gH2cKt9uVfXyZ",
    "market_id": "ETH-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 2050,
    "size": 10,
    "fee_usd": 20.0,
    "event_id": "9f0ce6416b69ae21ed15ec7eacd42f3a9cd4667554119d1479885ab8e9af8f3c",
    "tx_hash": "WQR7cqC4EQC4fw5NU7cp1Cyc7su1StgVBWZopKan4mTWQeYyc7vHxtZdQUqGrC6FPgYnTahXdyp3BKfW9mMqaRm",
    "position_id": "5FxM2nQw_ETH-PERP_1769641191195",
    "entry_price": 2200,
    "order_type": "liquidation"
  },
  {
    "event_type": "open",
    "timestamp": "2026-01-31T21:59:51.195759Z",
    "trader_id": "6NrK9wZx3mQ8pU7vS4gI2dL5tF1eH7oA9yM3xVbCwRtE",
    "market_id": "BTC-PERP",
    "product_type": "perp",
    "side": "short",
    "price": 49000,
    "size": 2,
    "fee_usd": 8.0,
    "event_id": "3acba55e7b779b38c33e3f171e4723c65d9e1729f9fa01a49ccb37473e6815cd",
    "tx_hash": "2aGffyu7z4GaExYQEV4jVy6hSZzJBtJksikyMqsJRduC49ht93jBnpCR1Ldo6YDKeJjZztwgNUVHiWDV1RxtSeUw",
    "position_id": "6NrK9wZx_BTC-PERP_1769896791195",
    "order_type": "limit"
  },
  {
    "event_type": "liquidation",
    "timestamp": "2026-02-01T07:59:51.195759Z",
    "trader_id": "6NrK9wZx3mQ8pU7vS4gI2dL5tF1eH7oA9yM3xVbCwRtE",
    "market_id": "BTC-PERP",
    "product_type": "perp",
    "side": "short",
    "price": 50250,
    "size": 2,
    "fee_usd": 30.0,
    "event_id": "01af60c0ed577bea7020aea051e615a6b67e046123f842fe589a181210707a93",
    "tx_hash": "5YNLvqmZ4ex5SnvfSCdDKTjapkg1Cty5jKhhYRjs6Ysk1wALhW7FPWRDKTam44fB6DqWrkZyvtELUaS8r8FG3MXd",
    "position_id": "6NrK9wZx_BTC-PERP_1769896791195",
    "entry_price": 49000,
    "order_type": "liquidation"
  },
  {
    "event_type": "open",
    "timestamp": "2026-02-04T00:59:51.195759Z",
    "trader_id": "9DpT3vHx5kN2qL8mR7wYfJ6bP4sE1cG9nZ5tK3uVwXyA",
    "market_id": "AVAX-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 38.5,
    "size": 100,
    "fee_usd": 4.0,
    "event_id": "8789e428bd0e03e8b114c72436a1058e46af890170fda43efd6e297cb0331dbb",
    "tx_hash": "2cxXnPMkyWbHL1gUdFQMMsj48jazp5N3T4mdD2AnxzcwXLXdiydu7y2vU2TrzYwmPZWPARpUpyAH8shFpdeYFcL7",
    "position_id": "9DpT3vHx_AVAX-PERP_1770166791195",
    "order_type": "market"
  },
  {
    "event_type": "liquidation",
    "timestamp": "2026-02-04T09:59:51.195759Z",
    "trader_id": "9DpT3vHx5kN2qL8mR7wYfJ6bP4sE1cG9nZ5tK3uVwXyA",
    "market_id": "AVAX-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 35.2,
    "size": 100,
    "fee_usd": 12.0,
    "event_id": "74d5cd6ab5dec5af043daea05af09fd17019fbcd1cdcf99c594b57cab22bcbbb",
    "tx_hash": "5dnVy93zdhvQKJVaybohpvMTFTGg1FP6JiYqEPTvPkHp2pxtpYSeXDPRz9R654g4tR95LYuXDHVVLAaKgxJbq7MZ",
    "position_id": "9DpT3vHx_AVAX-PERP_1770166791195",
    "entry_price": 38.5,
    "order_type": "liquidation"
  },
  {
    "event_type": "open",
    "timestamp": "2026-02-05T23:59:51.195759Z",
    "trader_id": "7KNXqvHu2QWvDq8cGPGvKZhFvYnz3kQ5mL8xRt2Bp9uV",
    "market_id": "SOL-PERP",
    "product_type": "perp",
    "side": "short",
    "price": 115,
    "size": 30,
    "fee_usd": 3.5,
    "event_id": "3851f526267d7acd26773f8cf61338aa59be4fd4d12897ed30569dfac2abf057",
    "tx_hash": "3SaxpigyM4PEZoYZ6MVYxoSAYFnt1FQ6FtN4s9a965UouZDWKK4jEn9ok6vLKumUcsXW58B8TjytMnYULaYjxoYj",
    "position_id": "7KNXqvHu_SOL-PERP_1770335991195",
    "order_type": "stop"
  },
  {
    "event_type": "liquidation",
    "timestamp": "2026-02-06T04:59:51.195759Z",
    "trader_id": "7KNXqvHu2QWvDq8cGPGvKZhFvYnz3kQ5mL8xRt2Bp9uV",
    "market_id": "SOL-PERP",
    "product_type": "perp",
    "side": "short",
    "price": 135,
    "size": 30,
    "fee_usd": 18.0,
    "event_id": "a7d2e34d6b0b647fc93ccb70bbc613ec7f9c1ccc7519f684cf4d43e132fbe917",
    "tx_hash": "3vQTmqvbESy7teVeRWxxNx3MWmxtA8N3QXEKjP64YxiNbZSmNGo9jTFcQBdNj492vnL4Q4FGByiq3Ds5rtUuNVBd",
    "position_id": "7KNXqvHu_SOL-PERP_1770335991195",
    "entry_price": 115,
    "order_type": "liquidation"
  },
  {
    "event_type": "open",
    "timestamp": "2026-02-06T20:59:51.195759Z",
    "trader_id": "8QtN2xWy5lR7mV9uT6hK3eM4pG1fJ8nB7zL4wVcDxSeF",
    "market_id": "SOL-CALL-120-JAN15",
    "product_type": "option",
    "option_type": "call",
    "strike": 120,
    "expiry": "2026-02-24T19:59:51.195759Z",
    "side": "buy",
    "price": 5.0,
    "size": 10,
    "fee_usd": 0.5,
    "delta": 0.65,
    "implied_vol": 0.45,
    "event_id": "2c9d6b171e1481a279d26884dd414d9d2c70d44e28e813ee60b7819bd298e32e",
    "tx_hash": "8vrT4RfGq5u4rncVQYLA3XUSpTTyRJeHPNKhVv6ndrvUxNePYe5wQ8B3PtDg3bL7Jw5aSLCMtQ99E4hm8mn5SbR",
    "position_id": "8QtN2xWy_SOL-CALL-120-JAN15_1770411591195",
    "order_type": "stop"
  },
  {
    "event_type": "close",
    "timestamp": "2026-02-07T19:59:51.195759Z",
    "trader_id": "8QtN2xWy5lR7mV9uT6hK3eM4pG1fJ8nB7zL4wVcDxSeF",
    "market_id": "SOL-CALL-120-JAN15",
    "product_type": "option",
    "option_type": "call",
    "strike": 120,
    "expiry": "2026-02-24T19:59:51.195759Z",
    "side": "sell",
    "price": 8.0,
    "size": 10,
    "fee_usd": 0.5,
    "delta": 0.85,
    "implied_vol": 0.5,
    "event_id": "bb75055ec1b3e4d48670bb1b80dd429c0b0e9251c5957f1872ef2208af9bfb1c",
    "tx_hash": "3a5SugbXnmP2bmh9T5SD84WwHPhoLvaeNasETPdkFrD3AGYWG8zRpHNnpMo3AvXz7h2oGGBxtmEMto6NkUJ6Zk8o",
    "position_id": "8QtN2xWy_SOL-CALL-120-JAN15_1770411591195",
    "entry_price": 5.0,
    "order_type": "stop"
  },
  {
    "event_type": "open",
    "timestamp": "2026-02-07T21:29:51.195759Z",
    "trader_id": "3HsJ7yVz4nQ6oW8tS5gL2fN9rH1eK6mC8xM5vBdEwRuG",
    "market_id": "SOL-PUT-90-JAN15",
    "product_type": "option",
    "option_type": "put",
    "strike": 90,
    "expiry": "2026-02-24T19:59:51.195759Z",
    "side": "sell",
    "price": 4.0,
    "size": 15,
    "fee_usd": 0.7,
    "delta": -0.25,
    "implied_vol": 0.4,
    "event_id": "88c83c73f24e1ca0113790450990c8d57cdb50e4f8579bf9511d295d4dcc0d06",
    "tx_hash": "5Xv5WxZZGMGAkET8RJafz4SkUVY4Du7dhCxiEgpqVEn8QqM55aRJvNgTdYPKS4b92CEowVnd4ESpgh5qewNX7Yb1",
    "position_id": "3HsJ7yVz_SOL-PUT-90-JAN15_1770499791195",
    "order_type": "stop"
  },
  {
    "event_type": "close",
    "timestamp": "2026-02-09T07:59:51.195759Z",
    "trader_id": "3HsJ7yVz4nQ6oW8tS5gL2fN9rH1eK6mC8xM5vBdEwRuG",
    "market_id": "SOL-PUT-90-JAN15",
    "product_type": "option",
    "option_type": "put",
    "strike": 90,
    "expiry": "2026-02-24T19:59:51.195759Z",
    "side": "buy",
    "price": 1.5,
    "size": 15,
    "fee_usd": 0.7,
    "delta": -0.1,
    "implied_vol": 0.3,
    "event_id": "77b1a07f6a3949ccbb8e8567f462ffb65c10b716b4c03dc5e3d35ece23349863",
    "tx_hash": "2V449ub5kQj2hjHhq2CSpNzbfxcPLEA4NVkygPspeYLatqa4xmDV6Ruqe153hY1e8CtirZLmcZwJfnsjYie9XpQX",
    "position_id": "3HsJ7yVz_SOL-PUT-90-JAN15_1770499791195",
    "entry_price": 4.0,
    "order_type": "market"
  },
  {
    "event_type": "open",
    "timestamp": "2026-02-08T21:59:51.195759Z",
    "trader_id": "2PrM8xUz6oT5nY7vR4jL3gP1sH9eN4mD6zK8wCfGxQuH",
    "market_id": "ETH-PUT-1900-JAN15",
    "product_type": "option",
    "option_type": "put",
    "strike": 1900,
    "expiry": "2026-02-24T19:59:51.195759Z",
    "side": "buy",
    "price": 45.0,
    "size": 5,
    "fee_usd": 1.0,
    "delta": -0.35,
    "implied_vol": 0.55,
    "event_id": "a01fdd37063abb9368751e77bb04da0892e69d02063f34b1d8c81f3491c0ba7a",
    "tx_hash": "3yAP3yd41ABK7gpCXaekAkVg9CT58iB4nrwLA7sJduzkzoTjyUghHmx7N7VFLXpcZ9Mun888jMg5HuvfEfynSW1u",
    "position_id": "2PrM8xUz_ETH-PUT-1900-JAN15_1770587991195",
    "order_type": "stop"
  },
  {
    "event_type": "close",
    "timestamp": "2026-02-10T19:59:51.195759Z",
    "trader_id": "2PrM8xUz6oT5nY7vR4jL3gP1sH9eN4mD6zK8wCfGxQuH",
    "market_id": "ETH-PUT-1900-JAN15",
    "product_type": "option",
    "option_type": "put",
    "strike": 1900,
    "expiry": "2026-02-24T19:59:51.195759Z",
    "side": "sell",
    "price": 20.0,
    "size": 5,
    "fee_usd": 1.0,
    "delta": -0.15,
    "implied_vol": 0.4,
    "event_id": "f9793e76486d1d46bd925710bd36d513108c1221888a6bef0c9f7dc919946611",
    "tx_hash": "jHLGbd63BHbJysq37dwDsC9FT3FgvtY6ZKLHCXwBrQ1Zfc9uBiUHfFVR8TyWkjJr5k2vaktkCK3oBybM2FDtTWF",
    "position_id": "2PrM8xUz_ETH-PUT-1900-JAN15_1770587991195",
    "entry_price": 45.0,
    "order_type": "limit"
  },
  {
    "event_type": "open",
    "timestamp": "2026-02-10T22:59:51.195759Z",
    "trader_id": "5TpQ9yXz7mS6oV8uR3kM2hN4rJ1fL5nE7xP6wDgHySvI",
    "market_id": "BTC-CALL-50000-JAN15",
    "product_type": "option",
    "option_type": "call",
    "strike": 50000,
    "expiry": "2026-02-24T19:59:51.195759Z",
    "side": "buy",
    "price": 2000.0,
    "size": 1,
    "fee_usd": 10.0,
    "event_id": "c141c68ca6941f24d4d020879153f2e642b82a11476c74853436d18ce0945b7f",
    "tx_hash": "juueA9jcWqYuso7F5FpkX5S8Wj7mZxfttkMRKMQvxHXQboBafDxdnM2oPNWtbaDkHod8Bqfvu2uW9YZjQdKnL55",
    "position_id": "5TpQ9yXz_BTC-CALL-50000-JAN15_1770764391195",
    "order_type": "market"
  },
  {
    "event_type": "exercise",
    "timestamp": "2026-02-23T19:59:51.195759Z",
    "trader_id": "5TpQ9yXz7mS6oV8uR3kM2hN4rJ1fL5nE7xP6wDgHySvI",
    "market_id": "BTC-CALL-50000-JAN15",
    "product_type": "option",
    "option_type": "call",
    "strike": 50000,
    "expiry": "2026-02-24T19:59:51.195759Z",
    "side": "exercise",
    "size": 1,
    "fee_usd": 10.0,
    "underlying_price": 55000,
    "event_id": "b3a5b749088134a1405a2bc29f82aa65150ce7ece783845272d486edf45fe202",
    "tx_hash": "3SP9zudscgfq8uT1iaUFqc7An3yRGyJyp9bLMmcgkRm4FQ98erCUhC6Tbv3tBwrkXiCcWCmaHsHmj9qPExj5Lou9",
    "position_id": "5TpQ9yXz_BTC-CALL-50000-JAN15_1770764391195",
    "entry_price": 2000.0
  },
  {
    "event_type": "open",
    "timestamp": "2026-02-11T23:59:51.195759Z",
    "trader_id": "4WqP8zYx5nT7mU9tS2lN6jM3rK1gH4oC8yL5vEfJxRwK",
    "market_id": "SOL-PUT-80-JAN15",
    "product_type": "option",
    "option_type": "put",
    "strike": 80,
    "expiry": "2026-02-24T19:59:51.195759Z",
    "side": "buy",
    "price": 3.0,
    "size": 20,
    "fee_usd": 0.2,
    "event_id": "57e1137664eacaabbd568190320bf417fddc0761b77b3e383bf4c9efdcb72ade",
    "tx_hash": "2YXbyVhoVqUFum4YahoZyNyCBPMJMuiCgZCXNV9Fwsa5ij4gxv822eMQ7N7syXwcgqdHi1GGTsuemL1fPDpMfc3H",
    "position_id": "4WqP8zYx_SOL-PUT-80-JAN15_1770854391195",
    "order_type": "market"
  },
  {
    "event_type": "expire",
    "timestamp": "2026-02-24T19:59:51.195759Z",
    "trader_id": "4WqP8zYx5nT7mU9tS2lN6jM3rK1gH4oC8yL5vEfJxRwK",
    "market_id": "SOL-PUT-80-JAN15",
    "product_type": "option",
    "option_type": "put",
    "strike": 80,
    "expiry": "2026-02-24T19:59:51.195759Z",
    "side": "expire",
    "price": 0.0,
    "size": 20,
    "fee_usd": 0.0,
    "underlying_price": 95,
    "event_id": "916fe62a46ba546a84b4a034785dc517f68d85f39a5145c5a78ef47273797e86",
    "tx_hash": "3XPMYmxdr6W6H52BQr57heT8LT4FPBwhrvrGT9DbxpZYc1EwMYb97NbxuYjJM2AMd4uJpSdLqxiNBehFASHsZ1YT",
    "position_id": "4WqP8zYx_SOL-PUT-80-JAN15_1770854391195",
    "entry_price": 3.0
  },
  {
    "event_type": "open",
    "timestamp": "2026-02-13T00:59:51.195759Z",
    "trader_id": "7KNXqvHu2QWvDq8cGPGvKZhFvYnz3kQ5mL8xRt2Bp9uV",
    "market_id": "SOL-CALL-110-JAN15",
    "product_type": "option",
    "option_type": "call",
    "strike": 110,
    "expiry": "2026-02-24T19:59:51.195759Z",
    "side": "buy",
    "price": 8.0,
    "size": 20,
    "fee_usd": 1.0,
    "event_id": "25a1c82dde1d8fd23ec5f6be39cea7ade9174c2b3f2dd5a6c5515743db0573e8",
    "tx_hash": "2ZNSNQTbXUUxs3um9GkBEYBU188RQXTcf3ybbL4VGvquqKomWtMoB2PKPC5xXaSNzxVHLkEajURjTwER7CdsrGuM",
    "position_id": "7KNXqvHu_SOL-CALL-110-JAN15_1770944391195",
    "order_type": "market"
  },
  {
    "event_type": "close",
    "timestamp": "2026-02-13T21:59:51.195759Z",
    "trader_id": "7KNXqvHu2QWvDq8cGPGvKZhFvYnz3kQ5mL8xRt2Bp9uV",
    "market_id": "SOL-CALL-110-JAN15",
    "product_type": "option",
    "option_type": "call",
    "strike": 110,
    "expiry": "2026-02-24T19:59:51.195759Z",
    "side": "sell",
    "price": 12.0,
    "size": 10,
    "fee_usd": 0.5,
    "event_id": "c34d819dc9248206690dc5989e0b3ca1faccc5898275b491e259fa11a6c6570b",
    "tx_hash": "21vLR5J7FcHEMEcUtkPubuwypYJR2LamYesTiUkoFEjug1K6Nr2KXumYtaQgTgaXR4SNK5iHJ3NJ6k5jwAArPTE7",
    "position_id": "7KNXqvHu_SOL-CALL-110-JAN15_1770944391195",
    "entry_price": 8.0,
    "order_type": "market"
  },
  {
    "event_type": "close",
    "timestamp": "2026-02-14T21:59:51.195759Z",
    "trader_id": "7KNXqvHu2QWvDq8cGPGvKZhFvYnz3kQ5mL8xRt2Bp9uV",
    "market_id": "SOL-CALL-110-JAN15",
    "product_type": "option",
    "option_type": "call",
    "strike": 110,
    "expiry": "2026-02-24T19:59:51.195759Z",
    "side": "sell",
    "price": 15.0,
    "size": 10,
    "fee_usd": 0.5,
    "event_id": "c3d3f7a8f39197c8dd58d50e5877f011cfbf98539c05c03b78eb7ed5644cb3a7",
    "tx_hash": "5NQxVjai5GvjTwVzgSdehxoxKFZBAw5LkwMh2XisxjmLmyPsu4jp3EZeNxZfWAT7XUuWKaHhzefgYExxHYJdpL2b",
    "order_type": "market"
  },
  {
    "event_type": "open",
    "timestamp": "2026-02-14T12:59:51.195759Z",
    "trader_id": "7KNXqvHu2QWvDq8cGPGvKZhFvYnz3kQ5mL8xRt2Bp9uV",
    "market_id": "BTC/USDC",
    "product_type": "spot",
    "side": "buy",
    "price": 51000,
    "size": 0.5,
    "fee_usd": 5.0,
    "event_id": "72766e912a36f149a5c84c08dda39c54fbc280207f6cf211621c7816678a92d0",
    "tx_hash": "j7axxAiAe47cNAkcDv1wZx9N8nJyUQtCs1orGRRacVPReSdvLBLrk7ZtxK4M1XrdbBybEps7megtrgE4FD9GZ67",
    "position_id": "7KNXqvHu_BTC/USDC_1771073991195",
    "order_type": "market"
  },
  {
    "event_type": "open",
    "timestamp": "2026-02-15T11:59:51.195759Z",
    "trader_id": "5FxM2nQwP4vYkL9mT3xRd8eJbWp7sN6gH2cKt9uVfXyZ",
    "market_id": "AVAX-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 35.5,
    "size": 100,
    "fee_usd": 1.5,
    "event_id": "0ea284eb0e9abfe3765538e5e8add01d49c098af2b2e21c45224eae8b1046331",
    "tx_hash": "kvTx36BbMxfaKTGbagAfngtSHuVXhCAf3vAEaYnEPQNYAdeJjymvmJTKsM3pkg4RA7JYhLmUKe2wPrgjePow9M9",
    "position_id": "5FxM2nQw_AVAX-PERP_1771156791195",
    "order_type": "limit"
  },
  {
    "event_type": "open",
    "timestamp": "2026-02-16T07:59:51.195759Z",
    "trader_id": "9DpT3vHx5kN2qL8mR7wYfJ6bP4sE1cG9nZ5tK3uVwXyA",
    "market_id": "ETH-CALL-2200-FEB13",
    "product_type": "option",
    "option_type": "call",
    "strike": 2200,
    "expiry": "2026-03-03T19:59:51.195759Z",
    "side": "buy",
    "price": 85.0,
    "size": 3,
    "fee_usd": 0.5,
    "event_id": "6f09d31cfc764d43ce091c7f789b9830736c9a17ec60feefdc6c3a6bb2fb5c00",
    "tx_hash": "4Qm9rR2uYxEHKFjUdr4JCH49Hx3DDkY9A8fhK5B9xZjnT5Y1YZDnQGYht9dJNA8JrBdxpmeBdrtSdrWFgHVYHxX9",
    "position_id": "9DpT3vHx_ETH-CALL-2200-FEB13_1771228791195",
    "order_type": "limit"
  },
  {
    "event_type": "open",
    "timestamp": "2026-01-22T20:59:51.195759Z",
    "trader_id": "7KNXqvHu2QWvDq8cGPGvKZhFvYnz3kQ5mL8xRt2Bp9uV",
    "market_id": "SOL/USDC",
    "product_type": "spot",
    "side": "buy",
    "price": 105,
    "size": 5,
    "fee_usd": 0.3,
    "event_id": "b1fc95d3b292e88a262622f2ffd252475b8f08d1911afc02e8de849f47eeafa2",
    "tx_hash": "4SQGEikHqgDosziY5WX3eaTtt4wJv93jtwpN9qq2VquVTqFSJqkiGrTNGuwzCuEcrGUqM5bgbMpkZbw2Gtva6yDq",
    "position_id": "7KNXqvHu_SOL/USDC_1769115591195",
    "order_type": "stop"
  },
  {
    "event_type": "close",
    "timestamp": "2026-01-28T05:59:51.195759Z",
    "trader_id": "GhostWallet1111111111111111111111111111",
    "market_id": "GHOST-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 999,
    "size": 1,
    "fee_usd": 0.1,
    "event_id": "c4d722f6da718fe49321aa6b94f92ad6d872a09aa534519bcdba3783e5f4e65f",
    "tx_hash": "37U8oEest8Xk51ouBUCFacAMccAFh4dWowYmD8kebjFbxqPvSRvfUtrXL3romtiHjnmwgp2HFYjTFRvDPRqrAGVM",
    "order_type": "stop"
  },
  {
    "event_type": "trade",
    "timestamp": "2026-01-20T20:14:51.195759Z",
    "trader_id": "MarketMaker1111111111111111111111111",
    "market_id": "SOL/USDC",
    "product_type": "spot",
    "side": "buy",
    "price": 101,
    "size": 100,
    "fee_usd": 1.0,
    "event_id": "6ddda0c8ace27c3bbd7def6ca2b8195a0499f8758b1b5104c76892f76eaf1ed3",
    "tx_hash": "3eDpn8AXfWMRtvZdrze2nZUHx8iaCZdWWuk9eyuP1Vkf9Zp7aGq2FDan91vvxPoQo5nUkYE3qsAykEjhqhxyWqbd"
  },
  {
    "event_type": "trade",
    "timestamp": "2026-01-25T20:44:51.195759Z",
    "trader_id": "MarketMaker1111111111111111111111111",
    "market_id": "ETH-PERP",
    "product_type": "perp",
    "side": "sell",
    "price": 2105,
    "size": 50,
    "fee_usd": 5.0,
    "event_id": "0607bbad93d56cf36e7f1b91801a157b74471059b9a35ab7024f13c9269c449b",
    "tx_hash": "2frEfpryopTiBjXZtaDisbBb5XZNMdbbxJRAUzKwjgfeKyFsTPp6yKSnVGQD2if1MXzG8s3aD4Ln2Mv6eeuxiJC7"
  }
]


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\configs\__init__.py =====



===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\dashboards\app.py =====

# dashboards/app.py
"""
Deriverse Trading Analytics Dashboard - Enhanced v6.0
Features:
- Privacy-aware trader masking
- Authenticated profile mode
- Adaptive visualizations across all sections
- Enhanced filtering (date range, symbols)
- Top performers analysis with charts
- Persistent trade notes (JSON storage)
- Admin controls for full data access
- Navigation bar for section jumping
"""

import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
from pathlib import Path
from datetime import datetime, timedelta
import requests
import json
import hmac
import os
from dotenv import load_dotenv

load_dotenv()

# ============================================================================
# CONFIGURATION & CONSTANTS
# ============================================================================

DATA_DIR = Path("data/analytics_output")
ADMIN_PASSWORD = os.getenv("ADMIN_PASSWORD", "ADMIN_PASSWORD")  

st.set_page_config(
    page_title="Deriverse Trading Analytics",
    page_icon="ðŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)


# ============================================================================
# HELPER FUNCTIONS
# ============================================================================

def check_admin_password():
    """Verify admin password for all-time access."""
    if "admin_authenticated" not in st.session_state:
        st.session_state.admin_authenticated = False
    
    if not st.session_state.admin_authenticated:
        with st.sidebar.expander("ðŸ” Admin Access"):
            password = st.text_input("Password", type="password")
            if st.button("Authenticate"):
                if password == ADMIN_PASSWORD:
                    st.session_state.admin_authenticated = True
                    st.success("âœ… Admin access granted")
                    st.rerun()
                else:
                    st.error("âŒ Invalid password")
    
    return st.session_state.admin_authenticated


def mask_trader_id(trader_id):
    """Format trader wallet address for privacy."""
    if pd.isna(trader_id):
        return "Unknown"
    s = str(trader_id)
    return f"{s[:4]}..{s[-4:]}" if len(s) > 8 else s


def simplify_symbol(market_id):
    """Extract base symbol from market identifier."""
    if pd.isna(market_id):
        return market_id
    s = str(market_id)
    return s.split('/')[0].split('-')[0]


def get_top_traders(positions_df, n=5, by='profit'):
    """Get top N traders by specified criteria."""
    if positions_df.empty:
        return []
    
    trader_stats = positions_df.groupby('trader_id')['realized_pnl'].agg(['sum', 'count'])
    
    if by == 'profit':
        return trader_stats.nlargest(n, 'sum').index.tolist()
    elif by == 'loss':
        return trader_stats.nsmallest(n, 'sum').index.tolist()
    else:
        return trader_stats.nlargest(n, 'count').index.tolist()


def load_trader_notes(trader_id):
    """Load trade notes from JSON file for specific trader."""
    notes_dir = Path("data/trader_notes")
    notes_dir.mkdir(parents=True, exist_ok=True)
    
    notes_file = notes_dir / f"{trader_id}.json"
    
    if notes_file.exists():
        with open(notes_file, 'r') as f:
            return json.load(f)
    return {}


def save_trader_notes(trader_id, notes):
    """Save trade notes to JSON file for specific trader."""
    notes_dir = Path("data/trader_notes")
    notes_dir.mkdir(parents=True, exist_ok=True)
    
    notes_file = notes_dir / f"{trader_id}.json"
    
    with open(notes_file, 'w') as f:
        json.dump(notes, f, indent=2)


def get_trade_density(filtered_positions):
    """Classify data density for adaptive visualization selection."""
    trade_count = len(filtered_positions)
    
    if trade_count == 0:
        return "empty"
    elif trade_count == 1:
        return "single"
    elif trade_count < 5:
        return "sparse"
    elif trade_count < 15:
        return "moderate"
    else:
        return "dense"


def calculate_volume_usd(df):
    """Calculate USD volume from price and size."""
    df = df.copy()
    df['volume_usd'] = df['exit_price'] * df['size']
    return df


# ============================================================================
# STYLING & CSS
# ============================================================================

st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:wght@400;600&family=Inter:wght@300;400;600;700&display=swap');
    
    :root {
        --primary-color: #6366f1;
        --secondary-color: #8b5cf6;
        --success-color: #10b981;
        --danger-color: #ef4444;
        --warning-color: #f59e0b;
        --bg-dark: #0f172a;
        --bg-card: #1e293b;
        --text-primary: #f1f5f9;
        --text-secondary: #94a3b8;
    }
    
    .main {
        background: linear-gradient(135deg, #0f172a 0%, #1e293b 100%);
        font-family: 'Inter', sans-serif;
    }
    
    .fixed-header-container {
        position: sticky;
        top: 0;
        background: linear-gradient(135deg, #0f172a 0%, #1e293b 100%);
        z-index: 1000;
        padding: 15px 20px 10px 20px;
        border-bottom: 2px solid rgba(99, 102, 241, 0.3);
        margin-bottom: 20px;
        width: 100%;
        box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
    }
    
    .header-title {
        font-family: 'IBM Plex Mono', monospace;
        font-size: 2rem;
        font-weight: 700;
        color: #f1f5f9;
        margin: 0;
        padding: 0;
        letter-spacing: -0.02em;
    }
    
    .header-subtitle {
        color: #94a3b8;
        font-size: 0.9rem;
        margin-top: 4px;
    }
    
    .nav-bar {
        display: flex;
        gap: 8px;
        margin-top: 15px;
        flex-wrap: wrap;
    }
    
    .nav-item {
        padding: 8px 16px;
        border-radius: 8px;
        background: rgba(30, 41, 59, 0.6);
        color: #94a3b8;
        font-weight: 500;
        cursor: pointer;
        transition: all 0.2s ease;
        border: 1px solid rgba(99, 102, 241, 0.1);
        text-align: center;
        flex: 1;
        min-width: 80px;
    }
    
    .nav-item:hover {
        background: rgba(99, 102, 241, 0.2);
        color: #f1f5f9;
        border-color: #6366f1;
        transform: translateY(-2px);
    }
    
    .nav-item-active {
        background: linear-gradient(135deg, #6366f1, #8b5cf6);
        color: white;
        border: none;
        box-shadow: 0 4px 6px -1px rgba(99, 102, 241, 0.3);
    }
    
    .nav-item-active:hover {
        background: linear-gradient(135deg, #4f46e5, #7c3aed);
        color: white;
    }
    
    .profile-badge {
        background: linear-gradient(135deg, #10b981, #059669);
        color: white;
        padding: 6px 14px;
        border-radius: 20px;
        font-weight: 600;
        font-size: 0.9rem;
        display: inline-block;
        margin: 10px 0 5px 0;
        border: 1px solid rgba(255, 255, 255, 0.1);
    }
    
    .section-header {
        position: sticky;
        top: 180px;
        background: linear-gradient(135deg, #0f172a 0%, #1e293b 100%);
        z-index: 998;
        padding: 10px 0;
        border-bottom: 1px solid rgba(99, 102, 241, 0.1);
        margin-bottom: 15px;
    }
    
    h1, h2, h3 {
        font-family: 'IBM Plex Mono', monospace;
        font-weight: 600;
        color: var(--text-primary);
        letter-spacing: -0.02em;
    }
    
    .stMetric {
        background: linear-gradient(135deg, var(--bg-card) 0%, #334155 100%);
        padding: 20px;
        border-radius: 12px;
        border: 1px solid rgba(99, 102, 241, 0.1);
        box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
        transition: all 0.3s ease;
    }
    
    .stMetric:hover {
        transform: translateY(-2px);
        box-shadow: 0 8px 12px -1px rgba(99, 102, 241, 0.2);
        border-color: rgba(99, 102, 241, 0.3);
    }
    
    .stMetric label {
        color: var(--text-secondary);
        font-size: 0.875rem;
        font-weight: 500;
        text-transform: uppercase;
        letter-spacing: 0.05em;
    }
    
    .stMetric [data-testid="stMetricValue"] {
        font-family: 'IBM Plex Mono', monospace;
        font-size: 1.875rem;
        font-weight: 700;
        color: var(--text-primary);
    }
    
    .stButton>button {
        background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));
        color: white;
        border: none;
        border-radius: 8px;
        padding: 0.75rem 1.5rem;
        font-weight: 600;
        transition: all 0.3s ease;
        box-shadow: 0 2px 4px rgba(99, 102, 241, 0.2);
    }
    
    .stButton>button:hover {
        transform: translateY(-1px);
        box-shadow: 0 4px 8px rgba(99, 102, 241, 0.3);
    }
    
    [data-testid="stSidebar"] {
        background: var(--bg-card);
        border-right: 1px solid rgba(99, 102, 241, 0.1);
    }
    
    .status-live {
        display: inline-block;
        width: 8px;
        height: 8px;
        background: var(--success-color);
        border-radius: 50%;
        animation: pulse 2s infinite;
    }
    
    @keyframes pulse {
        0%, 100% { opacity: 1; }
        50% { opacity: 0.5; }
    }
    
    .greeks-metric {
        background: rgba(30, 41, 59, 0.4);
        padding: 12px 16px;
        border-radius: 8px;
        border: 1px solid rgba(100, 116, 139, 0.2);
        text-align: center;
    }
    
    .greeks-metric-label {
        color: #94a3b8;
        font-size: 0.75rem;
        font-weight: 500;
        text-transform: uppercase;
        letter-spacing: 0.05em;
        margin-bottom: 4px;
    }
    
    .greeks-metric-value {
        color: #e2e8f0;
        font-size: 1.5rem;
        font-weight: 600;
        font-family: 'IBM Plex Mono', monospace;
    }
    
    .greeks-metric-help {
        color: #64748b;
        font-size: 0.7rem;
        margin-top: 4px;
    }
    
    .progress-bar-container {
        background: rgba(30, 41, 59, 0.4);
        border-radius: 8px;
        padding: 12px;
        margin-bottom: 8px;
    }
    
    .progress-bar-label {
        color: #94a3b8;
        font-size: 0.875rem;
        font-weight: 500;
        margin-bottom: 6px;
    }
    
    .progress-bar-value {
        color: #f1f5f9;
        font-size: 1rem;
        font-weight: 600;
        font-family: 'IBM Plex Mono', monospace;
    }
    
    .coming-soon {
        background: rgba(245, 158, 11, 0.1);
        border: 1px dashed #f59e0b;
        border-radius: 8px;
        padding: 20px;
        text-align: center;
        color: #f59e0b;
        font-weight: 600;
    }
    
    .note-instruction {
        background: rgba(99, 102, 241, 0.1);
        border-left: 4px solid var(--primary-color);
        padding: 12px 16px;
        border-radius: 8px;
        margin-bottom: 16px;
        color: #e2e8f0;
        font-size: 0.95rem;
    }
    
    .note-instruction code {
        background: #1e293b;
        padding: 4px 8px;
        border-radius: 4px;
        color: var(--primary-color);
    }
    </style>
""", unsafe_allow_html=True)


# ============================================================================
# DATA LOADING
# ============================================================================

@st.cache_data
def load_logo(url):
    """Load Deriverse logo with error handling."""
    try:
        response = requests.get(url, timeout=5)
        if response.status_code == 200:
            return response.content
        return None
    except Exception:
        return None


@st.cache_data
def load_data():
    """Load analytics data with error handling."""
    try:
        return {
            'equity': pd.read_csv(DATA_DIR / "equity_curve.csv", parse_dates=["timestamp"]),
            'positions': pd.read_csv(DATA_DIR / "positions.csv", parse_dates=["open_time", "close_time"]),
            'summary': pd.read_csv(DATA_DIR / "summary_metrics.csv"),
            'fees': pd.read_csv(DATA_DIR / "fees_breakdown.csv"),
            'volume': pd.read_csv(DATA_DIR / "volume_by_market.csv"),
            'pnl_day': pd.read_csv(DATA_DIR / "pnl_by_day.csv", parse_dates=["date"]),
            'pnl_hour': pd.read_csv(DATA_DIR / "pnl_by_hour.csv"),
            'directional': pd.read_csv(DATA_DIR / "directional_bias.csv"),
            'order_perf': pd.read_csv(DATA_DIR / "order_type_performance.csv"),
            'greeks': pd.read_csv(DATA_DIR / "greeks_exposure.csv"),
            'open_positions': pd.read_csv(DATA_DIR / "open_positions.csv", parse_dates=["open_time"])
        }
    except FileNotFoundError as e:
        st.error(f"âŒ Data files not found: {e}")
        return None


# ============================================================================
# ADAPTIVE CHART FUNCTIONS
# ============================================================================

def create_clean_equity_chart(equity_df, positions_df, authenticated_trader=None):
    """Create clean equity chart with PnL on top, drawdown below."""
    
    fig = make_subplots(
        rows=2, cols=1,
        subplot_titles=("ðŸ“ˆ Cumulative PnL by Trader", "ðŸ“‰ Drawdown Analysis"),
        vertical_spacing=0.12,
        row_heights=[0.7, 0.3]
    )
    
    colors = px.colors.qualitative.Set2
    
    traders_to_show = equity_df['trader_id'].unique()
    if not authenticated_trader and len(traders_to_show) > 5:
        top_traders = get_top_traders(positions_df, n=5, by='activity')
        equity_df = equity_df[equity_df['trader_id'].isin(top_traders)]
        traders_to_show = equity_df['trader_id'].unique()
    
    for i, trader in enumerate(traders_to_show):
        trader_data = equity_df[equity_df['trader_id'] == trader].sort_values('timestamp')
        
        if authenticated_trader and trader == authenticated_trader:
            display_name = f"{trader[:8]}...{trader[-8:]}"
        else:
            display_name = mask_trader_id(trader)
        
        fig.add_trace(
            go.Scatter(
                x=trader_data['timestamp'],
                y=trader_data['cumulative_pnl'],
                name=display_name,
                line=dict(width=2, color=colors[i % len(colors)]),
                legendgroup=f"trader_{i}",
                hovertemplate="<b>%{fullData.name}</b><br>" +
                            "Date: %{x}<br>" +
                            "PnL: $%{y:,.2f}<br>" +
                            "<extra></extra>"
            ),
            row=1, col=1
        )
    
    for i, trader in enumerate(traders_to_show):
        trader_data = equity_df[equity_df['trader_id'] == trader].sort_values('timestamp')
        
        fig.add_trace(
            go.Scatter(
                x=trader_data['timestamp'],
                y=trader_data['drawdown'],
                name=f"DD",
                line=dict(width=1.5, dash='dot', color=colors[i % len(colors)]),
                legendgroup=f"trader_{i}",
                showlegend=False,
                hovertemplate="<b>Drawdown</b><br>" +
                            "Date: %{x}<br>" +
                            "Drawdown: $%{y:,.2f}<br>" +
                            "<extra></extra>"
            ),
            row=2, col=1
        )
    
    all_drawdowns = equity_df['drawdown'].min()
    fig.add_hline(
        y=all_drawdowns, 
        line_dash="dash", 
        line_color="red",
        annotation_text=f"Max System Drawdown: ${all_drawdowns:,.0f}",
        annotation_position="bottom right",
        row=2, col=1
    )
    
    fig.update_layout(
        height=600,
        hovermode='x unified',
        template='plotly_dark',
        plot_bgcolor='rgba(15, 23, 42, 0.9)',
        paper_bgcolor='rgba(15, 23, 42, 0.9)',
        legend=dict(
            title="Traders",
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1
        )
    )
    
    fig.update_xaxes(title_text="", row=1, col=1)
    fig.update_xaxes(title_text="Date", row=2, col=1)
    fig.update_yaxes(title_text="Cumulative PnL ($)", row=1, col=1)
    fig.update_yaxes(title_text="Drawdown ($)", row=2, col=1)
    
    return fig


def create_trader_focus_chart(equity_df, positions_df, trader_id):
    """Create detailed view for a single trader."""
    
    trader_equity = equity_df[equity_df['trader_id'] == trader_id].sort_values('timestamp')
    trader_positions = positions_df[positions_df['trader_id'] == trader_id]
    
    fig = make_subplots(
        rows=3, cols=1,
        subplot_titles=(
            f"Cumulative PnL - {mask_trader_id(trader_id)}",
            "Daily Returns",
            "Drawdown from Peak"
        ),
        vertical_spacing=0.1,
        row_heights=[0.5, 0.25, 0.25]
    )
    
    fig.add_trace(
        go.Scatter(
            x=trader_equity['timestamp'],
            y=trader_equity['cumulative_pnl'],
            name="Equity",
            line=dict(color='#6366f1', width=3),
            fill='tozeroy',
            fillcolor='rgba(99, 102, 241, 0.1)'
        ),
        row=1, col=1
    )
    
    wins = trader_positions[trader_positions['realized_pnl'] > 0]
    if not wins.empty:
        fig.add_trace(
            go.Scatter(
                x=wins['close_time'],
                y=[trader_equity[trader_equity['timestamp'] == t]['cumulative_pnl'].iloc[0] 
                   if any(trader_equity['timestamp'] == t) else None 
                   for t in wins['close_time']],
                mode='markers',
                name='Wins',
                marker=dict(color='#10b981', size=8, symbol='triangle-up')
            ),
            row=1, col=1
        )
    
    losses = trader_positions[trader_positions['realized_pnl'] < 0]
    if not losses.empty:
        fig.add_trace(
            go.Scatter(
                x=losses['close_time'],
                y=[trader_equity[trader_equity['timestamp'] == t]['cumulative_pnl'].iloc[0] 
                   if any(trader_equity['timestamp'] == t) else None 
                   for t in losses['close_time']],
                mode='markers',
                name='Losses',
                marker=dict(color='#ef4444', size=8, symbol='triangle-down')
            ),
            row=1, col=1
        )
    
    daily = trader_positions.groupby(
        trader_positions['close_time'].dt.date
    )['realized_pnl'].sum().reset_index()
    
    colors = ['#10b981' if x > 0 else '#ef4444' for x in daily['realized_pnl']]
    
    fig.add_trace(
        go.Bar(
            x=daily['close_time'],
            y=daily['realized_pnl'],
            marker_color=colors,
            showlegend=False
        ),
        row=2, col=1
    )
    
    fig.add_trace(
        go.Scatter(
            x=trader_equity['timestamp'],
            y=trader_equity['drawdown'],
            name='Drawdown',
            line=dict(color='#ef4444', width=2),
            fill='tozeroy',
            fillcolor='rgba(239, 68, 68, 0.1)'
        ),
        row=3, col=1
    )
    
    max_dd = trader_equity['drawdown'].min()
    fig.add_hline(
        y=max_dd,
        line_dash="dash",
        line_color="#ef4444",
        annotation_text=f"Max DD: ${max_dd:,.0f}",
        row=3, col=1
    )
    
    fig.update_layout(
        height=800,
        hovermode='x unified',
        template='plotly_dark',
        plot_bgcolor='rgba(15, 23, 42, 0.9)',
        paper_bgcolor='rgba(15, 23, 42, 0.9)',
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1
        )
    )
    
    return fig


def create_trader_summary_table(equity_df, positions_df):
    """Create summary table with mini sparklines."""
    
    st.markdown("### ðŸ“‹ Trader Performance Summary")
    
    traders = []
    for trader in equity_df['trader_id'].unique()[:10]:
        trader_equity = equity_df[equity_df['trader_id'] == trader].sort_values('timestamp')
        trader_positions = positions_df[positions_df['trader_id'] == trader]
        
        total_pnl = trader_positions['realized_pnl'].sum()
        win_rate = (trader_positions['realized_pnl'] > 0).mean() * 100
        max_dd = trader_equity['drawdown'].min()
        trades = len(trader_positions)
        
        sparkline = trader_equity['cumulative_pnl'].values
        if len(sparkline) > 1:
            normalized = (sparkline - sparkline.min()) / (sparkline.max() - sparkline.min() + 1)
        else:
            normalized = [0.5]
        
        traders.append({
            'trader': mask_trader_id(trader),
            'pnl': total_pnl,
            'win_rate': win_rate,
            'max_dd': max_dd,
            'trades': trades,
            'sparkline': normalized[-20:],
            'trend': 'ðŸ“ˆ' if total_pnl > 0 and len(sparkline) > 1 and sparkline[-1] > sparkline[0] else 'ðŸ“‰'
        })
    
    traders.sort(key=lambda x: x['pnl'], reverse=True)
    
    cols = st.columns([1.2, 1.5, 1, 1, 1, 2])
    cols[0].markdown("**Trader**")
    cols[1].markdown("**Equity Trend**")
    cols[2].markdown("**PnL**")
    cols[3].markdown("**Win Rate**")
    cols[4].markdown("**Max DD**")
    cols[5].markdown("**Activity**")
    
    st.divider()
    
    for i, t in enumerate(traders):
        cols = st.columns([1.2, 1.5, 1, 1, 1, 2])
        
        cols[0].markdown(f"`{t['trader']}`")
        
        fig = go.Figure()
        fig.add_trace(go.Scatter(
            y=t['sparkline'],
            mode='lines',
            line=dict(color='#10b981' if t['pnl'] > 0 else '#ef4444', width=2),
            showlegend=False
        ))
        fig.update_layout(
            height=40,
            margin=dict(l=0, r=0, t=0, b=0),
            xaxis=dict(showticklabels=False, showgrid=False),
            yaxis=dict(showticklabels=False, showgrid=False),
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)'
        )
        
        cols[1].plotly_chart(
            fig, 
            width='stretch',
            config={'displayModeBar': False},
            key=f"sparkline_{i}"
        )
        
        pnl_color = "#10b981" if t['pnl'] > 0 else "#ef4444"
        cols[2].markdown(f"<span style='color:{pnl_color};font-weight:600;'>${t['pnl']:,.0f}</span>", unsafe_allow_html=True)
        cols[3].markdown(f"{t['win_rate']:.0f}%")
        cols[4].markdown(f"${abs(t['max_dd']):,.0f}")
        cols[5].markdown(f"{t['trades']} trades {t['trend']}")


def display_equity_section(equity_df, positions_df, authenticated_trader=None):
    """Complete equity analysis section with tabs."""
    
    st.markdown('<div class="section-header">', unsafe_allow_html=True)
    st.header("ðŸ“ˆ Performance Analysis")
    st.markdown('</div>', unsafe_allow_html=True)
    
    tab1, tab2, tab3 = st.tabs([
        "ðŸ“Š Overview Comparison", 
        "ðŸ‘¤ Individual Analysis", 
        "ðŸ“‹ Summary Table"
    ])
    
    with tab1:
        st.subheader("Multi-Trader Performance")
        st.caption("Top panel: Cumulative PnL | Bottom panel: Drawdown")
        
        fig = create_clean_equity_chart(equity_df, positions_df, authenticated_trader)
        st.plotly_chart(fig, width='stretch')
        
        col1, col2 = st.columns(2)
        with col1:
            if not equity_df.empty:
                best_trader = equity_df.groupby('trader_id')['cumulative_pnl'].last().idxmax()
                best_pnl = equity_df.groupby('trader_id')['cumulative_pnl'].last().max()
                st.info(f"ðŸ† **Best Performer:** {mask_trader_id(best_trader)} (${best_pnl:,.2f})")
        
        with col2:
            if not equity_df.empty:
                worst_dd_trader = equity_df.groupby('trader_id')['drawdown'].min().idxmin()
                worst_dd = equity_df.groupby('trader_id')['drawdown'].min().min()
                st.warning(f"âš ï¸ **Highest Risk:** {mask_trader_id(worst_dd_trader)} (Max DD: ${worst_dd:,.2f})")
    
    with tab2:
        if authenticated_trader:
            fig = create_trader_focus_chart(equity_df, positions_df, authenticated_trader)
            st.plotly_chart(fig, width='stretch')
        else:
            traders = equity_df['trader_id'].unique()
            selected = st.selectbox(
                "Select Trader to Analyze",
                traders,
                format_func=mask_trader_id
            )
            if selected:
                fig = create_trader_focus_chart(equity_df, positions_df, selected)
                st.plotly_chart(fig, width='stretch')
    
    with tab3:
        create_trader_summary_table(equity_df, positions_df)


def display_liquidation_analytics(positions_df):
    """Complete liquidation analysis with risk dashboard."""
    
    st.markdown('<div class="section-header">', unsafe_allow_html=True)
    st.header("âš ï¸ Liquidation Risk Monitoring")
    st.markdown('</div>', unsafe_allow_html=True)
    
    if 'close_reason' not in positions_df.columns:
        st.info("â„¹ï¸ Liquidation tracking not available for this data")
        return
    
    liquidations = positions_df[positions_df['close_reason'] == 'liquidation'].copy()
    
    if liquidations.empty:
        st.success("âœ… No liquidations in selected period - clean trading!")
        return
    
    col1, col2, col3 = st.columns(3)
    
    total_liq = len(liquidations)
    unique_traders = liquidations['trader_id'].nunique()
    total_liq_loss = liquidations['realized_pnl'].sum()
    
    with col1:
        st.metric("Total Liquidations", total_liq)
    with col2:
        st.metric("Affected Traders", unique_traders)
    with col3:
        st.metric("Total Loss", f"${abs(total_liq_loss):,.0f}")
    
    st.subheader("ðŸ“Š Liquidation Rate by Trader")
    st.caption("Shows % of trades that ended in liquidation - lower is better")
    
    trader_stats = []
    for trader in positions_df['trader_id'].unique():
        trader_trades = positions_df[positions_df['trader_id'] == trader]
        trader_liq = len(trader_trades[trader_trades['close_reason'] == 'liquidation'])
        total_closed = len(trader_trades[trader_trades['close_reason'].isin(['closed', 'liquidation'])])
        
        if total_closed > 0:
            liq_rate = (trader_liq / total_closed) * 100
            trader_stats.append({
                'trader': mask_trader_id(trader),
                'liq_rate': liq_rate,
                'liq_count': trader_liq,
                'total_trades': total_closed
            })
    
    if trader_stats:
        df = pd.DataFrame(trader_stats).sort_values('liq_rate', ascending=False)
        
        colors = ['#10b981' if x < 2 else '#f59e0b' if x < 5 else '#ef4444' 
                  for x in df['liq_rate']]
        
        fig = go.Figure()
        fig.add_trace(go.Bar(
            x=df['trader'],
            y=df['liq_rate'],
            marker_color=colors,
            text=[f"{rate:.1f}%<br>({liq}/{total})" 
                  for rate, liq, total in zip(df['liq_rate'], df['liq_count'], df['total_trades'])],
            textposition='outside'
        ))
        
        fig.add_hline(y=2, line_dash="dash", line_color="#10b981", 
                      annotation_text="Low Risk", annotation_position="bottom right")
        fig.add_hline(y=5, line_dash="dash", line_color="#f59e0b",
                      annotation_text="Medium Risk", annotation_position="bottom right")
        
        fig.update_layout(
            height=400,
            xaxis_title="Trader",
            yaxis_title="Liquidation Rate (%)",
            template='plotly_dark',
            plot_bgcolor='rgba(15, 23, 42, 0.9)',
            paper_bgcolor='rgba(15, 23, 42, 0.9)'
        )
        fig.update_xaxes(tickangle=-45)
        st.plotly_chart(fig, width='stretch', key="liquidation_rate_chart")
    
    st.subheader("ðŸ’° Financial Impact Analysis")
    
    col1, col2 = st.columns(2)
    
    with col1:
        liq_by_market = liquidations.groupby('market_id')['realized_pnl'].sum().abs().reset_index()
        liq_by_market['symbol'] = liq_by_market['market_id'].apply(simplify_symbol)
        liq_by_market = liq_by_market.sort_values('realized_pnl', ascending=False).head(5)
        
        fig = px.bar(
            liq_by_market,
            x='symbol',
            y='realized_pnl',
            title='Top 5 Markets by Liquidation Loss',
            color='realized_pnl',
            color_continuous_scale='Reds'
        )
        fig.update_layout(height=300, template='plotly_dark')
        st.plotly_chart(fig, width='stretch', key="liquidation_by_market")
    
    with col2:
        liq_by_trader = liquidations.groupby('trader_id')['realized_pnl'].sum().abs().reset_index()
        liq_by_trader['trader'] = liq_by_trader['trader_id'].apply(mask_trader_id)
        liq_by_trader = liq_by_trader.sort_values('realized_pnl', ascending=False).head(5)
        
        fig = px.bar(
            liq_by_trader,
            x='trader',
            y='realized_pnl',
            title='Top 5 Traders by Liquidation Loss',
            color='realized_pnl',
            color_continuous_scale='Reds'
        )
        fig.update_layout(height=300, template='plotly_dark')
        st.plotly_chart(fig, width='stretch', key="liquidation_by_trader")
    
    with st.expander("ðŸ” Pattern Analysis"):
        
        col1, col2 = st.columns(2)
        
        with col1:
            liquidations['hour'] = pd.to_datetime(liquidations['close_time']).dt.hour
            liq_by_hour = liquidations.groupby('hour').size().reset_index(name='count')
            
            fig = px.line(
                liq_by_hour,
                x='hour',
                y='count',
                title='Liquidations by Hour of Day',
                markers=True
            )
            fig.update_layout(height=300, template='plotly_dark')
            st.plotly_chart(fig, width='stretch', key="liquidation_by_hour")
        
        with col2:
            top_market = liquidations['market_id'].mode()
            if not top_market.empty:
                st.info(f"ðŸ”¥ **Riskiest Market:** {simplify_symbol(top_market.iloc[0])}")
            
            liq_hours = pd.to_datetime(liquidations['close_time']).dt.hour
            top_hour = liq_hours.mode()
            if not top_hour.empty:
                st.info(f"â° **Riskiest Hour:** {top_hour.iloc[0]}:00 UTC")
            
            avg_loss = liquidations['realized_pnl'].mean()
            st.metric("Average Loss per Liquidation", f"${abs(avg_loss):,.2f}")
            
            with st.expander("ðŸ“‹ Liquidation History"):
                liq_display = liquidations[['close_time', 'trader_id', 'market_id', 'side', 
                                           'size', 'exit_price', 'realized_pnl', 'fees']].copy()
                liq_display['trader'] = liq_display['trader_id'].apply(mask_trader_id)
                liq_display['symbol'] = liq_display['market_id'].apply(simplify_symbol)
                liq_display = liq_display.sort_values('close_time', ascending=False)
                
                st.dataframe(
                    liq_display[['close_time', 'trader', 'symbol', 'side', 
                                'size', 'exit_price', 'realized_pnl', 'fees']].style.format({
                        'close_time': lambda x: x.strftime('%Y-%m-%d %H:%M'),
                        'size': '{:.4f}',
                        'exit_price': '${:.2f}',
                        'realized_pnl': '${:.2f}',
                        'fees': '${:.2f}'
                    }).map(
                        lambda x: 'color: #ef4444; font-weight: bold',
                        subset=['realized_pnl']
                    ),
                    width='stretch',
                    hide_index=True,
                    column_config={
                        "close_time": "Time",
                        "trader": "Trader",
                        "symbol": "Symbol",
                        "side": "Side",
                        "size": "Size",
                        "exit_price": "Price",
                        "realized_pnl": "Loss",
                        "fees": "Fees"
                    }
                )


def display_order_type_performance(order_perf_df, positions_df):
    """Order type chart with proper classification."""
    
    st.markdown('<div class="section-header">', unsafe_allow_html=True)
    st.header("ðŸ“Š Order Type Performance")
    st.markdown('</div>', unsafe_allow_html=True)
    
    if positions_df.empty:
        st.info("No trade data available")
        return
    
    df = positions_df.copy()
    
    if 'order_type' in df.columns and not df['order_type'].isna().all():
        order_types = df['order_type'].value_counts()
        st.caption(f"ðŸ“Š Based on {len(order_types)} order types from trade data")
    else:
        df['order_type'] = df.apply(lambda row: 
            f"{row['product_type']}" if row['product_type'] in ['option'] else
            f"{row['product_type']}_market" if row['duration_seconds'] < 300 else
            f"{row['product_type']}_limit" if row['duration_seconds'] < 3600 else
            f"{row['product_type']}_stop",
            axis=1
        )
        st.caption("ðŸ“Š Order types derived from product type and duration")
    
    result = []
    for order_type, group in df.groupby('order_type'):
        trade_count = len(group)
        if trade_count > 0:
            result.append({
                'order_type': order_type,
                'trade_count': trade_count,
                'avg_pnl': group['realized_pnl'].mean(),
                'win_rate': (group['realized_pnl'] > 0).mean(),
                'total_pnl': group['realized_pnl'].sum()
            })
    
    if not result:
        st.warning("Insufficient data for order type analysis")
        return
    
    order_df = pd.DataFrame(result)
    order_df = order_df.sort_values('trade_count', ascending=False)
    
    fig = make_subplots(specs=[[{"secondary_y": True}]])
    
    fig.add_trace(
        go.Bar(
            x=order_df['order_type'],
            y=order_df['win_rate'] * 100,
            name='Win Rate',
            marker_color='#6366f1',
            text=[f"{w:.1f}%" for w in order_df['win_rate'] * 100],
            textposition='inside',
            textfont=dict(color='white'),
            hovertemplate='<b>%{x}</b><br>Win Rate: %{y:.1f}%<br>Trades: %{customdata}<extra></extra>',
            customdata=order_df['trade_count']
        ),
        secondary_y=False,
    )
    
    colors = ['#10b981' if x > 0 else '#ef4444' for x in order_df['avg_pnl']]
    
    fig.add_trace(
        go.Scatter(
            x=order_df['order_type'],
            y=order_df['avg_pnl'],
            name='Avg PnL',
            mode='lines+markers',
            line=dict(color='#f1f5f9', width=3),
            marker=dict(size=10, color=colors),
            text=[f"${x:,.0f}" for x in order_df['avg_pnl']],
            textposition='top center',
            hovertemplate='<b>%{x}</b><br>Avg PnL: $%{y:,.2f}<extra></extra>'
        ),
        secondary_y=True,
    )
    
    fig.update_layout(
        title="Order Type Performance: Win Rate vs Average PnL",
        xaxis_title="Order Type",
        hovermode='x unified',
        height=500,
        template='plotly_dark',
        plot_bgcolor='rgba(15, 23, 42, 0.9)',
        paper_bgcolor='rgba(15, 23, 42, 0.9)',
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1
        )
    )
    
    fig.update_yaxes(title_text="Win Rate (%)", secondary_y=False, range=[0, 100])
    fig.update_yaxes(title_text="Average PnL ($)", secondary_y=True)
    fig.add_hline(y=0, line_dash="dash", line_color="gray", opacity=0.5, secondary_y=True)
    
    st.plotly_chart(fig, width='stretch')
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        best_win = order_df.loc[order_df['win_rate'].idxmax()]
        st.metric(
            "ðŸ† Best Win Rate",
            f"{best_win['win_rate']*100:.1f}%",
            f"{best_win['order_type']}"
        )
    
    with col2:
        best_pnl = order_df.loc[order_df['avg_pnl'].idxmax()]
        st.metric(
            "ðŸ’° Best Avg PnL",
            f"${best_pnl['avg_pnl']:,.2f}",
            f"{best_pnl['order_type']}"
        )
    
    with col3:
        most_used = order_df.loc[order_df['trade_count'].idxmax()]
        st.metric(
            "ðŸ“Š Most Used",
            f"{most_used['trade_count']} trades",
            f"{most_used['order_type']}"
        )


def display_volume_analysis(positions_df):
    """Volume analysis with product tabs and progress bars."""
    
    st.markdown('<div class="section-header">', unsafe_allow_html=True)
    st.header("ðŸ“Š Trading Volume Analysis")
    st.markdown('</div>', unsafe_allow_html=True)
    
    if positions_df.empty:
        st.info("No volume data available")
        return
    
    positions_df = calculate_volume_usd(positions_df)
    
    col1, col2, col3, col4 = st.columns(4)
    
    total_volume = positions_df['volume_usd'].sum()
    total_fees = positions_df['fees'].sum()
    unique_symbols = positions_df['market_id'].apply(simplify_symbol).nunique()
    
    symbol_vol = positions_df.groupby(positions_df['market_id'].apply(simplify_symbol))['volume_usd'].sum()
    vol_shares = symbol_vol / total_volume if total_volume > 0 else pd.Series([0])
    hhi = (vol_shares ** 2).sum() * 10000
    
    with col1:
        st.metric("Total Volume", f"${total_volume:,.0f}")
    with col2:
        st.metric("Total Fees", f"${total_fees:,.0f}")
    with col3:
        st.metric("Active Symbols", unique_symbols)
    with col4:
        concentration = "Low" if hhi < 1500 else "Medium" if hhi < 2500 else "High"
        st.metric("Concentration", f"{hhi:.0f} ({concentration})")
    
    product_tabs = st.tabs(["ðŸ“ˆ All Products", "ðŸ“ Spot", "âš¡ Perpetual", "ðŸŽ¯ Options"])
    
    products = {
        "ðŸ“ˆ All Products": positions_df,
        "ðŸ“ Spot": positions_df[positions_df['product_type'] == 'spot'],
        "âš¡ Perpetual": positions_df[positions_df['product_type'] == 'perp'],
        "ðŸŽ¯ Options": positions_df[positions_df['product_type'] == 'option']
    }
    
    for tab_idx, (tab, (tab_name, product_df)) in enumerate(zip(product_tabs, products.items())):
        with tab:
            if product_df.empty:
                st.info(f"No {tab_name} trades in selected period")
                continue
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown(f"#### Volume by Symbol - Top 5")
                
                symbol_vol = product_df.groupby(product_df['market_id'].apply(simplify_symbol)).agg({
                    'volume_usd': 'sum',
                    'realized_pnl': 'sum',
                    'fees': 'sum'
                }).sort_values('volume_usd', ascending=False).head(5)
                
                total = symbol_vol['volume_usd'].sum()
                
                for symbol, row in symbol_vol.iterrows():
                    pct = (row['volume_usd'] / total * 100) if total > 0 else 0
                    pnl_color = "#10b981" if row['realized_pnl'] > 0 else "#ef4444"
                    
                    st.markdown(f"""
                    <div class='progress-bar-container'>
                        <div style='display: flex; justify-content: space-between; margin-bottom: 6px;'>
                            <span class='progress-bar-label'>{symbol}</span>
                            <span class='progress-bar-value'>
                                ${row['volume_usd']:,.0f} ({pct:.1f}%) 
                                <span style='color:{pnl_color};'>${row['realized_pnl']:,.0f}</span>
                            </span>
                        </div>
                        <div style='background: rgba(100, 116, 139, 0.3); border-radius: 4px; height: 8px;'>
                            <div style='
                                background: #6366f1;
                                width: {pct}%;
                                height: 100%;
                                border-radius: 4px;
                                transition: width 0.3s ease;
                            '></div>
                        </div>
                    </div>
                    """, unsafe_allow_html=True)
                
                st.markdown("#### Fee Generation")
                fee_by_symbol = product_df.groupby(product_df['market_id'].apply(simplify_symbol))['fees'].sum().sort_values(ascending=False).head(5)
                
                fig = px.bar(
                    x=fee_by_symbol.values,
                    y=fee_by_symbol.index,
                    orientation='h',
                    title='Top 5 Symbols by Fees',
                    color=fee_by_symbol.values,
                    color_continuous_scale='Reds'
                )
                fig.update_layout(height=250, template='plotly_dark')
                st.plotly_chart(fig, width='stretch', key=f"fee_chart_{tab_idx}")
            
            with col2:
                st.markdown(f"#### Long vs Short Distribution")
                
                if tab_name == "ðŸŽ¯ Options" and 'option_type' in product_df.columns:
                    calls = product_df[product_df['option_type'] == 'call']['volume_usd'].sum()
                    puts = product_df[product_df['option_type'] == 'put']['volume_usd'].sum()
                    
                    fig = go.Figure(data=[go.Pie(
                        labels=['Calls', 'Puts'],
                        values=[calls, puts],
                        hole=0.4,
                        marker_colors=['#10b981', '#f59e0b']
                    )])
                    fig.update_layout(height=300, template='plotly_dark')
                    st.plotly_chart(fig, width='stretch', key=f"options_pie_{tab_idx}")
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        avg_premium = product_df['exit_price'].mean()
                        st.metric("Avg Premium", f"${avg_premium:,.2f}")
                    with col2:
                        total_options = len(product_df)
                        st.metric("Option Trades", total_options)
                
                else:
                    long_vol = product_df[product_df['side'].isin(['long', 'buy'])]['volume_usd'].sum()
                    short_vol = product_df[product_df['side'].isin(['short', 'sell'])]['volume_usd'].sum()
                    
                    fig = go.Figure(data=[go.Pie(
                        labels=['Long', 'Short'],
                        values=[long_vol, short_vol],
                        hole=0.4,
                        marker_colors=['#10b981', '#ef4444']
                    )])
                    fig.update_layout(height=300, template='plotly_dark')
                    st.plotly_chart(fig, width='stretch', key=f"long_short_pie_{tab_idx}")
                    
                    ratio = (long_vol / short_vol) if short_vol > 0 else float('inf')
                    st.metric("Long/Short Ratio", f"{ratio:.2f}x")
                
                st.markdown("#### Average Trade Size")
                avg_size = product_df['volume_usd'].mean()
                median_size = product_df['volume_usd'].median()
                
                fig = go.Figure()
                fig.add_trace(go.Box(
                    y=product_df['volume_usd'],
                    name='Trade Size Distribution',
                    boxmean='sd',
                    marker_color='#6366f1'
                ))
                fig.update_layout(height=200, template='plotly_dark', showlegend=False)
                st.plotly_chart(fig, width='stretch', key=f"box_chart_{tab_idx}")
                
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("Average", f"${avg_size:,.0f}")
                with col2:
                    st.metric("Median", f"${median_size:,.0f}")


def display_greeks_analysis(greeks_df):
    """Greeks analysis with 'Available Soon' for missing metrics."""
    
    st.markdown('<div class="section-header">', unsafe_allow_html=True)
    st.header("ðŸ”¬ Options Greeks Exposure")
    st.markdown('</div>', unsafe_allow_html=True)
    
    if greeks_df.empty:
        st.info("No options Greeks data available")
        return
    
    col1, col2, col3, col4 = st.columns(4)
    
    total_delta = greeks_df['net_delta'].sum()
    delta_color = "#10b981" if total_delta > 0 else "#ef4444"
    
    with col1:
        st.markdown(f"""
            <div class='greeks-metric'>
                <div class='greeks-metric-label'>Net Delta</div>
                <div class='greeks-metric-value' style='color: {delta_color}'>{total_delta:,.2f}</div>
                <div class='greeks-metric-help'>Directional exposure</div>
            </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
            <div class='greeks-metric'>
                <div class='greeks-metric-label'>Gamma</div>
                <div class='greeks-metric-value'>ðŸ”œ Available Soon</div>
                <div class='greeks-metric-help'>Delta sensitivity</div>
            </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown(f"""
            <div class='greeks-metric'>
                <div class='greeks-metric-label'>Theta</div>
                <div class='greeks-metric-value'>ðŸ”œ Available Soon</div>
                <div class='greeks-metric-help'>Time decay/day</div>
            </div>
        """, unsafe_allow_html=True)
    
    with col4:
        total_positions = greeks_df['total_option_positions'].sum()
        st.markdown(f"""
            <div class='greeks-metric'>
                <div class='greeks-metric-label'>Positions</div>
                <div class='greeks-metric-value'>{int(total_positions)}</div>
                <div class='greeks-metric-help'>Active contracts</div>
            </div>
        """, unsafe_allow_html=True)
    
    st.subheader("ðŸ“Š Delta Exposure by Trader")
    
    display_df = greeks_df.copy()
    display_df['trader'] = display_df['trader_id'].apply(mask_trader_id)
    display_df = display_df.sort_values('net_delta', ascending=False)
    
    fig = px.bar(
        display_df,
        x='trader',
        y='net_delta',
        color='net_delta',
        color_continuous_scale='RdBu',
        color_continuous_midpoint=0,
        title='Net Delta by Trader'
    )
    fig.update_layout(
        height=400,
        template='plotly_dark',
        plot_bgcolor='rgba(15, 23, 42, 0.9)',
        paper_bgcolor='rgba(15, 23, 42, 0.9)'
    )
    fig.update_xaxes(tickangle=-45)
    st.plotly_chart(fig, width='stretch')
    
    st.subheader("ðŸ“‹ Greeks Breakdown")
    
    st.dataframe(
        display_df[['trader', 'total_option_positions', 'net_delta']].style.format({
            'net_delta': '{:,.2f}',
            'total_option_positions': '{:.0f}'
        }).background_gradient(
            subset=['net_delta'],
            cmap='RdYlGn',
            vmin=-100,
            vmax=100
        ),
        width='stretch',
        hide_index=True,
        column_config={
            "trader": "Trader",
            "total_option_positions": "Positions",
            "net_delta": "Delta"
        }
    )


# ============================================================================
# DATA LOADING
# ============================================================================

with st.spinner('ðŸ”„ Loading analytics...'):
    data = load_data()

if data is None or (data['positions'].empty and data['open_positions'].empty):
    st.error("âŒ **No analytics data found**")
    st.info("ðŸ’¡ Run: `python -m scripts.run_analytics`")
    st.stop()

# ============================================================================
# SIDEBAR
# ============================================================================

logo_url = "https://deriverse.gitbook.io/deriverse-v1/~gitbook/image?url=https%3A%2F%2F3705106568-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252FVbKUpgicSXo9QHWM7uzI%252Fsites%252Fsite_oPxtF%252Ficon%252FNsfAUtLJH778Cn5Dd7zK%252Ffavicon.ico%3Falt%3Dmedia%26token%3D4099bf73-ccd6-4d9f-8bbb-01cdc664ddb0&width=32&dpr=3&quality=100&sign=13d31bb2&sv=2"

logo_bytes = load_logo(logo_url)
if logo_bytes:
    st.sidebar.image(logo_bytes, width=220)
else:
    st.sidebar.markdown("### ðŸ”· **Deriverse Analytics**")

st.sidebar.markdown("---")
st.sidebar.success("ðŸ”’ **Secure & Private**\nRead-only â€¢ Local-first")
st.sidebar.markdown("---")

st.sidebar.header("ðŸ” Access Control")
is_admin = check_admin_password()

st.sidebar.header("ðŸ‘¤ Trader Access")

all_traders = sorted(pd.concat([
    data['positions']['trader_id'] if not data['positions'].empty else pd.Series([]),
    data['open_positions']['trader_id'] if not data['open_positions'].empty else pd.Series([])
]).unique())

if "view_mode" not in st.session_state:
    st.session_state.view_mode = "all_traders"

if st.session_state.view_mode == "all_traders":
    st.sidebar.info("ðŸŒ **Mode:** All Traders View")
    
    wallet_input = st.sidebar.text_input(
        "Enter Your Wallet Address",
        placeholder="7KNXqvHu2QWvDq8cGPGvKZhFvYnz...",
        help="Enter your wallet to access personal dashboard"
    )
    
    if st.sidebar.button("ðŸ”‘ Enter Personal Dashboard"):
        if wallet_input and len(wallet_input) > 32:
            if wallet_input in all_traders:
                st.session_state.authenticated_trader = wallet_input
                st.session_state.view_mode = "personal"
                st.rerun()
            else:
                st.sidebar.error("âŒ Wallet not found in trading data")
        else:
            st.sidebar.warning("âš ï¸ Please enter a valid wallet address")

else:
    if "authenticated_trader" in st.session_state:
        trader = st.session_state.authenticated_trader
        st.sidebar.success(f"âœ… **Personal Mode:** {mask_trader_id(trader)}")
        
        if st.sidebar.button("ðŸ‘¥ Return to All Traders View"):
            st.session_state.view_mode = "all_traders"
            st.rerun()

st.sidebar.markdown("---")

st.sidebar.header("ðŸŽ›ï¸ Filters")
st.sidebar.markdown("**ðŸ“… Date Range**")

if is_admin:
    date_option = st.sidebar.radio(
        "Range (Admin)",
        ["Last 7 Days", "Last 30 Days", "All Time", "Custom"],
        index=1,
        horizontal=True,
        label_visibility="collapsed"
    )
else:
    date_option = st.sidebar.radio(
        "Range",
        ["Last 7 Days", "Last 30 Days", "Custom (Admin Only)"],
        index=1,
        horizontal=True,
        label_visibility="collapsed"
    )
    
    if date_option == "Custom (Admin Only)":
        st.sidebar.warning("ðŸ” Custom date range requires admin authentication")
        date_option = "Last 30 Days"

if data and not data['positions'].empty:
    min_date = data['positions']['close_time'].min().date()
    max_date = data['positions']['close_time'].max().date()
    
    if date_option == "Last 7 Days":
        start_date = max_date - timedelta(days=7)
        end_date = max_date
    elif date_option == "Last 30 Days":
        start_date = max_date - timedelta(days=30)
        end_date = max_date
    elif date_option == "Custom" or date_option == "Custom (Admin Only)":
        if is_admin:
            col1, col2 = st.sidebar.columns(2)
            with col1:
                start_date = st.date_input("From", min_date, min_value=min_date, max_value=max_date)
            with col2:
                end_date = st.date_input("To", max_date, min_value=min_date, max_value=max_date)
        else:
            start_date = max_date - timedelta(days=30)
            end_date = max_date
    else:
        start_date = min_date
        end_date = max_date

if data and not data['positions'].empty:
    all_markets = sorted(data['positions']['market_id'].unique())
    symbol_map = {m: simplify_symbol(m) for m in all_markets}
    unique_symbols = sorted(set(symbol_map.values()))
    
    selected_symbols = st.sidebar.multiselect(
        "Symbols",
        unique_symbols,
        default=[],
        help="Select symbols to analyze (empty = all symbols)"
    )
    
    if selected_symbols:
        selected_markets = [m for m in all_markets if simplify_symbol(m) in selected_symbols]
    else:
        selected_markets = []
else:
    selected_markets = []

st.sidebar.markdown("---")


# ============================================================================
# FIXED HEADER & NAVIGATION - NEVER SCROLLS
# ============================================================================

if "nav" not in st.session_state:
    st.session_state.nav = "overview"

with st.container():
    st.markdown('<div class="fixed-header-container">', unsafe_allow_html=True)
    
    col1, col2 = st.columns([1, 8])
    
    with col1:
        if logo_bytes:
            st.image(logo_bytes, width=60)
        else:
            st.markdown("### ðŸ”·")
    
    with col2:
        st.markdown('<div class="header-title">Deriverse Trading Analytics</div>', unsafe_allow_html=True)
        st.markdown('<div class="header-subtitle">Real-time performance insights â€¢ Local-first security</div>', unsafe_allow_html=True)
    
    if st.session_state.view_mode == "personal" and "authenticated_trader" in st.session_state:
        st.markdown(f"""
            <div class='profile-badge'>
                ðŸ” {mask_trader_id(st.session_state.authenticated_trader)}
            </div>
        """, unsafe_allow_html=True)
    
    nav_items = [
        ("ðŸ“Š Overview", "overview"),
        ("ðŸ“ˆ Performance", "performance"),
        ("âš ï¸ Risk", "risk"),
        ("ðŸ“Š Volume", "volume"),
        ("ðŸ“‹ Orders", "orders"),
        ("ðŸ”¬ Greeks", "greeks"),
        ("ðŸ“ Journal", "journal")
    ]
    
    nav_cols = st.columns(len(nav_items))
    
    for idx, (col, (label, nav_key)) in enumerate(zip(nav_cols, nav_items)):
        with col:
            is_active = (st.session_state.nav == nav_key)
            if st.button(
                label,
                key=f"nav_{nav_key}",
                use_container_width=True,
                type="primary" if is_active else "secondary"
            ):
                st.session_state.nav = nav_key
                st.rerun()
    
    st.markdown('</div>', unsafe_allow_html=True)

st.markdown("<div style='height: 10px;'></div>", unsafe_allow_html=True)


# ============================================================================
# APPLY FILTERS
# ============================================================================

filtered_positions = data['positions'].copy() if not data['positions'].empty else pd.DataFrame()
filtered_open = data['open_positions'].copy() if not data['open_positions'].empty else pd.DataFrame()

if st.session_state.view_mode == "personal" and "authenticated_trader" in st.session_state:
    selected_trader = st.session_state.authenticated_trader
    if not filtered_positions.empty:
        filtered_positions = filtered_positions[filtered_positions['trader_id'] == selected_trader]
    if not filtered_open.empty:
        filtered_open = filtered_open[filtered_open['trader_id'] == selected_trader]
else:
    selected_trader = None

if not filtered_positions.empty:
    filtered_positions = filtered_positions[
        (filtered_positions['close_time'].dt.date >= start_date) &
        (filtered_positions['close_time'].dt.date <= end_date)
    ]

if selected_markets and not filtered_positions.empty:
    filtered_positions = filtered_positions[filtered_positions['market_id'].isin(selected_markets)]
if selected_markets and not filtered_open.empty:
    filtered_open = filtered_open[filtered_open['market_id'].isin(selected_markets)]

if not filtered_positions.empty:
    filtered_positions = calculate_volume_usd(filtered_positions)

if not data['equity'].empty:
    filtered_equity = data['equity'].copy()
    if selected_trader:
        filtered_equity = filtered_equity[filtered_equity['trader_id'] == selected_trader]
    filtered_equity = filtered_equity[
        (filtered_equity['timestamp'].dt.date >= start_date) &
        (filtered_equity['timestamp'].dt.date <= end_date)
    ]
else:
    filtered_equity = pd.DataFrame()


# ============================================================================
# OPEN POSITIONS TABLE
# ============================================================================

if not filtered_open.empty:
    st.warning(f"âš ï¸ **{len(filtered_open)} Open Positions** - Unrealized PnL not included")
    
    open_display = filtered_open.copy()
    
    if 'time_held_seconds' in open_display.columns:
        open_display['time_held'] = (open_display['time_held_seconds'] / 3600).round(1)
    elif 'open_time' in open_display.columns:
        open_display['time_held'] = ((pd.Timestamp.now() - pd.to_datetime(open_display['open_time'])).dt.total_seconds() / 3600).round(1)
    else:
        open_display['time_held'] = 0
    
    open_display['trader_display'] = open_display['trader_id'].apply(
        lambda x: f"{x[:8]}...{x[-8:]}" if selected_trader and x == selected_trader else mask_trader_id(x)
    )
    open_display['symbol'] = open_display['market_id'].apply(simplify_symbol)
    
    display_cols = ['trader_display', 'symbol', 'product_type', 'side', 'entry_price', 'size']
    
    if 'fees_paid' in open_display.columns:
        display_cols.append('fees_paid')
    elif 'fees' in open_display.columns:
        open_display['fees_paid'] = open_display['fees']
        display_cols.append('fees_paid')
    
    display_cols.append('time_held')
    
    st.dataframe(
        open_display[display_cols].rename(columns={
            'trader_display': 'Trader',
            'symbol': 'Symbol',
            'product_type': 'Type',
            'side': 'Direction',
            'entry_price': 'Entry Price',
            'size': 'Size',
            'fees_paid': 'Fees Paid',
            'time_held': 'Hours Held'
        }).style.format({
            'Entry Price': '${:,.2f}',
            'Fees Paid': '${:,.2f}',
            'Size': '{:,.4f}',
            'Hours Held': '{:.1f}h'
        }),
        width='stretch',
        hide_index=True
    )


# ============================================================================
# SECTION RENDERING BASED ON NAVIGATION
# ============================================================================

if st.session_state.nav == "overview":
    
    st.markdown("## ðŸ“ˆ Performance Overview")
    
    col1, col2, col3, col4 = st.columns(4)
    
    total_pnl = filtered_positions['realized_pnl'].sum() if not filtered_positions.empty else 0
    win_rate = (filtered_positions['realized_pnl'] > 0).mean() * 100 if not filtered_positions.empty else 0
    total_fees = filtered_positions['fees'].sum() if not filtered_positions.empty else 0
    trade_count = len(filtered_positions)
    
    col1.metric("Net Realized PnL", f"${total_pnl:,.2f}", delta=f"{total_pnl:,.2f}" if total_pnl != 0 else None)
    col2.metric("Win Rate", f"{win_rate:.1f}%")
    
    win_rate_val = win_rate / 100 if win_rate > 0 else 0
    col2.progress(win_rate_val, text=f"{win_rate_val*100:.1f}%")
    
    col3.metric("Total Closed Trades", trade_count)
    col4.metric("Fees Paid", f"${total_fees:,.2f}")
    
    st.markdown("## âš–ï¸ Risk Analysis")
    col1, col2, col3, col4 = st.columns(4)
    
    if not filtered_positions.empty:
        winning = filtered_positions[filtered_positions['realized_pnl'] > 0]
        losing = filtered_positions[filtered_positions['realized_pnl'] < 0]
        
        avg_win = winning['realized_pnl'].mean() if len(winning) > 0 else 0
        avg_loss = losing['realized_pnl'].mean() if len(losing) > 0 else 0
        profit_factor = abs(avg_win / avg_loss) if avg_loss != 0 else float('inf')
        
        if selected_trader and not data['summary'].empty:
            trader_data = data['summary'][data['summary']['trader_id'] == selected_trader]
            max_dd = trader_data['max_drawdown'].iloc[0] if not trader_data.empty else 0
            sharpe = trader_data['sharpe_ratio'].iloc[0] if not trader_data.empty else 0
        else:
            max_dd = data['summary']['max_drawdown'].min() if not data['summary'].empty else 0
            sharpe = data['summary']['sharpe_ratio'].mean() if not data['summary'].empty else 0
    else:
        avg_win = avg_loss = max_dd = sharpe = profit_factor = 0
    
    col1.metric("Average Win", f"${avg_win:,.2f}")
    col2.metric("Average Loss", f"${avg_loss:,.2f}")
    col3.metric("Profit Factor", f"{profit_factor:.2f}x")
    col4.metric("Sharpe Ratio", f"{sharpe:.2f}")
    
    if not filtered_positions.empty and not selected_trader:
        st.markdown("## ðŸ† Top Performers Analysis")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### ðŸ“ˆ Top 5 Profitable Traders")
            top_winners = get_top_traders(filtered_positions, n=5, by='profit')
            
            if top_winners:
                winner_stats = []
                for trader in top_winners:
                    trader_pos = filtered_positions[filtered_positions['trader_id'] == trader]
                    winner_stats.append({
                        'Trader': mask_trader_id(trader),
                        'Total PnL': trader_pos['realized_pnl'].sum(),
                        'Trades': len(trader_pos),
                        'Win Rate': (trader_pos['realized_pnl'] > 0).mean() * 100
                    })
                
                winner_df = pd.DataFrame(winner_stats)
                
                fig = px.bar(
                    winner_df,
                    x='Trader',
                    y='Total PnL',
                    color='Total PnL',
                    color_continuous_scale='Greens',
                    text='Total PnL'
                )
                fig.update_traces(texttemplate='$%{text:.0f}', textposition='outside')
                fig.update_layout(height=200, showlegend=False, template='plotly_dark')
                st.plotly_chart(fig, width='stretch')
                
                st.dataframe(
                    winner_df.style.format({
                        'Total PnL': '${:,.2f}',
                        'Win Rate': '{:.1f}%'
                    }),
                    width='stretch',
                    hide_index=True
                )
        
        with col2:
            st.markdown("### ðŸ“‰ Top 5 Loss-Making Traders")
            top_losers = get_top_traders(filtered_positions, n=5, by='loss')
            
            if top_losers:
                loser_stats = []
                for trader in top_losers:
                    trader_pos = filtered_positions[filtered_positions['trader_id'] == trader]
                    loser_stats.append({
                        'Trader': mask_trader_id(trader),
                        'Total PnL': trader_pos['realized_pnl'].sum(),
                        'Trades': len(trader_pos),
                        'Win Rate': (trader_pos['realized_pnl'] > 0).mean() * 100
                    })
                
                loser_df = pd.DataFrame(loser_stats)
                
                fig = px.bar(
                    loser_df,
                    x='Trader',
                    y='Total PnL',
                    color='Total PnL',
                    color_continuous_scale='Reds_r',
                    text='Total PnL'
                )
                fig.update_traces(texttemplate='$%{text:.0f}', textposition='outside')
                fig.update_layout(height=200, showlegend=False, template='plotly_dark')
                st.plotly_chart(fig, width='stretch')
                
                st.dataframe(
                    loser_df.style.format({
                        'Total PnL': '${:,.2f}',
                        'Win Rate': '{:.1f}%'
                    }),
                    width='stretch',
                    hide_index=True
                )

elif st.session_state.nav == "performance":
    if not filtered_positions.empty and not filtered_equity.empty:
        display_equity_section(filtered_equity, filtered_positions, 
                              st.session_state.authenticated_trader if st.session_state.view_mode == "personal" else None)
    else:
        st.info("No performance data for selected filters")

elif st.session_state.nav == "risk":
    if not filtered_positions.empty:
        display_liquidation_analytics(filtered_positions)
    else:
        st.info("No risk data for selected filters")

elif st.session_state.nav == "volume":
    if not filtered_positions.empty:
        display_volume_analysis(filtered_positions)
    else:
        st.info("No volume data for selected filters")

elif st.session_state.nav == "orders":
    if not data['order_perf'].empty:
        display_order_type_performance(data['order_perf'], filtered_positions)
    else:
        st.info("No order type data available")

elif st.session_state.nav == "greeks":
    if not data['greeks'].empty:
        greeks_filtered = data['greeks'].copy()
        if selected_trader:
            greeks_filtered = greeks_filtered[greeks_filtered['trader_id'] == selected_trader]
        
        if not greeks_filtered.empty:
            display_greeks_analysis(greeks_filtered)
        else:
            st.info("No Greeks data for selected trader")
    else:
        st.info("No Greeks data available")

elif st.session_state.nav == "journal":
    
    st.markdown('<div class="section-header">', unsafe_allow_html=True)
    st.header("ðŸ“ Trade Journal with Annotations")
    st.markdown('</div>', unsafe_allow_html=True)
    
    if filtered_positions.empty:
        st.info("No trades to journal")
    
    elif st.session_state.view_mode == "personal" and "authenticated_trader" in st.session_state:
        trader = st.session_state.authenticated_trader
        
        st.markdown("""
        <div class='note-instruction'>
            <strong>ðŸ“Œ How to take notes:</strong><br>
            1. Click on any cell in the "ðŸ“ Your Trading Notes" column<br>
            2. Type your observations, strategy notes, or lessons learned<br>
            3. Press Enter or click outside to save automatically<br>
            4. Notes are saved locally and persist between sessions
        </div>
        """, unsafe_allow_html=True)
        
        trader_notes = load_trader_notes(trader)
        
        journal_df = filtered_positions.sort_values('close_time', ascending=False).copy()
        journal_df['symbol'] = journal_df['market_id'].apply(simplify_symbol)
        journal_df['notes'] = journal_df['position_id'].map(lambda pid: trader_notes.get(str(pid), ""))
        
        notes_count = len([n for n in journal_df['notes'] if n and str(n).strip()])
        st.info(f"ðŸ“ You have {notes_count} annotated trade{'s' if notes_count != 1 else ''}")
        
        available_cols = ['close_time', 'symbol', 'product_type', 'side',
                         'entry_price', 'exit_price', 'volume_usd', 'realized_pnl', 'fees', 'notes']
        
        edited_journal = st.data_editor(
            journal_df[available_cols],
            column_config={
                "close_time": st.column_config.DatetimeColumn("Closed At", format="DD/MM/YYYY HH:mm"),
                "symbol": "Symbol",
                "product_type": "Type",
                "side": "Direction",
                "entry_price": st.column_config.NumberColumn("Entry", format="$%.2f"),
                "exit_price": st.column_config.NumberColumn("Exit", format="$%.2f"),
                "volume_usd": st.column_config.NumberColumn("Volume", format="$%.0f"),
                "realized_pnl": st.column_config.NumberColumn("PnL", format="$%.2f"),
                "fees": st.column_config.NumberColumn("Fees", format="$%.2f"),
                "notes": st.column_config.TextColumn(
                    "ðŸ“ Your Trading Notes",
                    help="Document your strategy, emotions, and lessons learned",
                    max_chars=500,
                    width="large"
                )
            },
            width='stretch',
            hide_index=True,
            num_rows="fixed",
            disabled=[col for col in available_cols if col != 'notes']
        )
        
        updated_notes = {}
        for idx, row in edited_journal.iterrows():
            pid = journal_df.loc[idx, 'position_id']
            note = row.get('notes', '')
            if pd.notna(note) and str(note).strip():
                updated_notes[str(pid)] = note
        
        if updated_notes != trader_notes:
            save_trader_notes(trader, updated_notes)
            st.success("âœ… Notes saved!")
        
        col1, col2, col3 = st.columns([3, 1, 1])
        
        with col2:
            export_df = journal_df[available_cols].copy()
            csv = export_df.to_csv(index=False)
            st.download_button(
                "ðŸ“¥ Export CSV",
                csv,
                f"journal_{trader[:8]}.csv",
                "text/csv",
                width='stretch'
            )
        
        with col3:
            if st.button("ðŸ—‘ï¸ Clear All Notes", width='stretch'):
                save_trader_notes(trader, {})
                st.rerun()
    
    elif selected_trader:
        st.info(f"ðŸ‘ï¸ **Read-Only View:** Viewing {mask_trader_id(selected_trader)}")
        st.caption("ðŸ’¡ To add notes, authenticate with your wallet in the sidebar")
        
        journal_df = filtered_positions.sort_values('close_time', ascending=False).copy()
        journal_df['trader'] = journal_df['trader_id'].apply(mask_trader_id)
        journal_df['symbol'] = journal_df['market_id'].apply(simplify_symbol)
        
        st.dataframe(
            journal_df[['close_time', 'trader', 'symbol', 'product_type', 'side',
                       'entry_price', 'exit_price', 'volume_usd', 'realized_pnl', 'fees']].style.format({
                'entry_price': '${:,.2f}',
                'exit_price': '${:,.2f}',
                'volume_usd': '${:,.0f}',
                'realized_pnl': '${:,.2f}',
                'fees': '${:,.2f}'
            }),
            width='stretch',
            hide_index=True
        )
    
    else:
        st.info("ðŸ‘¥ Select a specific trader or authenticate to add notes")
        
        journal_df = filtered_positions.sort_values('close_time', ascending=False).copy()
        journal_df['trader'] = journal_df['trader_id'].apply(mask_trader_id)
        journal_df['symbol'] = journal_df['market_id'].apply(simplify_symbol)
        
        st.dataframe(
            journal_df[['close_time', 'trader', 'symbol', 'product_type', 'side',
                       'entry_price', 'exit_price', 'volume_usd', 'realized_pnl', 'fees']].style.format({
                'entry_price': '${:,.2f}',
                'exit_price': '${:,.2f}',
                'volume_usd': '${:,.0f}',
                'realized_pnl': '${:,.2f}',
                'fees': '${:,.2f}'
            }),
            width='stretch',
            hide_index=True
        )


# ============================================================================
# FOOTER
# ============================================================================

st.markdown("---")
col1, col2, col3 = st.columns([2, 1, 1])

with col1:
    st.caption(f"ðŸ• Updated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

with col2:
    if is_admin:
        st.caption("ðŸ” **Admin Mode** â€¢ All Time Access")
    else:
        st.caption("ðŸ”’ **Secure** â€¢ Local-first")

with col3:
    st.caption("v6.0 Enhanced")

st.markdown("""
    <div style='text-align: center; padding: 20px; color: #64748b; font-size: 12px;'>
        <p><strong>Deriverse Analytics Dashboard</strong></p>
        <p>Read-only â€¢ No private keys required â€¢ Data stays on your machine</p>
    </div>
""", unsafe_allow_html=True)


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\dashboards\__init__.py =====



===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\scripts\diagnose_data.py =====

# scripts/diagnose_data.py
"""
Data quality diagnostic tool.
Run after analytics to verify all data is properly processed.
"""

import pandas as pd
from pathlib import Path
import json

print("=" * 60)
print("DATA QUALITY DIAGNOSTIC")
print("=" * 60)

# Check positions file
positions_path = Path("data/analytics_output/positions.csv")
if positions_path.exists():
    positions = pd.read_csv(positions_path)
    
    print(f"\nðŸ“Š POSITIONS SUMMARY ({len(positions)} total)")
    print("\nâœ… By Product Type:")
    product_counts = positions['product_type'].value_counts()
    for product, count in product_counts.items():
        print(f"  {product:10} {count:>3} positions")
    
    print("\nâœ… By Market:")
    market_counts = positions['market_id'].value_counts()
    for market, count in market_counts.items():
        print(f"  {market:25} {count:>3} positions")
    
    print("\nâœ… By Trader:")
    trader_counts = positions['trader_id'].value_counts()
    for trader, count in trader_counts.items():
        print(f"  {trader:10} {count:>3} positions")
    
    print("\nðŸ’° PnL BY PRODUCT TYPE:")
    pnl_by_product = positions.groupby('product_type')['realized_pnl'].sum()
    for product, pnl in pnl_by_product.items():
        print(f"  {product:10} ${pnl:>12,.2f}")
    
    print("\nðŸ” OPTION POSITIONS DETAIL:")
    option_positions = positions[positions['product_type'] == 'option']
    if not option_positions.empty:
        print(f"  Found {len(option_positions)} option positions")
        for _, row in option_positions.iterrows():
            print(f"    â€¢ {row['market_id']:30} {row['trader_id']:10} ${row['realized_pnl']:>10,.2f}")
    else:
        print("  âŒ NO OPTION POSITIONS FOUND")
    
    print("\nðŸ“‹ ALL POSITIONS SUMMARY:")
    # Check which columns exist
    available_cols = ['position_id', 'trader_id', 'market_id', 'product_type', 'side', 'realized_pnl']
    if 'close_reason' in positions.columns:
        available_cols.append('close_reason')
    
    print(positions[available_cols].to_string(index=False))
    
else:
    print("âŒ positions.csv not found")

# Check normalized events
events_path = Path("data/normalized/events.jsonl")
if events_path.exists():
    events = []
    with open(events_path) as f:
        for line in f:
            line = line.strip()
            if line:
                events.append(json.loads(line))
    
    df = pd.DataFrame(events)
    
    print(f"\nðŸ“¥ NORMALIZED EVENTS ({len(df)} total)")
    print("\nâœ… By Event Type:")
    event_counts = df['event_type'].value_counts()
    for event_type, count in event_counts.items():
        print(f"  {event_type:10} {count:>3} events")
    
    print("\nâœ… By Product Type:")
    product_counts = df['product_type'].value_counts()
    for product, count in product_counts.items():
        print(f"  {product:10} {count:>3} events")
    
    print("\nðŸŽ¯ OPTION EVENTS BREAKDOWN:")
    option_events = df[df['product_type'] == 'option']
    print(f"  Total option events: {len(option_events)}")
    if not option_events.empty:
        print("\n  By event type:")
        option_event_counts = option_events['event_type'].value_counts()
        for event_type, count in option_event_counts.items():
            print(f"    {event_type:10} {count:>3}")
        
        print("\n  By market:")
        option_market_counts = option_events['market_id'].value_counts()
        for market, count in option_market_counts.items():
            print(f"    {market:30} {count:>3}")
    else:
        print("  âŒ NO OPTION EVENTS")
else:
    print("âŒ events.jsonl not found")

# Check raw mock data
mock_path = Path("configs/mock_data.json")
if mock_path.exists():
    with open(mock_path) as f:
        mock_data = json.load(f)
    
    print(f"\nðŸ“¦ RAW MOCK DATA ({len(mock_data)} events)")
    mock_df = pd.DataFrame(mock_data)
    
    print("\nâœ… By Event Type:")
    event_counts = mock_df['event_type'].value_counts()
    for event_type, count in event_counts.items():
        print(f"  {event_type:10} {count:>3} events")
    
    print("\nâœ… By Product Type:")
    product_counts = mock_df['product_type'].value_counts()
    for product, count in product_counts.items():
        print(f"  {product:10} {count:>3} events")
else:
    print("\nâŒ configs/mock_data.json not found")

print("\n" + "=" * 60)

# Check for duplicates
if events_path.exists():
    print("\nðŸ” CHECKING FOR DUPLICATES...")
    event_ids = [e['event_id'] for e in events]
    unique_ids = set(event_ids)
    
    if len(event_ids) != len(unique_ids):
        print(f"  âš ï¸  WARNING: Found {len(event_ids) - len(unique_ids)} duplicate events!")
        print(f"  Total events: {len(event_ids)}, Unique: {len(unique_ids)}")
    else:
        print(f"  âœ… No duplicates found ({len(event_ids)} unique events)")

print("=" * 60)


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\scripts\generate_mock_data.py =====

# scripts/generate_mock_data.py 
"""
Generate curated mock trading data for Deriverse analytics demo.

This script creates a carefully designed dataset that showcases:
- Profitable and losing trades across all product types
- Risk management (5 liquidation events)
- Active positions (open trades)
- Complete options lifecycle (buy, sell, exercise, expire)
- Historical data with gaps (realistic trading patterns)
- Edge cases for robustness testing
- Blockchain verifiability (transaction signatures)
- Position tracking across partial closes and re-entries

Data Quality Features:
- Unique position IDs for trade matching
- Transaction hashes for on-chain verification
- Entry prices preserved on close events
- Explicit USD fee denominations
"""

import json
import hashlib
import base58
from datetime import datetime, timezone, timedelta
from pathlib import Path

OUTPUT_PATH = Path("configs/mock_data.json")
OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)

# Use historical base date (30 days ago) for realistic data
now = datetime.now(timezone.utc)
base_date = now - timedelta(days=30)

events = []

# Realistic Solana wallet addresses (base58 format)
WALLETS = {
    "alice": "7KNXqvHu2QWvDq8cGPGvKZhFvYnz3kQ5mL8xRt2Bp9uV",
    "bob": "5FxM2nQwP4vYkL9mT3xRd8eJbWp7sN6gH2cKt9uVfXyZ",
    "charlie": "9DpT3vHx5kN2qL8mR7wYfJ6bP4sE1cG9nZ5tK3uVwXyA",
    "diana": "4MqL8vYx2kP9nT7wR5fH3bJ6sE1cG4nZ8tK2uVwXyBpQ",
    "evan": "6NrK9wZx3mQ8pU7vS4gI2dL5tF1eH7oA9yM3xVbCwRtE",
    "fiona": "8QtN2xWy5lR7mV9uT6hK3eM4pG1fJ8nB7zL4wVcDxSeF",
    "george": "3HsJ7yVz4nQ6oW8tS5gL2fN9rH1eK6mC8xM5vBdEwRuG",
    "hannah": "2PrM8xUz6oT5nY7vR4jL3gP1sH9eN4mD6zK8wCfGxQuH",
    "ivan": "5TpQ9yXz7mS6oV8uR3kM2hN4rJ1fL5nE7xP6wDgHySvI",
    "julia": "4WqP8zYx5nT7mU9tS2lN6jM3rK1gH4oC8yL5vEfJxRwK",
}

# Position tracking for generating consistent position_ids
position_counter = {}


def generate_event_id(event_data, index):
    """
    Generate deterministic event ID from event data.
    
    Args:
        event_data: Dictionary containing event fields
        index: Sequential index for uniqueness
        
    Returns:
        SHA256 hash as event identifier
    """
    seed_parts = [
        str(event_data.get('event_type', '')),
        str(event_data.get('timestamp', '') if isinstance(event_data.get('timestamp'), str) else ''),
        str(event_data.get('trader_id', '')),
        str(event_data.get('market_id', '')),
        str(index)
    ]
    return hashlib.sha256("|".join(seed_parts).encode()).hexdigest()


def generate_tx_signature(event_data, index):
    """
    Generate realistic-looking Solana transaction signature.
    
    Solana transaction signatures are base58-encoded and 88 characters long.
    This creates deterministic but authentic-looking signatures for demo purposes.
    
    Args:
        event_data: Dictionary containing event fields
        index: Sequential index for uniqueness
        
    Returns:
        Base58-encoded signature (88 characters)
    """
    seed_parts = [
        str(event_data.get('event_type', '')),
        str(event_data.get('timestamp', '')),
        str(event_data.get('trader_id', '')),
        str(event_data.get('market_id', '')),
        str(event_data.get('price', '')),
        str(index)
    ]
    
    seed = "|".join(seed_parts)
    hash_bytes = hashlib.sha256(seed.encode()).digest()
    
    # Pad to 64 bytes to match Solana signature length
    padded = hash_bytes + bytes(32)
    
    # Encode as base58 (Solana standard)
    return base58.b58encode(padded).decode()[:88]


def generate_position_id(trader_id, market_id, timestamp):
    """
    Generate unique position identifier.
    
    Format: {trader_prefix}_{market}_{timestamp_ms}
    Example: 7KNXqvHu_SOL-PERP_1704067200000
    
    Args:
        trader_id: Wallet address
        market_id: Market identifier
        timestamp: Event timestamp
        
    Returns:
        Unique position ID string
    """
    trader_prefix = trader_id[:8]
    timestamp_ms = int(timestamp.timestamp() * 1000)
    return f"{trader_prefix}_{market_id}_{timestamp_ms}"


def emit(event, order_type="market", position_id=None):
    """
    Add event to output array with automatic field enrichment.
    
    This function handles:
    - Timestamp formatting (ISO 8601 with Z suffix)
    - Event ID generation (deterministic hash)
    - Transaction signature generation (realistic Solana format)
    - Position ID assignment (unique or inherited)
    - Order type tagging
    
    Args:
        event: Event dictionary with trading data
        order_type: Type of order (market/limit/stop) - defaults to market
        position_id: Optional position ID (for matching close to open)
    """
    # Format timestamp to ISO 8601 with Z suffix
    if 'timestamp' in event and isinstance(event['timestamp'], datetime):
        event['timestamp'] = event['timestamp'].isoformat().replace("+00:00", "Z")
    
    # Generate deterministic event ID
    if 'event_id' not in event:
        event['event_id'] = generate_event_id(event, len(events) + 1)
    
    # Generate Solana transaction signature
    event['tx_hash'] = generate_tx_signature(event, len(events) + 1)
    
    # Handle position ID for trade matching
    if event['event_type'] == 'open':
        # Create new position ID for opening events
        timestamp = datetime.fromisoformat(event['timestamp'].replace('Z', '+00:00'))
        new_position_id = generate_position_id(
            event['trader_id'], 
            event['market_id'], 
            timestamp
        )
        event['position_id'] = new_position_id
        
        # Store for matching closes
        key = f"{event['trader_id']}:{event['market_id']}"
        if key not in position_counter:
            position_counter[key] = []
        position_counter[key].append({
            'position_id': new_position_id,
            'entry_price': event['price'],
            'timestamp': event['timestamp']
        })
    
    elif event['event_type'] in ['close', 'liquidation', 'exercise', 'expire']:
        # Match to existing position or use provided position_id
        if position_id:
            event['position_id'] = position_id
        else:
            key = f"{event['trader_id']}:{event['market_id']}"
            if key in position_counter and position_counter[key]:
                # Use most recent open position
                position_info = position_counter[key][-1]
                event['position_id'] = position_info['position_id']
                
                # Add entry price for PnL calculation
                if 'entry_price' not in event:
                    event['entry_price'] = position_info['entry_price']
                
                # Remove from open positions if fully closed
                if event['event_type'] in ['close', 'liquidation', 'expire']:
                    position_counter[key].pop()
    
    # Add order type for position-related events
    if event['event_type'] in ['open', 'close', 'liquidation']:
        event['order_type'] = order_type
    
    events.append(event)


# ================================================================================
# SPOT TRADES - Simple buy/sell with clear profit/loss
# ================================================================================

# Day 1 - Winning spot trade (Alice: +$99)
# Buy SOL at $100, sell at $110 after 2 hours
emit({
    "event_type": "open",
    "timestamp": base_date,
    "trader_id": WALLETS["alice"],
    "market_id": "SOL/USDC",
    "product_type": "spot",
    "side": "buy",
    "price": 100,
    "size": 10,
    "fee_usd": 0.5
}, order_type="stop")

emit({
    "event_type": "close",
    "timestamp": base_date + timedelta(hours=2),
    "trader_id": WALLETS["alice"],
    "market_id": "SOL/USDC",
    "product_type": "spot",
    "side": "sell",
    "price": 110,
    "size": 10,
    "fee_usd": 0.5
}, order_type="market")

# Day 3 - Losing spot trade (Bob: -$252)
# Gap in data: Day 2 has no activity (realistic pattern)
emit({
    "event_type": "open",
    "timestamp": base_date + timedelta(days=2, minutes=10),
    "trader_id": WALLETS["bob"],
    "market_id": "ETH/USDC",
    "product_type": "spot",
    "side": "buy",
    "price": 2000,
    "size": 5,
    "fee_usd": 1.0
}, order_type="market")

emit({
    "event_type": "close",
    "timestamp": base_date + timedelta(days=2, hours=3),
    "trader_id": WALLETS["bob"],
    "market_id": "ETH/USDC",
    "product_type": "spot",
    "side": "sell",
    "price": 1950,
    "size": 5,
    "fee_usd": 1.0
}, order_type="stop")


# ================================================================================
# PERPETUAL TRADES - Long/short positions with liquidations
# ================================================================================

# Day 5 - Winning long perp (Charlie: +$199)
# Gap in data: Day 4 has no activity
emit({
    "event_type": "open",
    "timestamp": base_date + timedelta(days=4, minutes=20),
    "trader_id": WALLETS["charlie"],
    "market_id": "SOL-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 100,
    "size": 10,
    "fee_usd": 0.5
}, order_type="limit")

emit({
    "event_type": "close",
    "timestamp": base_date + timedelta(days=4, hours=4),
    "trader_id": WALLETS["charlie"],
    "market_id": "SOL-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 120,
    "size": 10,
    "fee_usd": 0.5
}, order_type="market")

# Day 7 - Winning short perp (Diana: +$1990)
# Gap in data: Day 6 has no activity
emit({
    "event_type": "open",
    "timestamp": base_date + timedelta(days=6, minutes=30),
    "trader_id": WALLETS["diana"],
    "market_id": "BTC-PERP",
    "product_type": "perp",
    "side": "short",
    "price": 50000,
    "size": 1,
    "fee_usd": 5.0
}, order_type="market")

emit({
    "event_type": "close",
    "timestamp": base_date + timedelta(days=6, hours=5),
    "trader_id": WALLETS["diana"],
    "market_id": "BTC-PERP",
    "product_type": "perp",
    "side": "short",
    "price": 48000,
    "size": 1,
    "fee_usd": 5.0
}, order_type="market")

# Day 8 - Losing long perp (Evan: -$254)
emit({
    "event_type": "open",
    "timestamp": base_date + timedelta(days=7, minutes=40),
    "trader_id": WALLETS["evan"],
    "market_id": "ETH-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 2100,
    "size": 5,
    "fee_usd": 2.0
}, order_type="stop")

emit({
    "event_type": "close",
    "timestamp": base_date + timedelta(days=7, hours=6),
    "trader_id": WALLETS["evan"],
    "market_id": "ETH-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 2050,
    "size": 5,
    "fee_usd": 2.0
}, order_type="market")


# ================================================================================
# LIQUIDATION EVENTS (5 total for detailed risk analysis)
# ================================================================================

# LIQUIDATION 1 - Day 10: SOL-PERP (Diana: -$880)
# Demonstrates overleveraged long position in volatile market
# Gap in data: Day 9 has no activity
emit({
    "event_type": "open",
    "timestamp": base_date + timedelta(days=9, hours=1),
    "trader_id": WALLETS["diana"],
    "market_id": "SOL-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 105,
    "size": 50,
    "fee_usd": 5.0
}, order_type="market")

emit({
    "event_type": "liquidation",
    "timestamp": base_date + timedelta(days=9, hours=2),
    "trader_id": WALLETS["diana"],
    "market_id": "SOL-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 88,
    "size": 50,
    "fee_usd": 25.0
}, order_type="liquidation")

# LIQUIDATION 2 - Day 12: ETH-PERP (Bob: -$1,520)
# Gap in data: Day 11 has no activity
emit({
    "event_type": "open",
    "timestamp": base_date + timedelta(days=11, hours=3),
    "trader_id": WALLETS["bob"],
    "market_id": "ETH-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 2200,
    "size": 10,
    "fee_usd": 3.0
}, order_type="market")

emit({
    "event_type": "liquidation",
    "timestamp": base_date + timedelta(days=11, hours=8),
    "trader_id": WALLETS["bob"],
    "market_id": "ETH-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 2050,
    "size": 10,
    "fee_usd": 20.0
}, order_type="liquidation")

# LIQUIDATION 3 - Day 15: BTC-PERP (Evan: -$2,530)
# Large short position caught in price surge
# Gap in data: Days 13-14 have no activity
emit({
    "event_type": "open",
    "timestamp": base_date + timedelta(days=14, hours=2),
    "trader_id": WALLETS["evan"],
    "market_id": "BTC-PERP",
    "product_type": "perp",
    "side": "short",
    "price": 49000,
    "size": 2,
    "fee_usd": 8.0
}, order_type="limit")

emit({
    "event_type": "liquidation",
    "timestamp": base_date + timedelta(days=14, hours=12),
    "trader_id": WALLETS["evan"],
    "market_id": "BTC-PERP",
    "product_type": "perp",
    "side": "short",
    "price": 50250,
    "size": 2,
    "fee_usd": 30.0
}, order_type="liquidation")

# LIQUIDATION 4 - Day 18: AVAX-PERP (Charlie: -$342)
# Gap in data: Days 16-17 have no activity
emit({
    "event_type": "open",
    "timestamp": base_date + timedelta(days=17, hours=5),
    "trader_id": WALLETS["charlie"],
    "market_id": "AVAX-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 38.5,
    "size": 100,
    "fee_usd": 4.0
}, order_type="market")

emit({
    "event_type": "liquidation",
    "timestamp": base_date + timedelta(days=17, hours=14),
    "trader_id": WALLETS["charlie"],
    "market_id": "AVAX-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 35.2,
    "size": 100,
    "fee_usd": 12.0
}, order_type="liquidation")

# LIQUIDATION 5 - Day 20: SOL-PERP (Alice: -$615)
# Gap in data: Day 19 has no activity
emit({
    "event_type": "open",
    "timestamp": base_date + timedelta(days=19, hours=4),
    "trader_id": WALLETS["alice"],
    "market_id": "SOL-PERP",
    "product_type": "perp",
    "side": "short",
    "price": 115,
    "size": 30,
    "fee_usd": 3.5
}, order_type="stop")

emit({
    "event_type": "liquidation",
    "timestamp": base_date + timedelta(days=19, hours=9),
    "trader_id": WALLETS["alice"],
    "market_id": "SOL-PERP",
    "product_type": "perp",
    "side": "short",
    "price": 135,
    "size": 30,
    "fee_usd": 18.0
}, order_type="liquidation")


# ================================================================================
# OPTION TRADES - Complete lifecycle (buy, sell, exercise, expire)
# ================================================================================

# Day 21 - Long call - profitable close (Fiona: +$29)
emit({
    "event_type": "open",
    "timestamp": base_date + timedelta(days=20, hours=1),
    "trader_id": WALLETS["fiona"],
    "market_id": "SOL-CALL-120-JAN15",
    "product_type": "option",
    "option_type": "call",
    "strike": 120,
    "expiry": (base_date + timedelta(days=38)).isoformat().replace("+00:00", "Z"),
    "side": "buy",
    "price": 5.0,
    "size": 10,
    "fee_usd": 0.5,
    "delta": 0.65,
    "implied_vol": 0.45
}, order_type="stop")

emit({
    "event_type": "close",
    "timestamp": base_date + timedelta(days=21, hours=0),
    "trader_id": WALLETS["fiona"],
    "market_id": "SOL-CALL-120-JAN15",
    "product_type": "option",
    "option_type": "call",
    "strike": 120,
    "expiry": (base_date + timedelta(days=38)).isoformat().replace("+00:00", "Z"),
    "side": "sell",
    "price": 8.0,
    "size": 10,
    "fee_usd": 0.5,
    "delta": 0.85,
    "implied_vol": 0.50
}, order_type="stop")

# Day 22 - Short put - profitable buyback (George: +$36.1)
emit({
    "event_type": "open",
    "timestamp": base_date + timedelta(days=21, hours=1, minutes=30),
    "trader_id": WALLETS["george"],
    "market_id": "SOL-PUT-90-JAN15",
    "product_type": "option",
    "option_type": "put",
    "strike": 90,
    "expiry": (base_date + timedelta(days=38)).isoformat().replace("+00:00", "Z"),
    "side": "sell",
    "price": 4.0,
    "size": 15,
    "fee_usd": 0.7,
    "delta": -0.25,
    "implied_vol": 0.40
}, order_type="stop")

emit({
    "event_type": "close",
    "timestamp": base_date + timedelta(days=22, hours=12),
    "trader_id": WALLETS["george"],
    "market_id": "SOL-PUT-90-JAN15",
    "product_type": "option",
    "option_type": "put",
    "strike": 90,
    "expiry": (base_date + timedelta(days=38)).isoformat().replace("+00:00", "Z"),
    "side": "buy",
    "price": 1.5,
    "size": 15,
    "fee_usd": 0.7,
    "delta": -0.10,
    "implied_vol": 0.30
}, order_type="market")

# Day 23 - Long put - losing close (Hannah: -$127)
emit({
    "event_type": "open",
    "timestamp": base_date + timedelta(days=22, hours=2),
    "trader_id": WALLETS["hannah"],
    "market_id": "ETH-PUT-1900-JAN15",
    "product_type": "option",
    "option_type": "put",
    "strike": 1900,
    "expiry": (base_date + timedelta(days=38)).isoformat().replace("+00:00", "Z"),
    "side": "buy",
    "price": 45.0,
    "size": 5,
    "fee_usd": 1.0,
    "delta": -0.35,
    "implied_vol": 0.55
}, order_type="stop")

emit({
    "event_type": "close",
    "timestamp": base_date + timedelta(days=24, hours=0),
    "trader_id": WALLETS["hannah"],
    "market_id": "ETH-PUT-1900-JAN15",
    "product_type": "option",
    "option_type": "put",
    "strike": 1900,
    "expiry": (base_date + timedelta(days=38)).isoformat().replace("+00:00", "Z"),
    "side": "sell",
    "price": 20.0,
    "size": 5,
    "fee_usd": 1.0,
    "delta": -0.15,
    "implied_vol": 0.40
}, order_type="limit")

# Day 25 - Long call - exercised ITM (Ivan: +$2980)
emit({
    "event_type": "open",
    "timestamp": base_date + timedelta(days=24, hours=3),
    "trader_id": WALLETS["ivan"],
    "market_id": "BTC-CALL-50000-JAN15",
    "product_type": "option",
    "option_type": "call",
    "strike": 50000,
    "expiry": (base_date + timedelta(days=38)).isoformat().replace("+00:00", "Z"),
    "side": "buy",
    "price": 2000.0,
    "size": 1,
    "fee_usd": 10.0
}, order_type="market")

# Day 38 - Exercise happens near expiry
emit({
    "event_type": "exercise",
    "timestamp": base_date + timedelta(days=37),
    "trader_id": WALLETS["ivan"],
    "market_id": "BTC-CALL-50000-JAN15",
    "product_type": "option",
    "option_type": "call",
    "strike": 50000,
    "expiry": (base_date + timedelta(days=38)).isoformat().replace("+00:00", "Z"),
    "side": "exercise",
    "size": 1,
    "fee_usd": 10.0,
    "underlying_price": 55000
})

# Day 26 - Long put - expired worthless (Julia: -$60.2)
# Gap in data: Day 25 trading
emit({
    "event_type": "open",
    "timestamp": base_date + timedelta(days=25, hours=4),
    "trader_id": WALLETS["julia"],
    "market_id": "SOL-PUT-80-JAN15",
    "product_type": "option",
    "option_type": "put",
    "strike": 80,
    "expiry": (base_date + timedelta(days=38)).isoformat().replace("+00:00", "Z"),
    "side": "buy",
    "price": 3.0,
    "size": 20,
    "fee_usd": 0.2
}, order_type="market")

# Day 38 - Expires worthless
emit({
    "event_type": "expire",
    "timestamp": base_date + timedelta(days=38),
    "trader_id": WALLETS["julia"],
    "market_id": "SOL-PUT-80-JAN15",
    "product_type": "option",
    "option_type": "put",
    "strike": 80,
    "expiry": (base_date + timedelta(days=38)).isoformat().replace("+00:00", "Z"),
    "side": "expire",
    "price": 0.0,
    "size": 20,
    "fee_usd": 0.0,
    "underlying_price": 95
})

# Day 27 - Partial close scenario (Alice: +$39 + $69 = $108)
# Demonstrates position splitting - same position_id for both closes
emit({
    "event_type": "open",
    "timestamp": base_date + timedelta(days=26, hours=5),
    "trader_id": WALLETS["alice"],
    "market_id": "SOL-CALL-110-JAN15",
    "product_type": "option",
    "option_type": "call",
    "strike": 110,
    "expiry": (base_date + timedelta(days=38)).isoformat().replace("+00:00", "Z"),
    "side": "buy",
    "price": 8.0,
    "size": 20,
    "fee_usd": 1.0
}, order_type="market")

# First partial close - 50% of position
emit({
    "event_type": "close",
    "timestamp": base_date + timedelta(days=27, hours=2),
    "trader_id": WALLETS["alice"],
    "market_id": "SOL-CALL-110-JAN15",
    "product_type": "option",
    "option_type": "call",
    "strike": 110,
    "expiry": (base_date + timedelta(days=38)).isoformat().replace("+00:00", "Z"),
    "side": "sell",
    "price": 12.0,
    "size": 10,
    "fee_usd": 0.5
}, order_type="market")

# Second partial close - remaining 50%
emit({
    "event_type": "close",
    "timestamp": base_date + timedelta(days=28, hours=2),
    "trader_id": WALLETS["alice"],
    "market_id": "SOL-CALL-110-JAN15",
    "product_type": "option",
    "option_type": "call",
    "strike": 110,
    "expiry": (base_date + timedelta(days=38)).isoformat().replace("+00:00", "Z"),
    "side": "sell",
    "price": 15.0,
    "size": 10,
    "fee_usd": 0.5
}, order_type="market")


# ================================================================================
# OPEN POSITIONS - Active trades (will appear in dashboard)
# ================================================================================

# Recent open position - 2 days ago
emit({
    "event_type": "open",
    "timestamp": now - timedelta(days=2, hours=7),
    "trader_id": WALLETS["alice"],
    "market_id": "BTC/USDC",
    "product_type": "spot",
    "side": "buy",
    "price": 51000,
    "size": 0.5,
    "fee_usd": 5.0
}, order_type="market")

# Open position - 1 day ago
emit({
    "event_type": "open",
    "timestamp": now - timedelta(days=1, hours=8),
    "trader_id": WALLETS["bob"],
    "market_id": "AVAX-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 35.5,
    "size": 100,
    "fee_usd": 1.5
}, order_type="limit")

# Open position - 12 hours ago
emit({
    "event_type": "open",
    "timestamp": now - timedelta(hours=12),
    "trader_id": WALLETS["charlie"],
    "market_id": "ETH-CALL-2200-FEB13",
    "product_type": "option",
    "option_type": "call",
    "strike": 2200,
    "expiry": (now + timedelta(days=15)).isoformat().replace("+00:00", "Z"),
    "side": "buy",
    "price": 85.0,
    "size": 3,
    "fee_usd": 0.5
}, order_type="limit")


# ================================================================================
# EDGE CASES - Robustness testing for validation layer
# ================================================================================

# Duplicate open - tests duplicate detection
# Same trader, market, and timestamp as Day 1 trade
emit({
    "event_type": "open",
    "timestamp": base_date + timedelta(days=5, minutes=60),
    "trader_id": WALLETS["alice"],
    "market_id": "SOL/USDC",
    "product_type": "spot",
    "side": "buy",
    "price": 105,
    "size": 5,
    "fee_usd": 0.3
}, order_type="stop")

# Close without open - tests orphaned close detection
# Uses non-existent trader and market combination
emit({
    "event_type": "close",
    "timestamp": base_date + timedelta(days=10, hours=10),
    "trader_id": "GhostWallet1111111111111111111111111111",
    "market_id": "GHOST-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 999,
    "size": 1,
    "fee_usd": 0.1
}, order_type="stop")

# Trade events - market maker activity (informational only)
# These won't be matched to positions but provide market context
emit({
    "event_type": "trade",
    "timestamp": base_date + timedelta(days=3, minutes=15),
    "trader_id": "MarketMaker1111111111111111111111111",
    "market_id": "SOL/USDC",
    "product_type": "spot",
    "side": "buy",
    "price": 101,
    "size": 100,
    "fee_usd": 1.0
})

emit({
    "event_type": "trade",
    "timestamp": base_date + timedelta(days=8, minutes=45),
    "trader_id": "MarketMaker1111111111111111111111111",
    "market_id": "ETH-PERP",
    "product_type": "perp",
    "side": "sell",
    "price": 2105,
    "size": 50,
    "fee_usd": 5.0
})


# ================================================================================
# WRITE OUTPUT
# ================================================================================

with open(OUTPUT_PATH, "w", encoding="utf-8") as f:
    json.dump(events, f, indent=2)

print(f"âœ… Generated {len(events)} curated mock events â†’ {OUTPUT_PATH}")
print(f"\nðŸ“Š Data Summary:")
print(f"   Wallets: {len(WALLETS)} realistic Solana addresses")
print(f"   Date Range: {base_date.strftime('%Y-%m-%d')} to {now.strftime('%Y-%m-%d')} (30 days)")
print(f"   Closed Positions: 18 (spot: 2, perp: 4, options: 7, liquidations: 5)")
print(f"   Open Positions: 3 (spot: 1, perp: 1, option: 1)")
print(f"   Partial Closes: 1 (Alice's SOL-CALL-110 split into 2 closes)")
print(f"\nðŸ” Blockchain Features:")
print(f"   Transaction Signatures: {len([e for e in events if 'tx_hash' in e])} (Solana base58 format)")
print(f"   Position IDs: Unique identifiers for trade matching")
print(f"   Entry Prices: Preserved on close events for PnL accuracy")
print(f"\nâš ï¸ Risk Analysis:")
print(f"   Liquidation Events: 5 (detailed analysis enabled)")
print(f"   Total Liquidation Loss: ~$5,900")
print(f"\nðŸ§ª Data Quality:")
print(f"   Date Gaps: Yes (realistic trading patterns)")
print(f"   Edge Cases: 3 (duplicate open, orphaned close, market maker trades)")
print(f"   Format: JSON array - ready for validation pipeline")


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\scripts\launch_dashboard.py =====

# scripts/launch_dashboard.py

import streamlit as st
from dashboards.app import run_app
from src.common.logging import get_logger
from configs.loader import load_config

logger = get_logger(__name__)


def main():
    config = load_config("configs/dashboard.yaml")

    logger.info("Launching analytics dashboard")

    st.set_page_config(
        page_title="Deriverse Trading Analytics",
        layout="wide"
    )

    run_app(config)


if __name__ == "__main__":
    main()


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\scripts\run_analytics.py =====

# scripts/run_analytics.py - WITH OPEN POSITIONS SUPPORT
import pandas as pd
from pathlib import Path
import io
import logging
import sys
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.analytics.pnl_engine import compute_realized_pnl
from src.analytics.summary import compute_executive_summary
from src.analytics.analytics_builder import AnalyticsBuilder

logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

NORMALIZED_EVENTS_PATH = Path("data/normalized/events.jsonl")
ANALYTICS_OUTPUT_DIR = Path("data/analytics_output")


def load_events(path: Path) -> pd.DataFrame:
    """Load events from JSONL file with flexible timestamp parsing."""
    events = []
    with open(path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if line:
                events.append(pd.read_json(io.StringIO(line), typ="series"))
    
    if not events:
        logger.warning(f"No events found in {path}")
        return pd.DataFrame()
    
    df = pd.DataFrame(events)
    
    try:
        df["timestamp"] = pd.to_datetime(df["timestamp"], format='ISO8601', utc=True)
    except Exception as e:
        logger.warning(f"ISO8601 parsing failed, trying mixed format: {e}")
        df["timestamp"] = pd.to_datetime(df["timestamp"], format='mixed', utc=True)
    
    return df


def run_analytics(events_df, auto_summary=True):
    if events_df.empty:
        logger.error("No events to analyze")
        return None, None, None
    
    logger.info(f"Loaded {len(events_df)} events")

    logger.info("Computing realized PnL (truth engine)")
    positions_df, pnl_df, open_positions_df = compute_realized_pnl(events_df)  # âœ… NOW RETURNS 3 VALUES

    # Build all analytics outputs
    logger.info("Building comprehensive analytics tables...")
    builder = AnalyticsBuilder(positions_df, pnl_df, open_positions_df, ANALYTICS_OUTPUT_DIR)  # âœ… PASS OPEN POSITIONS
    builder.build_all()

    if not positions_df.empty and auto_summary:
        summary = compute_executive_summary(positions_df, pnl_df)
        
        print("\n" + "=" * 50)
        print("EXECUTIVE SUMMARY")
        print("=" * 50)
        print(f"Total Realized PnL:  ${summary['total_pnl']:,.2f}")
        print(f"Total Fees Paid:     ${summary['total_fees']:,.2f}")
        print(f"Total Trades:        {summary['trade_count']}")
        print(f"Win Rate:            {summary['win_rate']:.1%}")
        print(f"Avg Win:             ${summary['avg_win']:,.2f}")
        print(f"Avg Loss:            ${summary['avg_loss']:,.2f}")
        print(f"Best Trade:          ${summary['best_trade']:,.2f}")
        print(f"Worst Trade:         ${summary['worst_trade']:,.2f}")
        print(f"Avg Duration:        {summary['avg_duration']}")
        print(f"Long Ratio:          {summary['long_ratio']:.1%}")
        print(f"Short Ratio:         {summary['short_ratio']:.1%}")
        print(f"Max Drawdown:        ${summary['max_drawdown']:,.2f}")
        
        if 'sharpe_ratio' in summary:
            print(f"Sharpe Ratio:        {summary['sharpe_ratio']:.2f}")
        if 'sortino_ratio' in summary:
            print(f"Sortino Ratio:       {summary['sortino_ratio']:.2f}")
        
        print("=" * 50 + "\n")
    
    # âœ… Show open positions summary
    if not open_positions_df.empty:
        print(f"ðŸ“Š OPEN POSITIONS: {len(open_positions_df)} positions still active")
        for _, pos in open_positions_df.iterrows():
            trader_short = pos['trader_id'][:8] + "..." if len(pos['trader_id']) > 12 else pos['trader_id']
            print(f"  â€¢ {trader_short} | {pos['market_id']:20} | {pos['side']:5} | ${pos['entry_price']:>8,.2f} Ã— {pos['size']:.2f}")

    logger.info("Analytics run complete âœ…")
    return positions_df, pnl_df, open_positions_df


def main():
    logger.info("=" * 60)
    logger.info("Starting Deriverse Analytics Pipeline")
    logger.info("=" * 60)

    if not NORMALIZED_EVENTS_PATH.exists():
        logger.error(f"Normalized events not found at {NORMALIZED_EVENTS_PATH}")
        logger.error("Run 'python -m scripts.generate_mock_data' first")
        return

    events_df = load_events(NORMALIZED_EVENTS_PATH)
    run_analytics(events_df)


if __name__ == "__main__":
    main()


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\scripts\run_ingestion.py =====


# scripts/run_ingestion.py
import logging
from src.ingestion.pipelines import IngestionPipeline
from configs.loader import load_config

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def main():
    logger.info("Starting incremental ingestion")

    config = load_config("configs/ingestion.yaml")
    
    pipeline = IngestionPipeline(
        raw_path=config["raw_data_path"],
        output_path=config["normalized_output_path"],
        checkpoint_path=config["checkpoint_path"],
    )

    count = pipeline.run()
    logger.info(f"Ingested {count} new events")


if __name__ == "__main__":
    main()


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\scripts\validate_analytics.py =====

# scripts/validate_analytics.py
"""
Validation script to verify analytics output quality and correctness.
Run after python -m scripts.run_analytics
"""

import pandas as pd
from pathlib import Path
import sys

OUTPUT_DIR = Path("data/analytics_output")

class bcolors:
    OK = '\033[92m'
    FAIL = '\033[91m'
    WARN = '\033[93m'
    END = '\033[0m'

def validate_file_exists(filename):
    """Check if required file exists."""
    path = OUTPUT_DIR / filename
    if path.exists():
        print(f"{bcolors.OK}âœ“{bcolors.END} {filename} exists")
        return True
    else:
        print(f"{bcolors.FAIL}âœ—{bcolors.END} {filename} missing")
        return False

def validate_positions():
    """Validate positions.csv structure and data quality."""
    df = pd.read_csv(OUTPUT_DIR / "positions.csv")
    
    required_cols = [
        'position_id', 'trader_id', 'market_id', 'product_type', 'side',
        'open_time', 'close_time', 'duration_seconds',
        'entry_price', 'exit_price', 'size', 'gross_pnl', 'fees', 'realized_pnl'
    ]
    
    issues = []
    
    # Check columns
    missing_cols = set(required_cols) - set(df.columns)
    if missing_cols:
        issues.append(f"Missing columns: {missing_cols}")
    
    # Check data quality
    if not df.empty:
        if (df['duration_seconds'] < 0).any():
            issues.append("Negative duration_seconds found")
        
        if (df['fees'] < 0).any():
            issues.append("Negative fees found")
        
        # PnL consistency check
        expected_pnl = df['gross_pnl'] - df['fees']
        if not expected_pnl.equals(df['realized_pnl']):
            max_diff = abs(expected_pnl - df['realized_pnl']).max()
            if max_diff > 0.01:  # Allow for rounding
                issues.append(f"PnL inconsistency detected (max diff: {max_diff:.4f})")
    
    if issues:
        print(f"{bcolors.WARN}âš {bcolors.END} positions.csv has issues:")
        for issue in issues:
            print(f"  - {issue}")
        return False
    else:
        print(f"{bcolors.OK}âœ“{bcolors.END} positions.csv is valid ({len(df)} rows)")
        return True

def validate_summary_metrics():
    """Validate summary_metrics.csv calculations."""
    positions = pd.read_csv(OUTPUT_DIR / "positions.csv")
    summary = pd.read_csv(OUTPUT_DIR / "summary_metrics.csv")
    
    issues = []
    
    for _, row in summary.iterrows():
        trader = row['trader_id']
        trader_pos = positions[positions['trader_id'] == trader]
        
        # Validate win rate
        actual_wins = (trader_pos['realized_pnl'] > 0).sum()
        actual_total = len(trader_pos)
        expected_win_rate = actual_wins / actual_total if actual_total > 0 else 0
        
        if abs(row['win_rate'] - expected_win_rate) > 0.01:
            issues.append(f"{trader}: win_rate mismatch ({row['win_rate']:.2f} vs {expected_win_rate:.2f})")
        
        # Validate long/short ratio
        if abs(row['long_ratio'] + row['short_ratio'] - 1.0) > 0.01:
            issues.append(f"{trader}: long_ratio + short_ratio != 1.0")
        
        # Validate total_pnl
        expected_total = trader_pos['realized_pnl'].sum()
        if abs(row['total_pnl'] - expected_total) > 0.01:
            issues.append(f"{trader}: total_pnl mismatch")
    
    if issues:
        print(f"{bcolors.WARN}âš {bcolors.END} summary_metrics.csv has issues:")
        for issue in issues:
            print(f"  - {issue}")
        return False
    else:
        print(f"{bcolors.OK}âœ“{bcolors.END} summary_metrics.csv is valid")
        return True

def validate_equity_curve():
    """Validate equity_curve.csv drawdown calculations."""
    df = pd.read_csv(OUTPUT_DIR / "equity_curve.csv")
    
    issues = []
    
    for trader in df['trader_id'].unique():
        trader_data = df[df['trader_id'] == trader].sort_values('timestamp')
        
        # Validate drawdown is always <= 0
        if (trader_data['drawdown'] > 0.01).any():
            issues.append(f"{trader}: Positive drawdown found")
        
        # Validate cumulative PnL is monotonic sum
        if not trader_data['cumulative_pnl'].is_monotonic_increasing and not trader_data['cumulative_pnl'].is_monotonic_decreasing:
            # This is actually OK - cumulative can go up and down
            pass
    
    if issues:
        print(f"{bcolors.WARN}âš {bcolors.END} equity_curve.csv has issues:")
        for issue in issues:
            print(f"  - {issue}")
        return False
    else:
        print(f"{bcolors.OK}âœ“{bcolors.END} equity_curve.csv is valid")
        return True

def validate_directional_bias():
    """Validate directional_bias.csv calculations."""
    df = pd.read_csv(OUTPUT_DIR / "directional_bias.csv")
    
    issues = []
    
    for _, row in df.iterrows():
        total = row['long_trades'] + row['short_trades']
        
        if total == 0:
            issues.append(f"{row['trader_id']}: No trades")
            continue
        
        expected_long_ratio = row['long_trades'] / total
        expected_short_ratio = row['short_trades'] / total
        
        if abs(row['long_ratio'] - expected_long_ratio) > 0.01:
            issues.append(f"{row['trader_id']}: long_ratio calculation error")
        
        if abs(row['short_ratio'] - expected_short_ratio) > 0.01:
            issues.append(f"{row['trader_id']}: short_ratio calculation error")
        
        if abs(row['long_ratio'] + row['short_ratio'] - 1.0) > 0.01:
            issues.append(f"{row['trader_id']}: ratios don't sum to 1.0")
    
    if issues:
        print(f"{bcolors.WARN}âš {bcolors.END} directional_bias.csv has issues:")
        for issue in issues:
            print(f"  - {issue}")
        return False
    else:
        print(f"{bcolors.OK}âœ“{bcolors.END} directional_bias.csv is valid")
        return True

def main():
    print("\n" + "=" * 60)
    print("DERIVERSE ANALYTICS VALIDATION")
    print("=" * 60 + "\n")
    
    if not OUTPUT_DIR.exists():
        print(f"{bcolors.FAIL}âœ—{bcolors.END} Output directory not found: {OUTPUT_DIR}")
        print("Run: python -m scripts.run_analytics")
        sys.exit(1)
    
    # Check file existence
    print("Checking required files...")
    required_files = [
        'positions.csv',
        'realized_pnl.csv',
        'equity_curve.csv',
        'summary_metrics.csv',
        'volume_by_market.csv',
        'fees_breakdown.csv',
        'pnl_by_day.csv',
        'pnl_by_hour.csv',
        'directional_bias.csv',
        'order_type_performance.csv'
    ]
    
    all_exist = all(validate_file_exists(f) for f in required_files)
    
    if not all_exist:
        print(f"\n{bcolors.FAIL}âœ— Some files are missing{bcolors.END}")
        sys.exit(1)
    
    print("\nValidating data quality...")
    
    validations = [
        validate_positions(),
        validate_summary_metrics(),
        validate_equity_curve(),
        validate_directional_bias()
    ]
    
    print("\n" + "=" * 60)
    if all(validations):
        print(f"{bcolors.OK}âœ“ ALL VALIDATIONS PASSED{bcolors.END}")
        print("=" * 60 + "\n")
        sys.exit(0)
    else:
        print(f"{bcolors.WARN}âš  SOME VALIDATIONS FAILED{bcolors.END}")
        print("=" * 60 + "\n")
        sys.exit(1)

if __name__ == "__main__":
    main()


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\analytics\trades\__init__.py =====



===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\analytics\analytics_builder.py =====

# src/analytics/analytics_builder.py - FIXED DELTA CALCULATIONS
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
import logging

logger = logging.getLogger(__name__)


class AnalyticsBuilder:
    """Build all required analytics tables from canonical PnL engine outputs."""
    
    def __init__(self, positions_df: pd.DataFrame, pnl_df: pd.DataFrame, 
                 open_positions_df: pd.DataFrame, output_dir: Path):
        self.positions = positions_df.copy() if not positions_df.empty else pd.DataFrame()
        self.pnl = pnl_df.copy() if not pnl_df.empty else pd.DataFrame()
        self.open_positions = open_positions_df.copy() if not open_positions_df.empty else pd.DataFrame()
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # Ensure timestamps are datetime
        if not self.positions.empty:
            self.positions['open_time'] = pd.to_datetime(self.positions['open_time'])
            self.positions['close_time'] = pd.to_datetime(self.positions['close_time'])
            self.positions['duration_seconds'] = (
                self.positions['close_time'] - self.positions['open_time']
            ).dt.total_seconds()
    
    def build_all(self):
        """Generate all required analytics outputs."""
        logger.info("Building core truth tables...")
        self._build_positions()
        self._build_realized_pnl()
        self._build_open_positions()
        
        if self.positions.empty:
            logger.warning("No closed positions - generating empty analytics")
            self._generate_empty_outputs()
            return
        
        logger.info("Building performance metrics...")
        self._build_equity_curve()
        self._build_summary_metrics()
        
        logger.info("Building volume & fees analytics...")
        self._build_volume_by_market()
        self._build_fees_breakdown()
        
        logger.info("Building time-based analytics...")
        self._build_pnl_by_day()
        self._build_pnl_by_hour()
        
        logger.info("Building behavioral analytics...")
        self._build_directional_bias()
        self._build_order_type_performance()
        
        logger.info("Building options Greeks...")
        self._build_greeks_exposure()
        
        logger.info(f"âœ… All analytics saved to {self.output_dir}")
    
    def _build_positions(self):
        """1. Core Truth: positions.csv"""
        if self.positions.empty:
            pd.DataFrame().to_csv(self.output_dir / 'positions.csv', index=False)
            return
        
        output = self.positions[[
            'position_id', 'trader_id', 'market_id', 'product_type', 'side',
            'open_time', 'close_time', 'duration_seconds',
            'entry_price', 'exit_price', 'size', 'gross_pnl', 'fees', 'realized_pnl',
            'close_reason' 
        ]].copy()
        output.to_csv(self.output_dir / 'positions.csv', index=False)
    
    def _build_realized_pnl(self):
        """2. Core Truth: realized_pnl.csv"""
        if self.positions.empty:
            pd.DataFrame().to_csv(self.output_dir / 'realized_pnl.csv', index=False)
            return
            
        output = self.positions[[
            'close_time', 'trader_id', 'market_id', 'realized_pnl', 'fees'
        ]].copy()
        output.rename(columns={'close_time': 'timestamp'}, inplace=True)
        output['net_pnl'] = output['realized_pnl'] - output['fees']
        output = output[['timestamp', 'trader_id', 'market_id', 'realized_pnl', 'fees', 'net_pnl']]
        output.to_csv(self.output_dir / 'realized_pnl.csv', index=False)
    
    def _build_open_positions(self):
        """âœ… NEW: open_positions.csv - Currently active positions"""
        if self.open_positions.empty:
            pd.DataFrame().to_csv(self.output_dir / 'open_positions.csv', index=False)
            logger.info("No open positions")
            return
        
        output = self.open_positions[[
            'position_id', 'trader_id', 'market_id', 'product_type', 'side',
            'entry_price', 'size', 'fees_paid', 'open_time', 'time_held_seconds'
        ]].copy()
        
        output.to_csv(self.output_dir / 'open_positions.csv', index=False)
        logger.info(f"Saved {len(output)} open positions")
    
    def _build_equity_curve(self):
        """3. Performance: equity_curve.csv"""
        equity = self.positions.copy()
        equity = equity.sort_values('close_time')
        
        result = []
        for trader in equity['trader_id'].unique():
            trader_data = equity[equity['trader_id'] == trader].copy()
            trader_data['cumulative_pnl'] = trader_data['realized_pnl'].cumsum()
            trader_data['rolling_max'] = trader_data['cumulative_pnl'].cummax()
            trader_data['drawdown'] = trader_data['cumulative_pnl'] - trader_data['rolling_max']
            
            for _, row in trader_data.iterrows():
                result.append({
                    'timestamp': row['close_time'],
                    'trader_id': row['trader_id'],
                    'net_realized_pnl': row['realized_pnl'],
                    'cumulative_pnl': row['cumulative_pnl'],
                    'drawdown': row['drawdown']
                })
        
        df = pd.DataFrame(result)
        df.to_csv(self.output_dir / 'equity_curve.csv', index=False)
    
    def _build_summary_metrics(self):
        """4. Performance: summary_metrics.csv"""
        result = []
        
        for trader in self.positions['trader_id'].unique():
            trader_pos = self.positions[self.positions['trader_id'] == trader]
            
            winning = trader_pos[trader_pos['realized_pnl'] > 0]
            losing = trader_pos[trader_pos['realized_pnl'] < 0]
            
            total_pnl = trader_pos['realized_pnl'].sum()
            total_fees = trader_pos['fees'].sum()
            trade_count = len(trader_pos)
            win_rate = len(winning) / trade_count if trade_count > 0 else 0
            avg_win = winning['realized_pnl'].mean() if len(winning) > 0 else 0
            avg_loss = losing['realized_pnl'].mean() if len(losing) > 0 else 0
            best_trade = trader_pos['realized_pnl'].max()
            worst_trade = trader_pos['realized_pnl'].min()
            avg_duration = trader_pos['duration_seconds'].mean()
            
            long_trades = trader_pos[trader_pos['side'].isin(['long', 'buy'])]
            short_trades = trader_pos[trader_pos['side'].isin(['short', 'sell'])]
            long_ratio = len(long_trades) / trade_count if trade_count > 0 else 0
            short_ratio = len(short_trades) / trade_count if trade_count > 0 else 0
            
            trader_sorted = trader_pos.sort_values('close_time')
            cum_pnl = trader_sorted['realized_pnl'].cumsum()
            rolling_max = cum_pnl.cummax()
            drawdown = cum_pnl - rolling_max
            max_drawdown = drawdown.min()
            
            if len(trader_pos) > 1:
                trader_daily = trader_pos.copy()
                trader_daily['date'] = trader_daily['close_time'].dt.date
                daily_returns = trader_daily.groupby('date')['realized_pnl'].sum()
                
                mean_return = daily_returns.mean()
                std_return = daily_returns.std()
                sharpe_ratio = mean_return / std_return if std_return > 0 else 0
                
                downside_returns = daily_returns[daily_returns < 0]
                downside_std = downside_returns.std() if len(downside_returns) > 0 else std_return
                sortino_ratio = mean_return / downside_std if downside_std > 0 else 0
            else:
                sharpe_ratio = 0
                sortino_ratio = 0
            
            result.append({
                'trader_id': trader,
                'total_pnl': total_pnl,
                'total_fees': total_fees,
                'trade_count': trade_count,
                'win_rate': win_rate,
                'avg_win': avg_win,
                'avg_loss': avg_loss,
                'best_trade': best_trade,
                'worst_trade': worst_trade,
                'avg_duration_seconds': avg_duration,
                'long_ratio': long_ratio,
                'short_ratio': short_ratio,
                'max_drawdown': max_drawdown,
                'sharpe_ratio': sharpe_ratio,
                'sortino_ratio': sortino_ratio
            })
        
        df = pd.DataFrame(result)
        df.to_csv(self.output_dir / 'summary_metrics.csv', index=False)
    
    def _build_volume_by_market(self):
        """5. Volume: volume_by_market.csv"""
        result = []
        
        for (market, product), group in self.positions.groupby(['market_id', 'product_type']):
            total_volume = (group['exit_price'] * group['size']).sum()
            trade_count = len(group)
            
            result.append({
                'market_id': market,
                'product_type': product,
                'total_volume': total_volume,
                'trade_count': trade_count
            })
        
        df = pd.DataFrame(result)
        df.to_csv(self.output_dir / 'volume_by_market.csv', index=False)
    
    def _build_fees_breakdown(self):
        """6. Fees: fees_breakdown.csv"""
        result = []
        
        for (trader, product), group in self.positions.groupby(['trader_id', 'product_type']):
            total_fees = group['fees'].sum()
            
            result.append({
                'trader_id': trader,
                'product_type': product,
                'total_fees': total_fees
            })
        
        df = pd.DataFrame(result)
        df.to_csv(self.output_dir / 'fees_breakdown.csv', index=False)
    
    def _build_pnl_by_day(self):
        """7. Time Analytics: pnl_by_day.csv"""
        df = self.positions.copy()
        df['date'] = df['close_time'].dt.date
        
        result = []
        for (date, trader), group in df.groupby(['date', 'trader_id']):
            daily_pnl = group['realized_pnl'].sum()
            
            trader_data = df[df['trader_id'] == trader]
            trader_data = trader_data[trader_data['date'] <= date]
            cumulative_pnl = trader_data['realized_pnl'].sum()
            
            result.append({
                'date': date,
                'trader_id': trader,
                'daily_pnl': daily_pnl,
                'cumulative_pnl': cumulative_pnl
            })
        
        output = pd.DataFrame(result)
        output.to_csv(self.output_dir / 'pnl_by_day.csv', index=False)
    
    def _build_pnl_by_hour(self):
        """8. Time Analytics: pnl_by_hour.csv"""
        df = self.positions.copy()
        df['hour_of_day'] = df['close_time'].dt.hour
        
        result = []
        for (hour, trader), group in df.groupby(['hour_of_day', 'trader_id']):
            avg_pnl = group['realized_pnl'].mean()
            trade_count = len(group)
            
            result.append({
                'hour_of_day': hour,
                'trader_id': trader,
                'avg_pnl': avg_pnl,
                'trade_count': trade_count
            })
        
        output = pd.DataFrame(result)
        output.to_csv(self.output_dir / 'pnl_by_hour.csv', index=False)
    
    def _build_directional_bias(self):
        """9. Behavioral: directional_bias.csv"""
        result = []
        
        for trader, group in self.positions.groupby('trader_id'):
            long_trades = len(group[group['side'].isin(['long', 'buy'])])
            short_trades = len(group[group['side'].isin(['short', 'sell'])])
            total = long_trades + short_trades
            
            result.append({
                'trader_id': trader,
                'long_trades': long_trades,
                'short_trades': short_trades,
                'long_ratio': long_trades / total if total > 0 else 0,
                'short_ratio': short_trades / total if total > 0 else 0
            })
        
        df = pd.DataFrame(result)
        df.to_csv(self.output_dir / 'directional_bias.csv', index=False)
    
    def _build_order_type_performance(self):
        """10. Behavioral: order_type_performance.csv"""
        df = self.positions.copy()
        
        df['order_type'] = df['duration_seconds'].apply(lambda x:
            'market' if x < 300 else
            'limit' if x < 3600 else
            'stop'
        )
        
        result = []
        for order_type, group in df.groupby('order_type'):
            trade_count = len(group)
            avg_pnl = group['realized_pnl'].mean()
            win_rate = (group['realized_pnl'] > 0).mean()
            
            result.append({
                'order_type': order_type,
                'trade_count': trade_count,
                'avg_pnl': avg_pnl,
                'win_rate': win_rate
            })
        
        output = pd.DataFrame(result)
        output.to_csv(self.output_dir / 'order_type_performance.csv', index=False)
    
    def _build_greeks_exposure(self):
        """11. Greeks: greeks_exposure.csv (options only)"""
        options = self.positions[self.positions['product_type'] == 'option'].copy()
        
        if options.empty:
            pd.DataFrame().to_csv(self.output_dir / 'greeks_exposure.csv', index=False)
            return
        
        result = []
        for trader in options['trader_id'].unique():
            trader_opts = options[options['trader_id'] == trader]
            
            net_delta = 0
            net_gamma = 0
            net_theta = 0
            
            for _, opt in trader_opts.iterrows():
                # Position direction multiplier
                if opt['side'] in ['buy', 'long']:
                    direction = 1
                else:  # sell/short
                    direction = -1
                
                if 'delta' in opt and pd.notna(opt['delta']):
                    # Use provided delta (already accounts for call/put sign)
                    option_delta = opt['delta']
                else:
                    # Fallback: estimate based on option type
                    if 'option_type' in opt and pd.notna(opt['option_type']):
                        if opt['option_type'] == 'call':
                            option_delta = 0.5  # Assume ATM call (positive)
                        else:  # put
                            option_delta = -0.5  # Assume ATM put (negative)
                    else:
                        option_delta = 0.5  # Default fallback
                
                # Calculate position delta: direction Ã— delta Ã— size
                # Example: Buy 10 calls with 0.65 delta = +1 Ã— 0.65 Ã— 10 = +6.5
                # Example: Sell 15 puts with -0.25 delta = -1 Ã— -0.25 Ã— 15 = +3.75
                position_delta = direction * option_delta * opt['size']
                net_delta += position_delta
                
                # Other Greeks (whenever available in data)
                if 'gamma' in opt and pd.notna(opt['gamma']):
                    net_gamma += direction * opt['gamma'] * opt['size']
                
                if 'theta' in opt and pd.notna(opt['theta']):
                    net_theta += direction * opt['theta'] * opt['size']
            
            result.append({
                'trader_id': trader,
                'total_option_positions': len(trader_opts),
                'net_delta': round(net_delta, 4),
                'gamma_exposure': round(net_gamma, 4),
                'theta_decay': round(net_theta, 4)
            })
        
        df = pd.DataFrame(result)
        df.to_csv(self.output_dir / 'greeks_exposure.csv', index=False)
    
    def _generate_empty_outputs(self):
        """Generate empty CSV files when no data available."""
        empty_files = [
            'equity_curve.csv', 'summary_metrics.csv', 'volume_by_market.csv',
            'fees_breakdown.csv', 'pnl_by_day.csv', 'pnl_by_hour.csv',
            'directional_bias.csv', 'order_type_performance.csv', 'greeks_exposure.csv'
        ]
        
        for filename in empty_files:
            pd.DataFrame().to_csv(self.output_dir / filename, index=False)


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\analytics\debug.py =====

import json
from pathlib import Path
from collections import Counter

def inspect_normalized_data():
    normalized_path = Path("data/normalized/events.jsonl")

    if not normalized_path.exists():
        print("âŒ No normalized data file found.")
        return

    if normalized_path.stat().st_size == 0:
        print("âš ï¸ Normalized file exists but is empty.")
        return

    all_fields = set()
    event_types = Counter()
    sample_events = []

    with normalized_path.open() as f:
        for i, line in enumerate(f):
            event = json.loads(line)
            all_fields.update(event.keys())
            event_types[event.get("event_type")] += 1

            if i < 3:
                sample_events.append(event)

    print("\nðŸ“Š Normalized Data Overview")
    print(f"Total events: {sum(event_types.values())}")

    print("\nEvent types:")
    for et, c in event_types.items():
        print(f"  - {et}: {c}")

    print("\nColumns present:")
    for field in sorted(all_fields):
        print(f"  - {field}")

    print("\nSample events:")
    for i, ev in enumerate(sample_events, 1):
        print(f"\nEvent {i}")
        for k, v in ev.items():
            print(f"  {k}: {v}")


if __name__ == "__main__":
    inspect_normalized_data()


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\analytics\pnl_engine.py =====

# src/analytics/pnl_engine.py
import pandas as pd
import hashlib
import logging
from datetime import datetime, timezone

logger = logging.getLogger(__name__)


def compute_realized_pnl(events: pd.DataFrame):
    """
    Canonical PnL engine with full options lifecycle support.
    NOW RETURNS OPEN POSITIONS TOO!
    
    Returns:
        positions_df: Closed positions with realized PnL
        pnl_df: Daily PnL aggregates
        open_positions_df: Currently open positions (NEW!)
    """

    required_cols = {
        "event_type", "timestamp", "trader_id",
        "market_id", "product_type", "side",
        "price", "size", "fee"
    }

    missing = required_cols - set(events.columns)
    if missing:
        raise ValueError(f"Missing required columns: {missing}")

    events = events.sort_values("timestamp")

    open_positions = {}
    closed_positions = []

    # Validation stats
    stats = {
        "duplicate_opens": 0,
        "close_without_open": 0,
        "oversized_closes": 0,
    }

    for _, event in events.iterrows():

        if event["product_type"] == "perp":
            key = (
                event["trader_id"],
                event["market_id"],
                event["product_type"],
                event["side"]
            )
        elif event["product_type"] == "option":
            key = (
                event["trader_id"],
                event["market_id"],
                event["product_type"]
            )
        else:  # spot
            key = (
                event["trader_id"],
                event["market_id"],
                event["product_type"]
            )

        # OPEN POSITION
        if event["event_type"] == "open":
            if key in open_positions:
                stats["duplicate_opens"] += 1
                continue

            position_data = (
                f"{event['trader_id']}|{event['market_id']}|"
                f"{event['timestamp']}|{event.get('side', '')}"
            )
            position_id = hashlib.sha256(position_data.encode()).hexdigest()[:16]

            open_positions[key] = {
                "position_id": position_id,
                "open_time": event["timestamp"],
                "entry_price": event["price"],
                "size": event["size"],
                "fees": event["fee"],
                "trader_id": event["trader_id"],
                "market_id": event["market_id"],
                "product_type": event["product_type"],
                "side": event["side"],
            }
            
            if event["product_type"] == "option":
                open_positions[key]["option_type"] = event.get("option_type")
                open_positions[key]["strike"] = event.get("strike")
                open_positions[key]["expiry"] = event.get("expiry")

        # CLOSE POSITION
        elif event["event_type"] in {"close", "liquidation", "exercise", "expire"}:
            if key not in open_positions:
                stats["close_without_open"] += 1
                continue

            pos = open_positions[key]
            close_size = event["size"]

            if close_size > pos["size"]:
                stats["oversized_closes"] += 1
                continue

            # Calculate fees
            fee_ratio = close_size / pos["size"]
            allocated_open_fee = pos["fees"] * fee_ratio
            close_fee = event.get("fee", 0)
            total_fees = allocated_open_fee + close_fee

            # OPTIONS PNL
            if pos["product_type"] == "option":
                gross_pnl = calculate_option_pnl(
                    event_type=event["event_type"],
                    option_type=pos.get("option_type"),
                    side=pos["side"],
                    entry_price=pos["entry_price"],
                    exit_price=event.get("price", 0),
                    strike=pos.get("strike"),
                    underlying_price=event.get("underlying_price"),
                    size=close_size
                )
                net_pnl = gross_pnl - total_fees
                exit_price = event.get("price", 0)

            # SPOT/PERP PNL
            else:
                exit_price = event["price"]

                if pd.notna(event.get("pnl")):
                    net_pnl = event["pnl"]
                    gross_pnl = net_pnl + total_fees
                else:
                    if pos["side"] in {"long", "buy"}:
                        gross_pnl = (exit_price - pos["entry_price"]) * close_size
                    else:
                        gross_pnl = (pos["entry_price"] - exit_price) * close_size

                    net_pnl = gross_pnl - total_fees

            # Record closed position
            closed_positions.append({
                "position_id": pos["position_id"],
                "open_time": pos["open_time"],
                "close_time": event["timestamp"],
                "trader_id": pos["trader_id"],
                "market_id": pos["market_id"],
                "product_type": pos["product_type"],
                "side": pos["side"],
                "entry_price": pos["entry_price"],
                "exit_price": exit_price,
                "size": close_size,
                "gross_pnl": round(gross_pnl, 4),
                "net_pnl": round(net_pnl, 4),
                "realized_pnl": round(net_pnl, 4),
                "fees": round(total_fees, 4),
                "close_reason": event["event_type"],
            })

            # Update or remove position
            pos["size"] -= close_size
            pos["fees"] -= allocated_open_fee

            if pos["size"] <= 0:
                open_positions.pop(key)

    positions_df = pd.DataFrame(closed_positions)

    # Log validation summary
    logger.info(
        "PnL validation summary | "
        f"duplicate_opens={stats['duplicate_opens']} | "
        f"close_without_open={stats['close_without_open']} | "
        f"oversized_closes={stats['oversized_closes']}"
    )

    if positions_df.empty:
        positions_df = pd.DataFrame()
        pnl_df = pd.DataFrame()
    else:
        # Build daily PnL aggregates
        pnl_df = (
            positions_df
            .assign(date=lambda df: pd.to_datetime(df["close_time"]).dt.date)
            .groupby(
                ["date", "trader_id", "market_id", "product_type"],
                as_index=False
            )
            .agg(
                net_pnl=("net_pnl", "sum"),
                realized_pnl=("realized_pnl", "sum"),
                fees=("fees", "sum"),
                trade_count=("position_id", "count")
            )
        )

    # âœ… NEW: Build open positions dataframe
    open_positions_list = []
    for key, pos in open_positions.items():
        # Calculate time held
        now = datetime.now(timezone.utc)
        open_time = pd.to_datetime(pos["open_time"])
        if open_time.tzinfo is None:
            open_time = open_time.tz_localize(timezone.utc)
        
        time_held = (now - open_time).total_seconds()
        
        open_positions_list.append({
            "position_id": pos["position_id"],
            "trader_id": pos["trader_id"],
            "market_id": pos["market_id"],
            "product_type": pos["product_type"],
            "side": pos["side"],
            "entry_price": pos["entry_price"],
            "size": pos["size"],
            "fees_paid": pos["fees"],
            "open_time": pos["open_time"],
            "time_held_seconds": time_held
        })
    
    open_positions_df = pd.DataFrame(open_positions_list)

    logger.info(
        f"PnL engine results: {len(positions_df)} closed positions, "
        f"{len(open_positions_df)} still open"
    )

    return positions_df, pnl_df, open_positions_df


def calculate_option_pnl(
    event_type: str,
    option_type: str,
    side: str,
    entry_price: float,
    exit_price: float,
    strike: float,
    underlying_price: float,
    size: float
) -> float:
    """Calculate options PnL based on event type."""
    
    if event_type == "close":
        if side == "buy":
            gross_pnl = (exit_price - entry_price) * size
        else:
            gross_pnl = (entry_price - exit_price) * size
        return gross_pnl
    
    elif event_type == "exercise":
        if side == "buy":
            if option_type == "call":
                intrinsic_value = max(0, underlying_price - strike)
            else:
                intrinsic_value = max(0, strike - underlying_price)
            gross_pnl = (intrinsic_value - entry_price) * size
        else:
            if option_type == "call":
                intrinsic_value = max(0, underlying_price - strike)
            else:
                intrinsic_value = max(0, strike - underlying_price)
            gross_pnl = (entry_price - intrinsic_value) * size
        
        return gross_pnl
    
    elif event_type == "expire":
        if side == "buy":
            gross_pnl = -entry_price * size
        else:
            gross_pnl = entry_price * size
        
        return gross_pnl
    
    return 0.0


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\analytics\summary.py =====

# src/analytics/summary.py
import pandas as pd

def compute_executive_summary(positions: pd.DataFrame, pnl: pd.DataFrame) -> dict:
    """
    Compute high-level KPIs from canonical PnL outputs.
    
    Args:
        positions: Output from compute_realized_pnl (positions_df)
        pnl: Output from compute_realized_pnl (pnl_df)
    
    Returns:
        Dictionary of KPI metrics
    """
    if positions.empty:
        return {"status": "no_data"}
    
    summary = {}
    
    # Core PnL
    summary["total_pnl"] = pnl["net_pnl"].sum()
    summary["total_fees"] = pnl["fees"].sum()
    summary["trade_count"] = len(positions)
    summary["win_rate"] = (positions["net_pnl"] > 0).mean()
    
    # Win/Loss Analysis
    winning_trades = positions[positions["net_pnl"] > 0]
    losing_trades = positions[positions["net_pnl"] < 0]
    
    summary["avg_win"] = winning_trades["net_pnl"].mean() if len(winning_trades) > 0 else 0
    summary["avg_loss"] = losing_trades["net_pnl"].mean() if len(losing_trades) > 0 else 0
    summary["best_trade"] = positions["net_pnl"].max()
    summary["worst_trade"] = positions["net_pnl"].min()
    
    # Duration Analysis
    positions = positions.copy()
    positions["duration"] = (
        pd.to_datetime(positions["close_time"]) - 
        pd.to_datetime(positions["open_time"])
    )
    summary["avg_duration"] = positions["duration"].mean()
    
    # Directional Bias
    summary["long_ratio"] = (positions["side"].isin(["long", "buy"])).mean()
    summary["short_ratio"] = (positions["side"].isin(["short", "sell"])).mean()
    
    # Drawdown
    pnl_sorted = pnl.sort_values("date")
    pnl_sorted["cum_pnl"] = pnl_sorted["net_pnl"].cumsum()
    pnl_sorted["drawdown"] = pnl_sorted["cum_pnl"] - pnl_sorted["cum_pnl"].cummax()
    summary["max_drawdown"] = pnl_sorted["drawdown"].min()
    
    # âœ… NEW: Risk-Adjusted Returns
    if not pnl.empty and len(pnl) > 1:
        daily_returns = pnl.groupby('date')['net_pnl'].sum()
        
        # Sharpe Ratio (assuming risk-free rate = 0)
        mean_return = daily_returns.mean()
        std_return = daily_returns.std()
        sharpe_ratio = mean_return / std_return if std_return > 0 else 0
        summary["sharpe_ratio"] = sharpe_ratio
        
        # Sortino Ratio (downside deviation only)
        downside_returns = daily_returns[daily_returns < 0]
        downside_std = downside_returns.std() if len(downside_returns) > 0 else std_return
        sortino_ratio = mean_return / downside_std if downside_std > 0 else 0
        summary["sortino_ratio"] = sortino_ratio
    else:
        summary["sharpe_ratio"] = 0
        summary["sortino_ratio"] = 0
    
    return summary


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\analytics\validate.py =====

# src/analytics/validate.py - WITH LIQUIDATION SUPPORT
from typing import Dict, Any, Set
from datetime import datetime

class EventValidationError(Exception):
    """Raised when event fails validation."""
    pass

# --- Base required fields for ALL events ---
BASE_REQUIRED_FIELDS = {
    "event_id",
    "event_type",
    "timestamp",
    "trader_id",
    "market_id",
    "product_type"
}

# --- Base optional fields for ALL events ---
BASE_OPTIONAL_FIELDS = {
    "side",
    "price",
    "size",
    "fee",
    "pnl",
    "order_type"
}

# --- Option-specific fields ---
OPTION_REQUIRED_FIELDS = {
    "option_type",
    "strike",
    "expiry"
}

OPTION_OPTIONAL_FIELDS = {
    "delta",
    "gamma",
    "theta",
    "vega",
    "implied_vol",
    "underlying_price"
}

# --- Event type schemas ---
EVENT_TYPE_SCHEMAS = {
    "trade": {
        "required": {"side", "price", "size", "fee"},
        "optional": {"pnl"}
    },
    "open": {
        "required": {"side", "price", "size", "fee"},
        "optional": {"pnl", "order_type"}
    },
    "close": {
        "required": {"side", "price", "size", "fee"},
        "optional": {"pnl", "order_type"}
    },
    "liquidation": {  # âœ… NEW: Liquidation event schema
        "required": {"side", "price", "size", "fee"},
        "optional": {"pnl", "order_type"}
    },
    "exercise": {
        "required": {"side", "size", "fee"},
        "optional": {"price", "pnl", "underlying_price"}
    },
    "expire": {
        "required": {"side", "size"},
        "optional": {"price", "fee", "pnl", "underlying_price"}
    }
}


def validate_event(event: dict) -> None:
    """
    Validate event schema and data quality.
    
    Raises:
        EventValidationError: If validation fails
    """
    event_type = event.get("event_type")
    product_type = event.get("product_type")

    # Trade events are informational only - skip position validation
    if event_type == "trade":
        return

    # Validate product type
    valid_products = {"spot", "perp", "option"}
    if product_type not in valid_products:
        raise EventValidationError(
            f"Invalid product_type: {product_type}. Allowed: {valid_products}"
        )

    # Product-specific side validation
    if product_type == "option":
        allowed_sides = {"buy", "sell", "long", "short", "exercise", "expire"}
    elif product_type == "perp":
        allowed_sides = {"long", "short"}
    elif product_type == "spot":
        allowed_sides = {"buy", "sell"}
    
    side = event.get("side")
    if side and side not in allowed_sides:
        raise EventValidationError(
            f"Invalid side '{side}' for product_type '{product_type}'. "
            f"Must be one of: {allowed_sides}"
        )

    # Build allowed fields based on product type
    allowed_fields = BASE_REQUIRED_FIELDS | BASE_OPTIONAL_FIELDS
    
    if product_type == "option":
        allowed_fields |= OPTION_REQUIRED_FIELDS | OPTION_OPTIONAL_FIELDS
    
    # Add event-specific fields
    if event_type in EVENT_TYPE_SCHEMAS:
        schema = EVENT_TYPE_SCHEMAS[event_type]
        allowed_fields |= schema["required"] | schema["optional"]

    # Check for extra fields (schema drift)
    extra_fields = set(event.keys()) - allowed_fields
    if extra_fields:
        raise EventValidationError(
            f"Unexpected fields detected: {extra_fields}. "
            f"Allowed for {product_type}/{event_type}: {allowed_fields}"
        )

    # Check event-type-specific required fields
    if event_type in EVENT_TYPE_SCHEMAS:
        schema = EVENT_TYPE_SCHEMAS[event_type]
        missing_required = schema["required"] - set(event.keys())
        if missing_required:
            raise EventValidationError(
                f"Event type '{event_type}' missing required fields: {missing_required}"
            )

    # Check option-specific required fields
    if product_type == "option":
        missing_option_required = OPTION_REQUIRED_FIELDS - set(event.keys())
        if missing_option_required:
            raise EventValidationError(
                f"Option product missing required fields: {missing_option_required}"
            )

    # Validate timestamp format
    try:
        timestamp_str = event["timestamp"]
        if timestamp_str.endswith("Z"):
            timestamp_str = timestamp_str.replace("Z", "+00:00")
        datetime.fromisoformat(timestamp_str)
    except (ValueError, AttributeError, TypeError) as e:
        raise EventValidationError(f"Invalid timestamp format: {event.get('timestamp')} - {e}")

    # Validate numeric fields
    numeric_fields = {"price", "size", "fee", "pnl", "strike", "delta", "gamma", 
                     "theta", "vega", "implied_vol", "underlying_price"}
    for field in numeric_fields & event.keys():
        value = event[field]
        if value is not None and not isinstance(value, (int, float)):
            raise EventValidationError(
                f"Field '{field}' must be numeric or null, got {type(value)}: {value}"
            )

    # Validate option-specific values
    if product_type == "option":
        # Validate option_type
        option_type = event.get("option_type")
        if option_type not in {"call", "put"}:
            raise EventValidationError(f"Invalid option_type: {option_type}. Must be 'call' or 'put'")
        
        # Validate expiry format
        expiry = event.get("expiry")
        if expiry:
            try:
                if expiry.endswith("Z"):
                    expiry = expiry.replace("Z", "+00:00")
                datetime.fromisoformat(expiry)
            except (ValueError, AttributeError):
                raise EventValidationError(f"Invalid expiry format: {expiry}")


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\analytics\__init__.py =====



===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\common\logging.py =====

import logging

def get_logger(name):
    logger = logging.getLogger(name)
    if not logger.handlers:
        handler = logging.StreamHandler()
        formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        logger.setLevel(logging.INFO)
    return logger


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\common\__init__.py =====



===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\ingestion\normalizer.py =====

# src/ingestion/normalizer.py
from typing import Dict, Any
from datetime import datetime, timezone
import hashlib

def normalize_event(raw_event: Dict[str, Any]) -> Dict[str, Any]:
    """
    Normalize raw event data into canonical schema.
    - Convert keys to expected schema names
    - Convert timestamps to ISO 8601
    - Ensure event_id exists
    - Handle option-specific fields
    - Normalize position terminology (longâ†’buy, shortâ†’sell for options/spot)
    """
    event = raw_event.copy()

    # --- Normalize timestamp ---
    ts = event.get("timestamp")
    if isinstance(ts, (int, float)):
        # Convert Unix timestamp (seconds) to ISO 8601 UTC
        event["timestamp"] = datetime.fromtimestamp(ts, tz=timezone.utc).isoformat()
    elif isinstance(ts, datetime):
        # Convert datetime object to ISO string
        event["timestamp"] = ts.isoformat()
    elif isinstance(ts, str):
        # Ensure proper ISO format with timezone
        try:
            # Handle different formats
            ts_clean = ts.replace("Z", "+00:00")
            dt = datetime.fromisoformat(ts_clean)
            # Standardize to UTC with Z suffix
            if dt.tzinfo is None:
                dt = dt.replace(tzinfo=timezone.utc)
            event["timestamp"] = dt.isoformat().replace("+00:00", "Z")
        except ValueError:
            # Leave as-is; validation will catch errors
            pass

    # --- Normalize keys for backward compatibility ---
    key_mappings = {
        "trader": "trader_id",
        "market": "market_id", 
        "type": "event_type",
        "product": "product_type",
        "optionType": "option_type",  # Handle camelCase
        "impliedVol": "implied_vol"
    }
    
    for old_key, new_key in key_mappings.items():
        if old_key in event and new_key not in event:
            event[new_key] = event.pop(old_key)

    # --- Normalize product_type ---
    if "product_type" in event:
        product = event["product_type"].lower()
        if product in ["perpetual", "future", "futures", "perp"]:
            event["product_type"] = "perp"
        elif product in ["options", "option"]:
            event["product_type"] = "option"
        elif product in ["spot", "cash"]:
            event["product_type"] = "spot"

    # --- Normalize side terminology ---
    # Convert position terms (long/short) to trading terms (buy/sell) for spot and options
    # Keep long/short for perps
    if "side" in event and event.get("product_type") in ["spot", "option"]:
        side = event["side"].lower()
        
        # Only normalize for open/close events, not for exercise/expire
        if event.get("event_type") in ["open", "close", "trade"]:
            if side == "long":
                event["side"] = "buy"
            elif side == "short":
                event["side"] = "sell"
            # Already buy/sell stays as-is

    # --- Normalize option-specific fields ---
    if event.get("product_type") == "option":
        # Normalize option_type
        if "option_type" in event:
            event["option_type"] = event["option_type"].lower()
        
        # Normalize expiry timestamp
        if "expiry" in event and event["expiry"]:
            expiry = event["expiry"]
            if isinstance(expiry, str):
                try:
                    expiry_clean = expiry.replace("Z", "+00:00")
                    dt = datetime.fromisoformat(expiry_clean)
                    # Standardize format
                    if dt.tzinfo is None:
                        dt = dt.replace(tzinfo=timezone.utc)
                    event["expiry"] = dt.isoformat().replace("+00:00", "Z")
                except ValueError:
                    # Leave as-is
                    pass

    # --- Ensure event_id exists ---
    if "event_id" not in event:
        # Create deterministic event ID
        raw_parts = [
            str(event.get('event_type', '')),
            str(event.get('timestamp', '')),
            str(event.get('trader_id', '')),
            str(event.get('market_id', '')),
            str(event.get('product_type', ''))
        ]
        raw = "|".join(raw_parts)
        event["event_id"] = hashlib.sha256(raw.encode()).hexdigest()

    # --- Normalize numeric fields ---
    numeric_fields = ["price", "size", "fee", "pnl", "strike", "delta", 
                     "gamma", "theta", "vega", "implied_vol", "underlying_price"]
    
    for field in numeric_fields:
        if field in event and event[field] is not None:
            try:
                event[field] = float(event[field])
            except (ValueError, TypeError):
                # Keep as-is if conversion fails
                pass

    return event


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\ingestion\pipelines.py =====

# src/ingestion/pipelines.py
import json
import hashlib
from pathlib import Path
from src.ingestion.watermark import WatermarkStore
from src.ingestion.normalizer import normalize_event
from src.analytics.validate import validate_event, EventValidationError


class IngestionPipeline:
    def __init__(self, raw_path: str, output_path: str, checkpoint_path: str):
        self.raw_path = Path(raw_path)
        self.output_path = Path(output_path)
        self.watermark = WatermarkStore(checkpoint_path)

    def run(self) -> int:
        """
        Event-driven ingestion: normalize once, append forever.
        Supports both JSON array and JSONL formats.
        """
        if not self.raw_path.exists():
            raise FileNotFoundError(f"Raw data source not found: {self.raw_path}")

        # Load events based on file format
        if self.raw_path.suffix == '.json':
            # JSON array format (e.g., configs/mock_data.json)
            with self.raw_path.open("r", encoding="utf-8") as f:
                raw_events = json.load(f)
        elif self.raw_path.suffix == '.jsonl':
            # JSONL format (one JSON object per line)
            raw_events = []
            with self.raw_path.open("r", encoding="utf-8") as f:
                for line in f:
                    line = line.strip()
                    if line:  # Skip empty lines
                        raw_events.append(json.loads(line))
        else:
            raise ValueError(f"Unsupported file format: {self.raw_path.suffix}")

        new_events = []
        errors = []

        for idx, raw in enumerate(raw_events, 1):
            try:
                # Generate event_id if missing
                if "event_id" not in raw:
                    seed = (
                        f"{raw.get('event_type')}|"
                        f"{raw.get('timestamp')}|"
                        f"{raw.get('trader_id')}|"
                        f"{raw.get('market_id')}|{idx}"
                    )
                    raw["event_id"] = hashlib.sha256(seed.encode()).hexdigest()

                # Skip if already processed
                if not self.watermark.is_new(raw["event_id"]):
                    continue

                # Normalize and validate
                normalized = normalize_event(raw)
                validate_event(normalized)

                new_events.append(normalized)
                self.watermark.mark(raw["event_id"])

            except EventValidationError as e:
                errors.append(f"Event {idx}: Validation failed - {e}")
            except Exception as e:
                errors.append(f"Event {idx}: Unexpected error - {e}")

        # Report errors
        if errors:
            print(f"âš ï¸  {len(errors)} events had issues:")
            for e in errors[:5]:
                print(f"   - {e}")
            if len(errors) > 5:
                print(f"   ... and {len(errors) - 5} more")

        # Write normalized events to output (JSONL format)
        self.output_path.parent.mkdir(parents=True, exist_ok=True)
        with self.output_path.open("a", encoding="utf-8") as f:
            for e in new_events:
                f.write(json.dumps(e) + "\n")

        print(f"âœ… Ingested {len(new_events)} valid events")
        return len(new_events)


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\ingestion\watermark.py =====

# src/ingestion/watermark.py
import json
from pathlib import Path
from typing import Set

class WatermarkStore:
    """
    Persistent watermark store to prevent reprocessing events.
    """

    def __init__(self, path: str):
        self.path = Path(path)
        self.seen: Set[str] = set()
        self._load()

    def _load(self):
        if self.path.exists():
            with open(self.path, "r") as f:
                self.seen = set(json.load(f))

    def _save(self):
        self.path.parent.mkdir(parents=True, exist_ok=True)
        with open(self.path, "w") as f:
            json.dump(list(self.seen), f)

    def is_new(self, event_id: str) -> bool:
        return event_id not in self.seen

    def mark(self, event_id: str):
        self.seen.add(event_id)
        self._save()


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\ingestion\__init__.py =====



===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\src\__init__.py =====



===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\tests\analytics\test_ingestion.py =====

# Create a test script test_ingestion.py
import json

with open("data/normalized/events.jsonl", "r") as f:
    for i, line in enumerate(f, 1):
        line = line.strip()
        if line:
            try:
                data = json.loads(line)
                print(f"Line {i}: OK - {data.get('event_type', 'N/A')}")
            except json.JSONDecodeError as e:
                print(f"Line {i}: ERROR - {e}")
                print(f"  Content: {line[:50]}...")
        else:
            print(f"Line {i}: EMPTY LINE")


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\tests\analytics\test_pnl_engine.py =====

import pandas as pd
from datetime import datetime, timezone

from src.analytics.pnl_engine import compute_realized_pnl

def test_simple_open_close_pnl():
    events = pd.DataFrame([
        {
            "event_id": "e1",
            "event_type": "open",
            "timestamp": datetime(2026, 1, 1, tzinfo=timezone.utc),
            "trader_id": "T1",
            "market_id": "BTC-PERP",
            "product_type": "perp",
            "side": "long",
            "price": 100.0,
            "size": 1,
            "fee": 0.5,
        },
        {
            "event_id": "e2",
            "event_type": "close",
            "timestamp": datetime(2026, 1, 2, tzinfo=timezone.utc),
            "trader_id": "T1",
            "market_id": "BTC-PERP",
            "product_type": "perp",
            "side": "long",
            "price": 110.0,
            "size": 1,
            "fee": 0.5,
            "pnl": 9.0,  # truth reference
        },
    ])

    positions, pnl = compute_realized_pnl(events)

    assert len(positions) == 1
    assert positions.iloc[0]["realized_pnl"] == 9.0

def test_open_without_close_has_no_pnl():
    events = pd.DataFrame([
        {
            "event_id": "e1",
            "event_type": "open",
            "timestamp": datetime.now(timezone.utc),
            "trader_id": "T1",
            "market_id": "SOL-PERP",
            "product_type": "perp",
            "side": "long",
            "price": 50,
            "size": 2,
            "fee": 0.2,
        }
    ])

    positions, pnl = compute_realized_pnl(events)

    assert positions.empty
    assert pnl.empty

def test_pnl_only_on_close_events():
    events = pd.DataFrame([
        {
            "event_id": "e1",
            "event_type": "trade",
            "timestamp": datetime.now(timezone.utc),
            "trader_id": "T1",
            "market_id": "SOL/USDC",
            "product_type": "spot",
            "side": "buy",
            "price": 100,
            "size": 1,
            "fee": 0.1,
        }
    ])

    positions, pnl = compute_realized_pnl(events)

    assert positions.empty
    assert pnl.empty
def test_pnl_engine_is_deterministic():
    events = pd.DataFrame([
        {
            "event_id": "e1",
            "event_type": "open",
            "timestamp": datetime(2026, 1, 1, tzinfo=timezone.utc),
            "trader_id": "T2",
            "market_id": "ETH-PERP",
            "product_type": "perp",
            "side": "short",
            "price": 200,
            "size": 1,
            "fee": 0.3,
        },
        {
            "event_id": "e2",
            "event_type": "close",
            "timestamp": datetime(2026, 1, 2, tzinfo=timezone.utc),
            "trader_id": "T2",
            "market_id": "ETH-PERP",
            "product_type": "perp",
            "side": "short",
            "price": 180,
            "size": 1,
            "fee": 0.3,
            "pnl": 19.4,
        },
    ])

    p1, pnl1 = compute_realized_pnl(events)
    p2, pnl2 = compute_realized_pnl(events)

    pd.testing.assert_frame_equal(p1, p2)
    pd.testing.assert_frame_equal(pnl1, pnl2)

def test_close_without_open_is_rejected():
    events = pd.DataFrame([
        {
            "event_id": "e1",
            "event_type": "close",
            "timestamp": datetime.now(timezone.utc),
            "trader_id": "T3",
            "market_id": "BTC-PERP",
            "product_type": "perp",
            "side": "long",
            "price": 120,
            "size": 1,
            "fee": 0.4,
            "pnl": 0,
        }
    ])

    positions, pnl = compute_realized_pnl(events)

    assert positions.empty
    assert pnl.empty
def test_partial_close_pnl():
    events = pd.DataFrame([
        {
            "event_id": "e1",
            "event_type": "open",
            "timestamp": datetime(2026, 1, 1, tzinfo=timezone.utc),
            "trader_id": "T1",
            "market_id": "BTC-PERP",
            "product_type": "perp",
            "side": "long",
            "price": 100.0,
            "size": 10,
            "fee": 1.0,
        },
        {
            # partial close (50%)
            "event_id": "e2",
            "event_type": "close",
            "timestamp": datetime(2026, 1, 2, tzinfo=timezone.utc),
            "trader_id": "T1",
            "market_id": "BTC-PERP",
            "product_type": "perp",
            "side": "long",
            "price": 110.0,
            "size": 5,
            "fee": 0.5,
        },
        {
            # final close
            "event_id": "e3",
            "event_type": "close",
            "timestamp": datetime(2026, 1, 3, tzinfo=timezone.utc),
            "trader_id": "T1",
            "market_id": "BTC-PERP",
            "product_type": "perp",
            "side": "long",
            "price": 120.0,
            "size": 5,
            "fee": 0.5,
        },
    ])

    positions, pnl = compute_realized_pnl(events)

    assert len(positions) == 2

    realized = positions["realized_pnl"].sum()
    assert round(realized, 2) == round(
        ((110 - 100) * 5 + (120 - 100) * 5) - 2.0, 2
    )

def test_multiple_partial_closes_order_independent():
    base_events = [
        {
            "event_id": "o1",
            "event_type": "open",
            "timestamp": datetime(2026, 1, 1, tzinfo=timezone.utc),
            "trader_id": "T1",
            "market_id": "BTC-PERP",
            "product_type": "perp",
            "side": "long",
            "price": 100,
            "size": 10,
            "fee": 1.0,
        },
        {
            "event_id": "c1",
            "event_type": "close",
            "timestamp": datetime(2026, 1, 2, tzinfo=timezone.utc),
            "trader_id": "T1",
            "market_id": "BTC-PERP",
            "product_type": "perp",
            "side": "long",
            "price": 110,
            "size": 4,
            "fee": 0.4,
        },
        {
            "event_id": "c2",
            "event_type": "close",
            "timestamp": datetime(2026, 1, 3, tzinfo=timezone.utc),
            "trader_id": "T1",
            "market_id": "BTC-PERP",
            "product_type": "perp",
            "side": "long",
            "price": 120,
            "size": 6,
            "fee": 0.6,
        },
    ]

    df1 = pd.DataFrame(base_events)
    df2 = pd.DataFrame(reversed(base_events))

    p1, pnl1 = compute_realized_pnl(df1)
    p2, pnl2 = compute_realized_pnl(df2)

    pd.testing.assert_frame_equal(p1, p2)
    pd.testing.assert_frame_equal(pnl1, pnl2)
def test_liquidation_is_partial_close():
    events = pd.DataFrame([
        {
            "event_id": "o1",
            "event_type": "open",
            "timestamp": datetime(2026, 1, 1, tzinfo=timezone.utc),
            "trader_id": "T9",
            "market_id": "ETH-PERP",
            "product_type": "perp",
            "side": "long",
            "price": 200,
            "size": 10,
            "fee": 1.0,
        },
        {
            "event_id": "l1",
            "event_type": "liquidation",
            "timestamp": datetime(2026, 1, 2, tzinfo=timezone.utc),
            "trader_id": "T9",
            "market_id": "ETH-PERP",
            "product_type": "perp",
            "side": "long",
            "price": 150,
            "size": 4,
            "fee": 0.5,
        },
    ])

    positions, pnl = compute_realized_pnl(events)

    assert len(positions) == 1
    assert positions.iloc[0]["close_reason"] == "liquidation"


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\tests\analytics\__init__.py =====



===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\tests\__init__.py =====



===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\main.py =====

def main():
    print("Hello from deriverse-data-puller!")


if __name__ == "__main__":
    main()


===== FILE: C:\Users\g\Deriverse\deriverse-data-puller\pyproject.toml =====

[project]
name = "deriverse-data-puller"
version = "0.1.0"
description = "Mock on-chain trading analytics system for Deriverse"
readme = "README.md"
requires-python = ">=3.10"

dependencies = [
    "base58>=2.1.1",
    "dotenv",
    "matplotlib>=3.10.8",
    "pandas>=2.3.3",
    "plotly>=6.5.2",
    "pyyaml",
    "requests>=2.32.5",
    "streamlit",
]

