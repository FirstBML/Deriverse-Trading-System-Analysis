

===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\.vscode\settings.json =====

{
    "python.defaultInterpreterPath": "${workspaceFolder}/.venv/Scripts/python.exe",
    "python.analysis.extraPaths": ["./"],
    "python.autoComplete.extraPaths": [
        "${workspaceFolder}/.venv/Lib/site-packages"
    ]
}


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\configs\ingestion.yaml =====

# configs/ingestion.yaml

# Path to raw mock protocol events (JSON array)
raw_data_path: configs/mock_data.json

# Append-only normalized output (JSONL format)
normalized_output_path: data/normalized/events.jsonl

# Watermark / checkpoint store for incremental ingestion
checkpoint_path: data/checkpoints/watermark.json

# Allowed lateness for event-time processing (seconds)
allowed_lateness_seconds: 0

# Optional controls (future-safe)
markets: []
traders: []
max_events_per_run: null


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\configs\loader.py =====

# configs/loader.py

import yaml
from pathlib import Path
import logging  # âœ… ADD THIS

logger = logging.getLogger(__name__) 

def load_config(path: str) -> dict:
    with open(Path(path), "r") as f:
        return yaml.safe_load(f)


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\configs\mock_data.json =====

[
  {
    "event_type": "open",
    "timestamp": "2026-02-12T10:57:14.265052Z",
    "trader_id": "7KNXqvHu2QWvDq8cGPGvKZhFvYnz3kQ5mL8xRt2Bp9uV",
    "market_id": "SOL/USDC",
    "product_type": "spot",
    "side": "buy",
    "price": 100,
    "size": 10,
    "fee": 0.5,
    "event_id": "ddb3089c78aca56cb1a67aeb47c9f6f28375454250914a8e3d268780e28808cc",
    "order_type": "stop"
  },
  {
    "event_type": "close",
    "timestamp": "2026-02-12T12:57:14.265052Z",
    "trader_id": "7KNXqvHu2QWvDq8cGPGvKZhFvYnz3kQ5mL8xRt2Bp9uV",
    "market_id": "SOL/USDC",
    "product_type": "spot",
    "side": "sell",
    "price": 110,
    "size": 10,
    "fee": 0.5,
    "event_id": "8a8f431db222dc77749fb743baf5aeb131c8571908ea35b09230cf030036f719",
    "order_type": "market"
  },
  {
    "event_type": "open",
    "timestamp": "2026-02-12T11:07:14.265052Z",
    "trader_id": "5FxM2nQwP4vYkL9mT3xRd8eJbWp7sN6gH2cKt9uVfXyZ",
    "market_id": "ETH/USDC",
    "product_type": "spot",
    "side": "buy",
    "price": 2000,
    "size": 5,
    "fee": 1.0,
    "event_id": "8b3c6b9a981e2f4bb8448ea0484cde78c4922c629030b224e1dcc594b7034607",
    "order_type": "market"
  },
  {
    "event_type": "close",
    "timestamp": "2026-02-12T13:57:14.265052Z",
    "trader_id": "5FxM2nQwP4vYkL9mT3xRd8eJbWp7sN6gH2cKt9uVfXyZ",
    "market_id": "ETH/USDC",
    "product_type": "spot",
    "side": "sell",
    "price": 1950,
    "size": 5,
    "fee": 1.0,
    "event_id": "f38a2874102b6b24f6afa8c79cf759482bd9701567b9b3333f5cb0050101ac53",
    "order_type": "stop"
  },
  {
    "event_type": "open",
    "timestamp": "2026-02-12T11:17:14.265052Z",
    "trader_id": "9DpT3vHx5kN2qL8mR7wYfJ6bP4sE1cG9nZ5tK3uVwXyA",
    "market_id": "SOL-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 100,
    "size": 10,
    "fee": 0.5,
    "event_id": "6d12e0bb2cfcb0d90e9991838c7419198884592d03b9517ee2810a55c70831f6",
    "order_type": "limit"
  },
  {
    "event_type": "close",
    "timestamp": "2026-02-12T14:57:14.265052Z",
    "trader_id": "9DpT3vHx5kN2qL8mR7wYfJ6bP4sE1cG9nZ5tK3uVwXyA",
    "market_id": "SOL-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 120,
    "size": 10,
    "fee": 0.5,
    "event_id": "3ce3f79ca07e8b79e99c081f10592d9d01856290f111ca86fd88c37fdfc691cc",
    "order_type": "market"
  },
  {
    "event_type": "open",
    "timestamp": "2026-02-12T11:27:14.265052Z",
    "trader_id": "4MqL8vYx2kP9nT7wR5fH3bJ6sE1cG4nZ8tK2uVwXyBpQ",
    "market_id": "BTC-PERP",
    "product_type": "perp",
    "side": "short",
    "price": 50000,
    "size": 1,
    "fee": 5.0,
    "event_id": "3b4e54dab79cef25a5ee2e820d6440c90084f60cf89ed3e5291d9d62e8b4f255",
    "order_type": "market"
  },
  {
    "event_type": "close",
    "timestamp": "2026-02-12T15:57:14.265052Z",
    "trader_id": "4MqL8vYx2kP9nT7wR5fH3bJ6sE1cG4nZ8tK2uVwXyBpQ",
    "market_id": "BTC-PERP",
    "product_type": "perp",
    "side": "short",
    "price": 48000,
    "size": 1,
    "fee": 5.0,
    "event_id": "48409e4c5e22297fb40677a22431ecfa97e3422351cca94d8bc2822f07e9de66",
    "order_type": "market"
  },
  {
    "event_type": "open",
    "timestamp": "2026-02-12T11:37:14.265052Z",
    "trader_id": "6NrK9wZx3mQ8pU7vS4gI2dL5tF1eH7oA9yM3xVbCwRtE",
    "market_id": "ETH-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 2100,
    "size": 5,
    "fee": 2.0,
    "event_id": "3086ca3f32ef4df06f6c99fad0d8ed1032024a78a5e4a8f81eb15a418b21dfff",
    "order_type": "stop"
  },
  {
    "event_type": "close",
    "timestamp": "2026-02-12T16:57:14.265052Z",
    "trader_id": "6NrK9wZx3mQ8pU7vS4gI2dL5tF1eH7oA9yM3xVbCwRtE",
    "market_id": "ETH-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 2050,
    "size": 5,
    "fee": 2.0,
    "event_id": "4344d0d3fb90688ac351b5481c155cdd617e3aab3798316e28130cd38fd66ec5",
    "order_type": "market"
  },
  {
    "event_type": "open",
    "timestamp": "2026-02-12T11:57:14.265052Z",
    "trader_id": "4MqL8vYx2kP9nT7wR5fH3bJ6sE1cG4nZ8tK2uVwXyBpQ",
    "market_id": "SOL-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 105,
    "size": 50,
    "fee": 5.0,
    "event_id": "ecf09dd653367662d6e72804f0164a8708e5cf51ac701b696c65ce170917e4ce",
    "order_type": "market"
  },
  {
    "event_type": "liquidation",
    "timestamp": "2026-02-12T12:57:14.265052Z",
    "trader_id": "4MqL8vYx2kP9nT7wR5fH3bJ6sE1cG4nZ8tK2uVwXyBpQ",
    "market_id": "SOL-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 88,
    "size": 50,
    "fee": 25.0,
    "event_id": "8ec6cdc5d3fbfe57fe54acc8bbba82ad9de24b7e8ba25a8f6b9ae29a0fafbc32",
    "order_type": "liquidation"
  },
  {
    "event_type": "open",
    "timestamp": "2026-02-12T11:57:14.265052Z",
    "trader_id": "8QtN2xWy5lR7mV9uT6hK3eM4pG1fJ8nB7zL4wVcDxSeF",
    "market_id": "SOL-CALL-120-FEB28",
    "product_type": "option",
    "option_type": "call",
    "strike": 120,
    "expiry": "2026-03-02T10:57:14.265052Z",
    "side": "buy",
    "price": 5.0,
    "size": 10,
    "fee": 0.5,
    "delta": 0.65,
    "implied_vol": 0.45,
    "event_id": "f9cafab3cad628916eea5fc6684cad9405de4d23139d9edd6f4f25008bdba1e9",
    "order_type": "stop"
  },
  {
    "event_type": "close",
    "timestamp": "2026-02-13T10:57:14.265052Z",
    "trader_id": "8QtN2xWy5lR7mV9uT6hK3eM4pG1fJ8nB7zL4wVcDxSeF",
    "market_id": "SOL-CALL-120-FEB28",
    "product_type": "option",
    "option_type": "call",
    "strike": 120,
    "expiry": "2026-03-02T10:57:14.265052Z",
    "side": "sell",
    "price": 8.0,
    "size": 10,
    "fee": 0.5,
    "delta": 0.85,
    "implied_vol": 0.5,
    "event_id": "dd859392bdceb6122f901cf898d46a654fbe4538d0bc0e7330ce49766f10fe2b",
    "order_type": "stop"
  },
  {
    "event_type": "open",
    "timestamp": "2026-02-12T12:27:14.265052Z",
    "trader_id": "3HsJ7yVz4nQ6oW8tS5gL2fN9rH1eK6mC8xM5vBdEwRuG",
    "market_id": "SOL-PUT-90-FEB28",
    "product_type": "option",
    "option_type": "put",
    "strike": 90,
    "expiry": "2026-03-02T10:57:14.265052Z",
    "side": "sell",
    "price": 4.0,
    "size": 15,
    "fee": 0.7,
    "delta": -0.25,
    "implied_vol": 0.4,
    "event_id": "21231bd6588b624e48f8ad1db92a0322becedf1807cc84ae5287eb274511b498",
    "order_type": "stop"
  },
  {
    "event_type": "close",
    "timestamp": "2026-02-13T22:57:14.265052Z",
    "trader_id": "3HsJ7yVz4nQ6oW8tS5gL2fN9rH1eK6mC8xM5vBdEwRuG",
    "market_id": "SOL-PUT-90-FEB28",
    "product_type": "option",
    "option_type": "put",
    "strike": 90,
    "expiry": "2026-03-02T10:57:14.265052Z",
    "side": "buy",
    "price": 1.5,
    "size": 15,
    "fee": 0.7,
    "delta": -0.1,
    "implied_vol": 0.3,
    "event_id": "85b450ec23106ab1109d77a18fbfa0e6334a948c1806c4f017e60baeb9f47a21",
    "order_type": "market"
  },
  {
    "event_type": "open",
    "timestamp": "2026-02-12T12:57:14.265052Z",
    "trader_id": "2PrM8xUz6oT5nY7vR4jL3gP1sH9eN4mD6zK8wCfGxQuH",
    "market_id": "ETH-PUT-1900-FEB28",
    "product_type": "option",
    "option_type": "put",
    "strike": 1900,
    "expiry": "2026-03-02T10:57:14.265052Z",
    "side": "buy",
    "price": 45.0,
    "size": 5,
    "fee": 1.0,
    "delta": -0.35,
    "implied_vol": 0.55,
    "event_id": "710234138f5aa3d036315a4c2b4690660cd43cd4b57d98c62b057ffccfc9aa36",
    "order_type": "stop"
  },
  {
    "event_type": "close",
    "timestamp": "2026-02-14T10:57:14.265052Z",
    "trader_id": "2PrM8xUz6oT5nY7vR4jL3gP1sH9eN4mD6zK8wCfGxQuH",
    "market_id": "ETH-PUT-1900-FEB28",
    "product_type": "option",
    "option_type": "put",
    "strike": 1900,
    "expiry": "2026-03-02T10:57:14.265052Z",
    "side": "sell",
    "price": 20.0,
    "size": 5,
    "fee": 1.0,
    "delta": -0.15,
    "implied_vol": 0.4,
    "event_id": "95cec10ee1728c61fcf1b10055c479d230a2fbca29fb0e28144452e4f7df4b09",
    "order_type": "limit"
  },
  {
    "event_type": "open",
    "timestamp": "2026-02-12T13:57:14.265052Z",
    "trader_id": "5TpQ9yXz7mS6oV8uR3kM2hN4rJ1fL5nE7xP6wDgHySvI",
    "market_id": "BTC-CALL-50000-FEB28",
    "product_type": "option",
    "option_type": "call",
    "strike": 50000,
    "expiry": "2026-03-02T10:57:14.265052Z",
    "side": "buy",
    "price": 2000.0,
    "size": 1,
    "fee": 10.0,
    "event_id": "88cd81e3873647d1371b1868dbf71e3de16709b14b02ecf5d1f9097e99da168f",
    "order_type": "market"
  },
  {
    "event_type": "exercise",
    "timestamp": "2026-03-01T10:57:14.265052Z",
    "trader_id": "5TpQ9yXz7mS6oV8uR3kM2hN4rJ1fL5nE7xP6wDgHySvI",
    "market_id": "BTC-CALL-50000-FEB28",
    "product_type": "option",
    "option_type": "call",
    "strike": 50000,
    "expiry": "2026-03-02T10:57:14.265052Z",
    "side": "exercise",
    "size": 1,
    "fee": 10.0,
    "underlying_price": 55000,
    "event_id": "8f574fa03c5960fd11d8db6e044913a1cfab8bf34c2191d1932aebecf9f8cfd9"
  },
  {
    "event_type": "open",
    "timestamp": "2026-02-12T14:57:14.265052Z",
    "trader_id": "4WqP8zYx5nT7mU9tS2lN6jM3rK1gH4oC8yL5vEfJxRwK",
    "market_id": "SOL-PUT-80-FEB28",
    "product_type": "option",
    "option_type": "put",
    "strike": 80,
    "expiry": "2026-03-02T10:57:14.265052Z",
    "side": "buy",
    "price": 3.0,
    "size": 20,
    "fee": 0.2,
    "event_id": "533c16e94b273f50853a97c2a1a5045c634cf1c1fde7aa29698b9346c1c2f459",
    "order_type": "market"
  },
  {
    "event_type": "expire",
    "timestamp": "2026-03-02T10:57:14.265052Z",
    "trader_id": "4WqP8zYx5nT7mU9tS2lN6jM3rK1gH4oC8yL5vEfJxRwK",
    "market_id": "SOL-PUT-80-FEB28",
    "product_type": "option",
    "option_type": "put",
    "strike": 80,
    "expiry": "2026-03-02T10:57:14.265052Z",
    "side": "expire",
    "price": 0.0,
    "size": 20,
    "fee": 0.0,
    "underlying_price": 95,
    "event_id": "663bb985ce364533b866dba2aac02f7312185e7a552a28cede776f29fb785bb2"
  },
  {
    "event_type": "open",
    "timestamp": "2026-02-12T15:57:14.265052Z",
    "trader_id": "7KNXqvHu2QWvDq8cGPGvKZhFvYnz3kQ5mL8xRt2Bp9uV",
    "market_id": "SOL-CALL-110-FEB28",
    "product_type": "option",
    "option_type": "call",
    "strike": 110,
    "expiry": "2026-03-02T10:57:14.265052Z",
    "side": "buy",
    "price": 8.0,
    "size": 20,
    "fee": 1.0,
    "event_id": "6f34145730b8358d282ce24c0cc2025fcc781622ac10448eb1ea8cdcd704314d",
    "order_type": "market"
  },
  {
    "event_type": "close",
    "timestamp": "2026-02-13T12:57:14.265052Z",
    "trader_id": "7KNXqvHu2QWvDq8cGPGvKZhFvYnz3kQ5mL8xRt2Bp9uV",
    "market_id": "SOL-CALL-110-FEB28",
    "product_type": "option",
    "option_type": "call",
    "strike": 110,
    "expiry": "2026-03-02T10:57:14.265052Z",
    "side": "sell",
    "price": 12.0,
    "size": 10,
    "fee": 0.5,
    "event_id": "4cd54646509022bbae87dcc7cc667a7fbabbd30a333e02dbba8e7d7a69dd325a",
    "order_type": "market"
  },
  {
    "event_type": "close",
    "timestamp": "2026-02-14T12:57:14.265052Z",
    "trader_id": "7KNXqvHu2QWvDq8cGPGvKZhFvYnz3kQ5mL8xRt2Bp9uV",
    "market_id": "SOL-CALL-110-FEB28",
    "product_type": "option",
    "option_type": "call",
    "strike": 110,
    "expiry": "2026-03-02T10:57:14.265052Z",
    "side": "sell",
    "price": 15.0,
    "size": 10,
    "fee": 0.5,
    "event_id": "5ed06055b8f03df9c44db05a5672807bf88db38448d228574843845efe62ea87",
    "order_type": "market"
  },
  {
    "event_type": "open",
    "timestamp": "2026-02-12T17:57:14.265052Z",
    "trader_id": "7KNXqvHu2QWvDq8cGPGvKZhFvYnz3kQ5mL8xRt2Bp9uV",
    "market_id": "BTC/USDC",
    "product_type": "spot",
    "side": "buy",
    "price": 51000,
    "size": 0.5,
    "fee": 5.0,
    "event_id": "222abbf413d4c09d5231dc0393225e053b6d4b128b7330fdf8cd5c04c63ade8b",
    "order_type": "market"
  },
  {
    "event_type": "open",
    "timestamp": "2026-02-12T18:57:14.265052Z",
    "trader_id": "5FxM2nQwP4vYkL9mT3xRd8eJbWp7sN6gH2cKt9uVfXyZ",
    "market_id": "AVAX-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 35.5,
    "size": 100,
    "fee": 1.5,
    "event_id": "8b919117414cfec16b736a3ae485160617c3b10ea6572517eb79005c78c5e78b",
    "order_type": "limit"
  },
  {
    "event_type": "open",
    "timestamp": "2026-02-12T19:57:14.265052Z",
    "trader_id": "9DpT3vHx5kN2qL8mR7wYfJ6bP4sE1cG9nZ5tK3uVwXyA",
    "market_id": "ETH-CALL-2200-MAR15",
    "product_type": "option",
    "option_type": "call",
    "strike": 2200,
    "expiry": "2026-03-14T10:57:14.265052Z",
    "side": "buy",
    "price": 85.0,
    "size": 3,
    "fee": 0.5,
    "event_id": "67dd2cce31994b1d07c70b0609dc99da7a601a2e89fbcd039f1b67043cf3df8f",
    "order_type": "limit"
  },
  {
    "event_type": "open",
    "timestamp": "2026-02-12T11:57:14.265052Z",
    "trader_id": "7KNXqvHu2QWvDq8cGPGvKZhFvYnz3kQ5mL8xRt2Bp9uV",
    "market_id": "SOL/USDC",
    "product_type": "spot",
    "side": "buy",
    "price": 105,
    "size": 5,
    "fee": 0.3,
    "event_id": "67c1115bdaa6af8ea041f882d0aa8c48c301a512dc810fbcf4756a4e005eaa7d",
    "order_type": "stop"
  },
  {
    "event_type": "close",
    "timestamp": "2026-02-12T20:57:14.265052Z",
    "trader_id": "GhostWallet1111111111111111111111111111",
    "market_id": "GHOST-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 999,
    "size": 1,
    "fee": 0.1,
    "event_id": "3480bd711935d28d9bf9fb7fbdc6e77e0df97677cfb47ee23aa7b4d7b38372f7",
    "order_type": "stop"
  },
  {
    "event_type": "trade",
    "timestamp": "2026-02-12T11:12:14.265052Z",
    "trader_id": "MarketMaker1111111111111111111111111",
    "market_id": "SOL/USDC",
    "product_type": "spot",
    "side": "buy",
    "price": 101,
    "size": 100,
    "fee": 1.0,
    "event_id": "9cf9883b4843754c0a834d45bac8a0d5866da8deb71d228a01dea6ad2d59d2b3"
  },
  {
    "event_type": "trade",
    "timestamp": "2026-02-12T11:42:14.265052Z",
    "trader_id": "MarketMaker1111111111111111111111111",
    "market_id": "ETH-PERP",
    "product_type": "perp",
    "side": "sell",
    "price": 2105,
    "size": 50,
    "fee": 5.0,
    "event_id": "6d575a153e23b9f0faef3e0d3c30af4479335bf94a9a972321e2a26467b8f80d"
  }
]


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\configs\__init__.py =====



===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\dashboards\app.py =====

# dashboards/app.py - PRODUCTION READY v3.0
import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
from pathlib import Path
from datetime import datetime

DATA_DIR = Path("data/analytics_output")

st.set_page_config(page_title="Deriverse Trading Analytics", layout="wide")

st.markdown("""
    <style>
    .stMetric { background: #f0f2f6; padding: 15px; border-radius: 8px; }
    </style>
""", unsafe_allow_html=True)

st.title("ðŸ“Š Deriverse Trading Analytics Dashboard")

@st.cache_data
def load_data():
    try:
        equity = pd.read_csv(DATA_DIR / "equity_curve.csv", parse_dates=["timestamp"])
        positions = pd.read_csv(DATA_DIR / "positions.csv", parse_dates=["open_time", "close_time"])
        summary = pd.read_csv(DATA_DIR / "summary_metrics.csv")
        fees = pd.read_csv(DATA_DIR / "fees_breakdown.csv")
        volume = pd.read_csv(DATA_DIR / "volume_by_market.csv")
        pnl_day = pd.read_csv(DATA_DIR / "pnl_by_day.csv", parse_dates=["date"])
        pnl_hour = pd.read_csv(DATA_DIR / "pnl_by_hour.csv")
        directional = pd.read_csv(DATA_DIR / "directional_bias.csv")
        order_perf = pd.read_csv(DATA_DIR / "order_type_performance.csv")
        greeks = pd.read_csv(DATA_DIR / "greeks_exposure.csv")
        open_pos = pd.read_csv(DATA_DIR / "open_positions.csv", parse_dates=["open_time"])  # âœ… NEW
        
        return {
            'equity': equity, 'positions': positions, 'summary': summary,
            'fees': fees, 'volume': volume, 'pnl_day': pnl_day,
            'pnl_hour': pnl_hour, 'directional': directional, 
            'order_perf': order_perf, 'greeks': greeks,
            'open_positions': open_pos  # âœ… NEW
        }
    except FileNotFoundError:
        st.error("Analytics files not found. Run: python -m scripts.run_analytics")
        return None

data = load_data()

if data is None or (data['positions'].empty and data['open_positions'].empty):
    st.warning("No trading data available.")
    st.stop()

# Calculate volume in USD
if not data['positions'].empty:
    data['positions']['volume_usd'] = data['positions']['exit_price'] * data['positions']['size']

# Sidebar Filters
st.sidebar.header("ðŸŽ›ï¸ Filters")
traders = sorted(pd.concat([
    data['positions']['trader_id'] if not data['positions'].empty else pd.Series([]),
    data['open_positions']['trader_id'] if not data['open_positions'].empty else pd.Series([])
]).unique())
selected_trader = st.sidebar.selectbox("Trader Account", ["All"] + list(traders))

# Filter Data
filtered_positions = data['positions'].copy() if not data['positions'].empty else pd.DataFrame()
filtered_open = data['open_positions'].copy() if not data['open_positions'].empty else pd.DataFrame()

if selected_trader != "All":
    if not filtered_positions.empty:
        filtered_positions = filtered_positions[filtered_positions['trader_id'] == selected_trader]
    if not filtered_open.empty:
        filtered_open = filtered_open[filtered_open['trader_id'] == selected_trader]

# KPI Tiles
st.header("ðŸ“ˆ Performance Overview")
col1, col2, col3, col4 = st.columns(4)

total_pnl = filtered_positions['realized_pnl'].sum() if not filtered_positions.empty else 0
win_rate = (filtered_positions['realized_pnl'] > 0).mean() * 100 if not filtered_positions.empty else 0
total_fees = filtered_positions['fees'].sum() if not filtered_positions.empty else 0
trade_count = len(filtered_positions)

col1.metric("Net Realized PnL", f"${total_pnl:,.2f}", delta=f"{total_pnl:,.2f}" if total_pnl > 0 else None)
col2.metric("Win Rate", f"{win_rate:.1f}%")
col3.metric("Total Closed Trades", trade_count)
col4.metric("Fees Paid", f"${total_fees:,.2f}")

# Risk Management Metrics
st.header("âš–ï¸ Risk Analysis")
c1, c2, c3, c4 = st.columns(4)

if not filtered_positions.empty:
    winning = filtered_positions[filtered_positions['realized_pnl'] > 0]
    losing = filtered_positions[filtered_positions['realized_pnl'] < 0]
    
    avg_win = winning['realized_pnl'].mean() if len(winning) > 0 else 0
    avg_loss = losing['realized_pnl'].mean() if len(losing) > 0 else 0
    
    if selected_trader != "All" and not data['summary'].empty:
        trader_data = data['summary'][data['summary']['trader_id'] == selected_trader]
        max_dd = trader_data['max_drawdown'].iloc[0] if not trader_data.empty else 0
        sharpe = trader_data['sharpe_ratio'].iloc[0] if not trader_data.empty else 0
    else:
        max_dd = data['summary']['max_drawdown'].min() if not data['summary'].empty else 0
        sharpe = data['summary']['sharpe_ratio'].mean() if not data['summary'].empty else 0
else:
    avg_win = avg_loss = max_dd = sharpe = 0

c1.metric("Average Win", f"${avg_win:,.2f}")
c2.metric("Average Loss", f"${avg_loss:,.2f}")
c3.metric("Max Drawdown", f"${max_dd:,.2f}")
c4.metric("Sharpe Ratio", f"{sharpe:.2f}")

# âœ… OPEN POSITIONS - REAL DATA, NO UNREALIZED PNL
if not filtered_open.empty:
    st.header("ðŸ“Š Open Positions (Active Trades)")
    st.caption("ðŸ’¡ Current positions still held. Unrealized PnL calculated at closing.")
    
    # Prepare display
    open_display = filtered_open.copy()
    open_display['time_held'] = (open_display['time_held_seconds'] / 3600).round(1)
    
    # Format for display
    display_open = open_display[[
        'position_id', 'trader_id', 'market_id', 'product_type', 'side',
        'entry_price', 'size', 'fees_paid', 'open_time', 'time_held'
    ]].copy()
    
    display_open = display_open.rename(columns={
        'position_id': 'Position ID',
        'trader_id': 'Trader',
        'market_id': 'Market',
        'product_type': 'Type',
        'side': 'Direction',
        'entry_price': 'Entry Price',
        'size': 'Size',
        'fees_paid': 'Fees Paid',
        'open_time': 'Opened At',
        'time_held': 'Hours Held'
    })
    
    st.dataframe(
        display_open.style.format({
            'Entry Price': '${:,.2f}',
            'Fees Paid': '${:,.2f}',
            'Size': '{:,.4f}',
            'Hours Held': '{:,.1f}h'
        }),
        width='stretch',
        hide_index=True
    )

# Equity Curve
if not data['equity'].empty:
    st.header("ðŸ’° Equity Curve")
    filtered_equity = data['equity'].copy()
    if selected_trader != "All":
        filtered_equity = filtered_equity[filtered_equity['trader_id'] == selected_trader]
    
    if not filtered_equity.empty:
        fig = go.Figure()
        for trader in filtered_equity['trader_id'].unique():
            trader_eq = filtered_equity[filtered_equity['trader_id'] == trader].sort_values('timestamp')
            trader_short = trader[:8] + "..." if len(trader) > 12 else trader
            fig.add_trace(go.Scatter(x=trader_eq['timestamp'], y=trader_eq['cumulative_pnl'], name=f"{trader_short} PnL"))
            fig.add_trace(go.Scatter(x=trader_eq['timestamp'], y=trader_eq['drawdown'], fill='tozeroy', 
                                    fillcolor='rgba(255,0,0,0.2)', line=dict(color='red', width=0.5), 
                                    name=f"{trader_short} DD"))
        fig.update_layout(xaxis_title="Time", yaxis_title="PnL ($)", hovermode='x unified', height=400)
        st.plotly_chart(fig, width='stretch')

# Charts Row 1
col1, col2 = st.columns(2)

with col1:
    st.subheader("ðŸ“… Daily PnL")
    if not filtered_positions.empty:
        daily = filtered_positions.groupby(filtered_positions['close_time'].dt.date)['realized_pnl'].sum().reset_index()
        daily.columns = ['date', 'pnl']
        fig = px.bar(daily, x='date', y='pnl', color='pnl', color_continuous_scale=['red', 'gray', 'green'], 
                    color_continuous_midpoint=0)
        fig.update_layout(height=300, showlegend=False)
        st.plotly_chart(fig, width='stretch')

with col2:
    st.subheader("ðŸ’¸ Fees by Product")
    if not filtered_positions.empty:
        fees_prod = filtered_positions.groupby('product_type')['fees'].sum().reset_index()
        fig = px.bar(fees_prod, x='product_type', y='fees', color='product_type')
        fig.update_layout(height=300, showlegend=False)
        st.plotly_chart(fig, width='stretch')

# Complete Fee Analysis
if not filtered_positions.empty:
    st.header("ðŸ’¸ Complete Fee Analysis")
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Fee Composition")
        if not data['fees'].empty:
            trader_fees = data['fees'] if selected_trader == "All" else data['fees'][data['fees']['trader_id'] == selected_trader]
            fig = px.pie(trader_fees, values='total_fees', names='product_type', title='Fee Distribution')
            fig.update_layout(height=300)
            st.plotly_chart(fig, width='stretch')
        
        fee_summary = filtered_positions.groupby('product_type').agg({
            'fees': ['sum', 'mean', 'count']
        }).round(2)
        fee_summary.columns = ['Total Fees', 'Avg Fee', 'Trade Count']
        st.dataframe(fee_summary, width='stretch')
    
    with col2:
        st.subheader("Cumulative Fee Tracking")
        fee_timeline = filtered_positions.sort_values('close_time')[['close_time', 'fees']].copy()
        fee_timeline['cumulative_fees'] = fee_timeline['fees'].cumsum()
        
        fig = go.Figure()
        fig.add_trace(go.Scatter(x=fee_timeline['close_time'], y=fee_timeline['cumulative_fees'],
                                mode='lines+markers', name='Cumulative Fees', line=dict(color='red', width=2)))
        fig.update_layout(xaxis_title="Time", yaxis_title="Cumulative Fees ($)", height=300)
        st.plotly_chart(fig, width='stretch')

# Complete Volume Analysis
if not filtered_positions.empty:
    st.header("ðŸ“Š Trading Volume Analysis")
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Volume by Market (USD)")
        market_vol = filtered_positions.groupby('market_id').agg({
            'volume_usd': 'sum',
            'realized_pnl': 'sum'
        }).sort_values('volume_usd', ascending=False)
        
        fig = px.bar(market_vol.reset_index(), x='market_id', y='volume_usd',
                    title='Trading Volume (USD)', labels={'volume_usd': 'Volume (USD)'})
        fig.update_layout(height=350, xaxis_tickangle=-45)
        st.plotly_chart(fig, width='stretch')
    
    with col2:
        st.subheader("Volume vs PnL")
        market_stats = filtered_positions.groupby('market_id').agg({
            'volume_usd': 'sum',
            'realized_pnl': 'sum',
            'size': 'sum'
        }).sort_values('volume_usd', ascending=False).head(10)
        
        display_stats = market_stats.copy()
        display_stats.columns = ['Volume (USD)', 'PnL ($)', 'Size (Units)']
        st.dataframe(display_stats.style.format({
            'Volume (USD)': '${:,.2f}',
            'PnL ($)': '${:,.2f}',
            'Size (Units)': '{:,.2f}'
        }), width='stretch')

# Charts Row 2
if not filtered_positions.empty:
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("âš–ï¸ Long vs Short")
        long_cnt = len(filtered_positions[filtered_positions['side'].isin(['long', 'buy'])])
        short_cnt = len(filtered_positions[filtered_positions['side'].isin(['short', 'sell'])])
        fig = go.Figure(data=[go.Pie(labels=['Long', 'Short'], values=[long_cnt, short_cnt], 
                                     hole=0.4, marker_colors=['#00cc96', '#ef553b'])])
        fig.update_layout(height=300)
        st.plotly_chart(fig, width='stretch')
    
    with col2:
        st.subheader("ðŸ• Hourly Performance")
        hourly = filtered_positions.copy()
        hourly['hour'] = hourly['close_time'].dt.hour
        hour_pnl = hourly.groupby('hour')['realized_pnl'].mean().reset_index()
        fig = px.line(hour_pnl, x='hour', y='realized_pnl', markers=True)
        fig.update_layout(height=300, xaxis_title="Hour", yaxis_title="Avg PnL")
        st.plotly_chart(fig, width='stretch')

# Order Type Performance
if not data['order_perf'].empty:
    st.header("ðŸ“Š Order Type Performance")
    fig = go.Figure()
    fig.add_trace(go.Bar(name='Win Rate', x=data['order_perf']['order_type'], 
                        y=data['order_perf']['win_rate']*100, yaxis='y', marker_color='lightblue'))
    fig.add_trace(go.Scatter(name='Avg PnL', x=data['order_perf']['order_type'], 
                            y=data['order_perf']['avg_pnl'], yaxis='y2', marker_color='green', 
                            line=dict(width=3)))
    fig.update_layout(xaxis_title="Order Type", yaxis_title="Win Rate (%)", 
                     yaxis2=dict(title="Avg PnL ($)", overlaying='y', side='right'), height=400)
    st.plotly_chart(fig, width='stretch')

# Greeks Exposure
if not data['greeks'].empty:
    st.header("ðŸ”¬ Options Greeks Exposure")
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Net Delta by Trader")
        fig = px.bar(data['greeks'], x='trader_id', y='net_delta', title="Delta Exposure")
        st.plotly_chart(fig, width='stretch')
    
    with col2:
        st.subheader("Options Position Count")
        fig = px.bar(data['greeks'], x='trader_id', y='total_option_positions')
        st.plotly_chart(fig, width='stretch')

# âœ… TRADE JOURNAL WITH ANNOTATIONS
if not filtered_positions.empty:
    st.header("ðŸ“ Trade Journal with Annotations")
    st.caption("âœï¸ Document your trading decisions, lessons learned, and strategy insights")
    
    # Add explanatory info
    with st.expander("â„¹ï¸ What are trade annotations? Click to learn more..."):
        st.markdown("""
        **Trade annotations** are your personal trading journal entries where you document:
        - ðŸ“Š **Market conditions** when you entered/exited
        - ðŸŽ¯ **Why you took the trade** (setup, strategy, conviction level)
        - ðŸ§  **Emotional state** (FOMO, confident, fearful, disciplined)
        - âœ… **What went right** (good entries, proper risk management)
        - âŒ **What went wrong** (early exit, late entry, ignored signals)
        - ðŸ“š **Lessons learned** for future trades
        
        **Example notes:**
        - "Entered too early before confirmation - wait for volume spike next time"
        - "Perfect setup: broke resistance on high volume, followed plan exactly"
        - "Emotional revenge trade after previous loss - took too much risk"
        - "News-driven: Fed announcement caused spike - set tighter stops for news events"
        
        These notes help you identify patterns, improve your strategy, and become a better trader.
        """)
    
    # Prepare journal
    available_cols = [
        'close_time', 'trader_id', 'market_id', 'product_type', 'side',
        'entry_price', 'exit_price', 'volume_usd', 'realized_pnl', 'fees'
    ]
    
    # Add close_reason if it exists
    if 'close_reason' in filtered_positions.columns:
        available_cols.append('close_reason')
    
    journal_df = filtered_positions[available_cols].copy()
    journal_df = journal_df.sort_values('close_time', ascending=False)
    
    # Shorten trader IDs for display
    journal_df['trader_short'] = journal_df['trader_id'].str[:8] + '...'
    
    # Initialize notes in session state
    if 'trade_notes' not in st.session_state:
        st.session_state.trade_notes = {}
    
    # Add notes column
    journal_df['trader_notes'] = journal_df.index.map(
        lambda i: st.session_state.trade_notes.get(i, "")
    )
    
    # Reorder columns for display
    display_cols = [
        'close_time', 'trader_short', 'market_id', 'product_type', 'side',
        'entry_price', 'exit_price', 'volume_usd', 'realized_pnl', 'fees'
    ]
    
    if 'close_reason' in journal_df.columns:
        display_cols.append('close_reason')
    
    display_cols.append('trader_notes')
    
    # âœ… EDITABLE DATA TABLE
    edited_journal = st.data_editor(
        journal_df[display_cols],
        column_config={
            "close_time": st.column_config.DatetimeColumn(
                "Closed At",
                format="DD/MM/YYYY HH:mm"
            ),
            "trader_short": st.column_config.TextColumn(
                "Trader",
                help="First 8 characters of wallet address",
                disabled=True
            ),
            "market_id": "Market",
            "product_type": "Type",
            "side": "Direction",
            "entry_price": st.column_config.NumberColumn(
                "Entry",
                format="$%.2f"
            ),
            "exit_price": st.column_config.NumberColumn(
                "Exit",
                format="$%.2f",
                help="None for exercised/expired options (PnL calculated from intrinsic value)"
            ),
            "volume_usd": st.column_config.NumberColumn(
                "Volume (USD)",
                format="$%.0f"
            ),
            "realized_pnl": st.column_config.NumberColumn(
                "PnL",
                format="$%.2f"
            ),
            "fees": st.column_config.NumberColumn(
                "Fees",
                format="$%.2f"
            ),
            "close_reason": st.column_config.TextColumn(
                "Close Type",
                help="How position was closed: close (normal), liquidation, exercise, expire"
            ),
            "trader_notes": st.column_config.TextColumn(
                "ðŸ“ Your Trading Notes",
                help="Document your analysis: strategy, emotions, lessons learned, improvements for next time",
                max_chars=500,
                width="large"
            )
        },
        width='stretch',
        hide_index=True,
        num_rows="fixed",
        disabled=[col for col in display_cols if col != 'trader_notes']
    )
    
    # Update session state with edited notes
    for idx, row in edited_journal.iterrows():
        if pd.notna(row.get('trader_notes')) and row['trader_notes']:
            st.session_state.trade_notes[idx] = row['trader_notes']
    
    # Export functionality
    st.markdown("---")
    col1, col2, col3, col4 = st.columns([3, 1, 1, 1])
    
    with col1:
        notes_count = len([n for n in st.session_state.trade_notes.values() if n])
        if notes_count > 0:
            st.success(f"âœ… {notes_count} trade{'s' if notes_count != 1 else ''} annotated")
        else:
            st.info("ðŸ’¡ Click on the 'Your Trading Notes' column to add annotations")
    
    with col2:
        # Export with full trader IDs
        export_df = filtered_positions[available_cols].copy()
        export_df['trader_notes'] = export_df.index.map(
            lambda i: st.session_state.trade_notes.get(i, "")
        )
        
        csv = export_df.to_csv(index=False)
        st.download_button(
            "ðŸ“¥ Export CSV",
            csv,
            "trading_journal_annotated.csv",
            "text/csv",
            use_container_width=True
        )
    
    with col3:
        if st.button("ðŸ—‘ï¸ Clear Notes", use_container_width=True):
            if st.session_state.trade_notes:
                st.session_state.trade_notes = {}
                st.rerun()
    
    with col4:
        if st.button("ðŸ“Š Stats", use_container_width=True):
            st.toast(f"Trades: {len(journal_df)} | Annotated: {notes_count}")

    # Download button
    csv = edited_journal.to_csv(index=False)
    st.download_button("ðŸ“¥ Download Annotated Journal", csv, "trading_journal_annotated.csv", "text/csv")

# Footer
st.markdown("---")
st.caption(f"Updated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | Deriverse Analytics v3.0 - Production Ready")


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\dashboards\__init__.py =====



===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\scripts\diagnose_data.py =====

# scripts/diagnose_data.py
"""
Data quality diagnostic tool.
Run after analytics to verify all data is properly processed.
"""

import pandas as pd
from pathlib import Path
import json

print("=" * 60)
print("DATA QUALITY DIAGNOSTIC")
print("=" * 60)

# Check positions file
positions_path = Path("data/analytics_output/positions.csv")
if positions_path.exists():
    positions = pd.read_csv(positions_path)
    
    print(f"\nðŸ“Š POSITIONS SUMMARY ({len(positions)} total)")
    print("\nâœ… By Product Type:")
    product_counts = positions['product_type'].value_counts()
    for product, count in product_counts.items():
        print(f"  {product:10} {count:>3} positions")
    
    print("\nâœ… By Market:")
    market_counts = positions['market_id'].value_counts()
    for market, count in market_counts.items():
        print(f"  {market:25} {count:>3} positions")
    
    print("\nâœ… By Trader:")
    trader_counts = positions['trader_id'].value_counts()
    for trader, count in trader_counts.items():
        print(f"  {trader:10} {count:>3} positions")
    
    print("\nðŸ’° PnL BY PRODUCT TYPE:")
    pnl_by_product = positions.groupby('product_type')['realized_pnl'].sum()
    for product, pnl in pnl_by_product.items():
        print(f"  {product:10} ${pnl:>12,.2f}")
    
    print("\nðŸ” OPTION POSITIONS DETAIL:")
    option_positions = positions[positions['product_type'] == 'option']
    if not option_positions.empty:
        print(f"  Found {len(option_positions)} option positions")
        for _, row in option_positions.iterrows():
            print(f"    â€¢ {row['market_id']:30} {row['trader_id']:10} ${row['realized_pnl']:>10,.2f}")
    else:
        print("  âŒ NO OPTION POSITIONS FOUND")
    
    print("\nðŸ“‹ ALL POSITIONS SUMMARY:")
    # Check which columns exist
    available_cols = ['position_id', 'trader_id', 'market_id', 'product_type', 'side', 'realized_pnl']
    if 'close_reason' in positions.columns:
        available_cols.append('close_reason')
    
    print(positions[available_cols].to_string(index=False))
    
else:
    print("âŒ positions.csv not found")

# Check normalized events
events_path = Path("data/normalized/events.jsonl")
if events_path.exists():
    events = []
    with open(events_path) as f:
        for line in f:
            line = line.strip()
            if line:
                events.append(json.loads(line))
    
    df = pd.DataFrame(events)
    
    print(f"\nðŸ“¥ NORMALIZED EVENTS ({len(df)} total)")
    print("\nâœ… By Event Type:")
    event_counts = df['event_type'].value_counts()
    for event_type, count in event_counts.items():
        print(f"  {event_type:10} {count:>3} events")
    
    print("\nâœ… By Product Type:")
    product_counts = df['product_type'].value_counts()
    for product, count in product_counts.items():
        print(f"  {product:10} {count:>3} events")
    
    print("\nðŸŽ¯ OPTION EVENTS BREAKDOWN:")
    option_events = df[df['product_type'] == 'option']
    print(f"  Total option events: {len(option_events)}")
    if not option_events.empty:
        print("\n  By event type:")
        option_event_counts = option_events['event_type'].value_counts()
        for event_type, count in option_event_counts.items():
            print(f"    {event_type:10} {count:>3}")
        
        print("\n  By market:")
        option_market_counts = option_events['market_id'].value_counts()
        for market, count in option_market_counts.items():
            print(f"    {market:30} {count:>3}")
    else:
        print("  âŒ NO OPTION EVENTS")
else:
    print("âŒ events.jsonl not found")

# Check raw mock data
mock_path = Path("configs/mock_data.json")
if mock_path.exists():
    with open(mock_path) as f:
        mock_data = json.load(f)
    
    print(f"\nðŸ“¦ RAW MOCK DATA ({len(mock_data)} events)")
    mock_df = pd.DataFrame(mock_data)
    
    print("\nâœ… By Event Type:")
    event_counts = mock_df['event_type'].value_counts()
    for event_type, count in event_counts.items():
        print(f"  {event_type:10} {count:>3} events")
    
    print("\nâœ… By Product Type:")
    product_counts = mock_df['product_type'].value_counts()
    for product, count in product_counts.items():
        print(f"  {product:10} {count:>3} events")
else:
    print("\nâŒ configs/mock_data.json not found")

print("\n" + "=" * 60)

# Check for duplicates
if events_path.exists():
    print("\nðŸ” CHECKING FOR DUPLICATES...")
    event_ids = [e['event_id'] for e in events]
    unique_ids = set(event_ids)
    
    if len(event_ids) != len(unique_ids):
        print(f"  âš ï¸  WARNING: Found {len(event_ids) - len(unique_ids)} duplicate events!")
        print(f"  Total events: {len(event_ids)}, Unique: {len(unique_ids)}")
    else:
        print(f"  âœ… No duplicates found ({len(event_ids)} unique events)")

print("=" * 60)


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\scripts\generate_mock_data.py =====

# scripts/generate_mock_data.py 
"""
Generate curated mock trading data for Deriverse analytics demo.

This script creates a carefully designed dataset that showcases:
- Profitable and losing trades across all product types
- Risk management (liquidation event)
- Active positions (open trades)
- Complete options lifecycle (buy, sell, exercise, expire)
- Edge cases for robustness testing
"""

import json
import hashlib
from datetime import datetime, timezone, timedelta
from pathlib import Path

OUTPUT_PATH = Path("configs/mock_data.json")
OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)

now = datetime.now(timezone.utc)
events = []

# Realistic Solana wallet addresses (base58 format)
WALLETS = {
    "alice": "7KNXqvHu2QWvDq8cGPGvKZhFvYnz3kQ5mL8xRt2Bp9uV",
    "bob": "5FxM2nQwP4vYkL9mT3xRd8eJbWp7sN6gH2cKt9uVfXyZ",
    "charlie": "9DpT3vHx5kN2qL8mR7wYfJ6bP4sE1cG9nZ5tK3uVwXyA",
    "diana": "4MqL8vYx2kP9nT7wR5fH3bJ6sE1cG4nZ8tK2uVwXyBpQ",
    "evan": "6NrK9wZx3mQ8pU7vS4gI2dL5tF1eH7oA9yM3xVbCwRtE",
    "fiona": "8QtN2xWy5lR7mV9uT6hK3eM4pG1fJ8nB7zL4wVcDxSeF",
    "george": "3HsJ7yVz4nQ6oW8tS5gL2fN9rH1eK6mC8xM5vBdEwRuG",
    "hannah": "2PrM8xUz6oT5nY7vR4jL3gP1sH9eN4mD6zK8wCfGxQuH",
    "ivan": "5TpQ9yXz7mS6oV8uR3kM2hN4rJ1fL5nE7xP6wDgHySvI",
    "julia": "4WqP8zYx5nT7mU9tS2lN6jM3rK1gH4oC8yL5vEfJxRwK",
}


def generate_event_id(event_data, index):
    """Generate deterministic event ID from event data."""
    seed_parts = [
        str(event_data.get('event_type', '')),
        str(event_data.get('timestamp', '') if isinstance(event_data.get('timestamp'), str) else ''),
        str(event_data.get('trader_id', '')),
        str(event_data.get('market_id', '')),
        str(index)
    ]
    return hashlib.sha256("|".join(seed_parts).encode()).hexdigest()


def emit(event, order_type="market"):
    """
    Add event to output array with automatic formatting.
    
    Args:
        event: Event dictionary with trading data
        order_type: Type of order (market/limit/stop) - defaults to market
    """
    # Format timestamp
    if 'timestamp' in event and isinstance(event['timestamp'], datetime):
        event['timestamp'] = event['timestamp'].isoformat().replace("+00:00", "Z")
    
    # Generate event ID
    if 'event_id' not in event:
        event['event_id'] = generate_event_id(event, len(events) + 1)
    
    # Add order type for position events
    if event['event_type'] in ['open', 'close', 'liquidation']:
        event['order_type'] = order_type
    
    events.append(event)


# ================================================================================
# SPOT TRADES - Simple buy/sell with clear profit/loss
# ================================================================================

# Winning spot trade (Alice: +$99)
emit({"event_type": "open", "timestamp": now, "trader_id": WALLETS["alice"], 
      "market_id": "SOL/USDC", "product_type": "spot", "side": "buy", 
      "price": 100, "size": 10, "fee": 0.5}, order_type="stop")

emit({"event_type": "close", "timestamp": now + timedelta(hours=2), "trader_id": WALLETS["alice"], 
      "market_id": "SOL/USDC", "product_type": "spot", "side": "sell", 
      "price": 110, "size": 10, "fee": 0.5}, order_type="market")

# Losing spot trade (Bob: -$252)
emit({"event_type": "open", "timestamp": now + timedelta(minutes=10), "trader_id": WALLETS["bob"], 
      "market_id": "ETH/USDC", "product_type": "spot", "side": "buy", 
      "price": 2000, "size": 5, "fee": 1.0}, order_type="market")

emit({"event_type": "close", "timestamp": now + timedelta(hours=3), "trader_id": WALLETS["bob"], 
      "market_id": "ETH/USDC", "product_type": "spot", "side": "sell", 
      "price": 1950, "size": 5, "fee": 1.0}, order_type="stop")


# ================================================================================
# PERPETUAL TRADES - Long/short positions with liquidation
# ================================================================================

# Winning long perp (Charlie: +$199)
emit({"event_type": "open", "timestamp": now + timedelta(minutes=20), "trader_id": WALLETS["charlie"], 
      "market_id": "SOL-PERP", "product_type": "perp", "side": "long", 
      "price": 100, "size": 10, "fee": 0.5}, order_type="limit")

emit({"event_type": "close", "timestamp": now + timedelta(hours=4), "trader_id": WALLETS["charlie"], 
      "market_id": "SOL-PERP", "product_type": "perp", "side": "long", 
      "price": 120, "size": 10, "fee": 0.5}, order_type="market")

# Winning short perp (Diana: +$1990)
emit({"event_type": "open", "timestamp": now + timedelta(minutes=30), "trader_id": WALLETS["diana"], 
      "market_id": "BTC-PERP", "product_type": "perp", "side": "short", 
      "price": 50000, "size": 1, "fee": 5.0}, order_type="market")

emit({"event_type": "close", "timestamp": now + timedelta(hours=5), "trader_id": WALLETS["diana"], 
      "market_id": "BTC-PERP", "product_type": "perp", "side": "short", 
      "price": 48000, "size": 1, "fee": 5.0}, order_type="market")

# Losing long perp (Evan: -$254)
emit({"event_type": "open", "timestamp": now + timedelta(minutes=40), "trader_id": WALLETS["evan"], 
      "market_id": "ETH-PERP", "product_type": "perp", "side": "long", 
      "price": 2100, "size": 5, "fee": 2.0}, order_type="stop")

emit({"event_type": "close", "timestamp": now + timedelta(hours=6), "trader_id": WALLETS["evan"], 
      "market_id": "ETH-PERP", "product_type": "perp", "side": "long", 
      "price": 2050, "size": 5, "fee": 2.0}, order_type="market")

# LIQUIDATION EVENT - Risk management showcase (Diana: -$875)
emit({"event_type": "open", "timestamp": now + timedelta(hours=1), "trader_id": WALLETS["diana"], 
      "market_id": "SOL-PERP", "product_type": "perp", "side": "long", 
      "price": 105, "size": 50, "fee": 5.0}, order_type="market")

emit({"event_type": "liquidation", "timestamp": now + timedelta(hours=2), "trader_id": WALLETS["diana"], 
      "market_id": "SOL-PERP", "product_type": "perp", "side": "long", 
      "price": 88, "size": 50, "fee": 25.0}, order_type="liquidation")


# ================================================================================
# OPTION TRADES - Complete lifecycle (buy, sell, exercise, expire)
# ================================================================================

# Long call - profitable close (Fiona: +$29)
emit({"event_type": "open", "timestamp": now + timedelta(hours=1), "trader_id": WALLETS["fiona"], 
      "market_id": "SOL-CALL-120-FEB28", "product_type": "option", "option_type": "call", 
      "strike": 120, "expiry": (now + timedelta(days=18)).isoformat().replace("+00:00", "Z"), 
      "side": "buy", "price": 5.0, "size": 10, "fee": 0.5, 
      "delta": 0.65, "implied_vol": 0.45}, order_type="stop")

emit({"event_type": "close", "timestamp": now + timedelta(hours=24), "trader_id": WALLETS["fiona"], 
      "market_id": "SOL-CALL-120-FEB28", "product_type": "option", "option_type": "call", 
      "strike": 120, "expiry": (now + timedelta(days=18)).isoformat().replace("+00:00", "Z"), 
      "side": "sell", "price": 8.0, "size": 10, "fee": 0.5, 
      "delta": 0.85, "implied_vol": 0.50}, order_type="stop")

# Short put - profitable buyback (George: +$36.1)
emit({"event_type": "open", "timestamp": now + timedelta(hours=1, minutes=30), "trader_id": WALLETS["george"], 
      "market_id": "SOL-PUT-90-FEB28", "product_type": "option", "option_type": "put", 
      "strike": 90, "expiry": (now + timedelta(days=18)).isoformat().replace("+00:00", "Z"), 
      "side": "sell", "price": 4.0, "size": 15, "fee": 0.7, 
      "delta": -0.25, "implied_vol": 0.40}, order_type="stop")

emit({"event_type": "close", "timestamp": now + timedelta(hours=36), "trader_id": WALLETS["george"], 
      "market_id": "SOL-PUT-90-FEB28", "product_type": "option", "option_type": "put", 
      "strike": 90, "expiry": (now + timedelta(days=18)).isoformat().replace("+00:00", "Z"), 
      "side": "buy", "price": 1.5, "size": 15, "fee": 0.7, 
      "delta": -0.10, "implied_vol": 0.30}, order_type="market")

# Long put - losing close (Hannah: -$127)
emit({"event_type": "open", "timestamp": now + timedelta(hours=2), "trader_id": WALLETS["hannah"], 
      "market_id": "ETH-PUT-1900-FEB28", "product_type": "option", "option_type": "put", 
      "strike": 1900, "expiry": (now + timedelta(days=18)).isoformat().replace("+00:00", "Z"), 
      "side": "buy", "price": 45.0, "size": 5, "fee": 1.0, 
      "delta": -0.35, "implied_vol": 0.55}, order_type="stop")

emit({"event_type": "close", "timestamp": now + timedelta(hours=48), "trader_id": WALLETS["hannah"], 
      "market_id": "ETH-PUT-1900-FEB28", "product_type": "option", "option_type": "put", 
      "strike": 1900, "expiry": (now + timedelta(days=18)).isoformat().replace("+00:00", "Z"), 
      "side": "sell", "price": 20.0, "size": 5, "fee": 1.0, 
      "delta": -0.15, "implied_vol": 0.40}, order_type="limit")

# Long call - exercised ITM (Ivan: +$2980)
emit({"event_type": "open", "timestamp": now + timedelta(hours=3), "trader_id": WALLETS["ivan"], 
      "market_id": "BTC-CALL-50000-FEB28", "product_type": "option", "option_type": "call", 
      "strike": 50000, "expiry": (now + timedelta(days=18)).isoformat().replace("+00:00", "Z"), 
      "side": "buy", "price": 2000.0, "size": 1, "fee": 10.0}, order_type="market")

emit({"event_type": "exercise", "timestamp": now + timedelta(days=17), "trader_id": WALLETS["ivan"], 
      "market_id": "BTC-CALL-50000-FEB28", "product_type": "option", "option_type": "call", 
      "strike": 50000, "expiry": (now + timedelta(days=18)).isoformat().replace("+00:00", "Z"), 
      "side": "exercise", "size": 1, "fee": 10.0, "underlying_price": 55000})

# Long put - expired worthless (Julia: -$60.2)
emit({"event_type": "open", "timestamp": now + timedelta(hours=4), "trader_id": WALLETS["julia"], 
      "market_id": "SOL-PUT-80-FEB28", "product_type": "option", "option_type": "put", 
      "strike": 80, "expiry": (now + timedelta(days=18)).isoformat().replace("+00:00", "Z"), 
      "side": "buy", "price": 3.0, "size": 20, "fee": 0.2}, order_type="market")

emit({"event_type": "expire", "timestamp": now + timedelta(days=18), "trader_id": WALLETS["julia"], 
      "market_id": "SOL-PUT-80-FEB28", "product_type": "option", "option_type": "put", 
      "strike": 80, "expiry": (now + timedelta(days=18)).isoformat().replace("+00:00", "Z"), 
      "side": "expire", "price": 0.0, "size": 20, "fee": 0.0, "underlying_price": 95})

# Partial close scenario (Alice: +$39 + $69 = $108)
emit({"event_type": "open", "timestamp": now + timedelta(hours=5), "trader_id": WALLETS["alice"], 
      "market_id": "SOL-CALL-110-FEB28", "product_type": "option", "option_type": "call", 
      "strike": 110, "expiry": (now + timedelta(days=18)).isoformat().replace("+00:00", "Z"), 
      "side": "buy", "price": 8.0, "size": 20, "fee": 1.0}, order_type="market")

emit({"event_type": "close", "timestamp": now + timedelta(hours=26), "trader_id": WALLETS["alice"], 
      "market_id": "SOL-CALL-110-FEB28", "product_type": "option", "option_type": "call", 
      "strike": 110, "expiry": (now + timedelta(days=18)).isoformat().replace("+00:00", "Z"), 
      "side": "sell", "price": 12.0, "size": 10, "fee": 0.5}, order_type="market")

emit({"event_type": "close", "timestamp": now + timedelta(hours=50), "trader_id": WALLETS["alice"], 
      "market_id": "SOL-CALL-110-FEB28", "product_type": "option", "option_type": "call", 
      "strike": 110, "expiry": (now + timedelta(days=18)).isoformat().replace("+00:00", "Z"), 
      "side": "sell", "price": 15.0, "size": 10, "fee": 0.5}, order_type="market")


# ================================================================================
# OPEN POSITIONS - Active trades (will appear in dashboard)
# ================================================================================

emit({"event_type": "open", "timestamp": now + timedelta(hours=7), "trader_id": WALLETS["alice"], 
      "market_id": "BTC/USDC", "product_type": "spot", "side": "buy", 
      "price": 51000, "size": 0.5, "fee": 5.0}, order_type="market")

emit({"event_type": "open", "timestamp": now + timedelta(hours=8), "trader_id": WALLETS["bob"], 
      "market_id": "AVAX-PERP", "product_type": "perp", "side": "long", 
      "price": 35.5, "size": 100, "fee": 1.5}, order_type="limit")

emit({"event_type": "open", "timestamp": now + timedelta(hours=9), "trader_id": WALLETS["charlie"], 
      "market_id": "ETH-CALL-2200-MAR15", "product_type": "option", "option_type": "call", 
      "strike": 2200, "expiry": (now + timedelta(days=30)).isoformat().replace("+00:00", "Z"), 
      "side": "buy", "price": 85.0, "size": 3, "fee": 0.5}, order_type="limit")


# ================================================================================
# EDGE CASES - Robustness testing
# ================================================================================

# Duplicate open (will be rejected by validation)
emit({"event_type": "open", "timestamp": now + timedelta(minutes=60), "trader_id": WALLETS["alice"], 
      "market_id": "SOL/USDC", "product_type": "spot", "side": "buy", 
      "price": 105, "size": 5, "fee": 0.3}, order_type="stop")

# Close without open (will be rejected)
emit({"event_type": "close", "timestamp": now + timedelta(hours=10), 
      "trader_id": "GhostWallet1111111111111111111111111111", 
      "market_id": "GHOST-PERP", "product_type": "perp", "side": "long", 
      "price": 999, "size": 1, "fee": 0.1}, order_type="stop")

# Trade events (informational only - not matched)
emit({"event_type": "trade", "timestamp": now + timedelta(minutes=15), 
      "trader_id": "MarketMaker1111111111111111111111111", 
      "market_id": "SOL/USDC", "product_type": "spot", "side": "buy", 
      "price": 101, "size": 100, "fee": 1.0})

emit({"event_type": "trade", "timestamp": now + timedelta(minutes=45), 
      "trader_id": "MarketMaker1111111111111111111111111", 
      "market_id": "ETH-PERP", "product_type": "perp", "side": "sell", 
      "price": 2105, "size": 50, "fee": 5.0})


# ================================================================================
# WRITE OUTPUT
# ================================================================================

with open(OUTPUT_PATH, "w", encoding="utf-8") as f:
    json.dump(events, f, indent=2)

print(f"âœ… Generated {len(events)} curated mock events â†’ {OUTPUT_PATH}")
print(f"   Wallets: {len(WALLETS)} realistic Solana addresses")
print(f"   Closed Positions: 13 (spot: 2, perp: 4, options: 7)")
print(f"   Open Positions: 3 (spot: 1, perp: 1, option: 1)")
print(f"   Risk Features: 1 liquidation event")
print(f"   Format: JSON array - ready for ingestion")


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\scripts\launch_dashboard.py =====

# scripts/launch_dashboard.py

import streamlit as st
from dashboards.app import run_app
from src.common.logging import get_logger
from configs.loader import load_config

logger = get_logger(__name__)


def main():
    config = load_config("configs/dashboard.yaml")

    logger.info("Launching analytics dashboard")

    st.set_page_config(
        page_title="Deriverse Trading Analytics",
        layout="wide"
    )

    run_app(config)


if __name__ == "__main__":
    main()


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\scripts\run_analytics.py =====

# scripts/run_analytics.py - WITH OPEN POSITIONS SUPPORT
import pandas as pd
from pathlib import Path
import io
import logging
import sys
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.analytics.pnl_engine import compute_realized_pnl
from src.analytics.summary import compute_executive_summary
from src.analytics.analytics_builder import AnalyticsBuilder

logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

NORMALIZED_EVENTS_PATH = Path("data/normalized/events.jsonl")
ANALYTICS_OUTPUT_DIR = Path("data/analytics_output")


def load_events(path: Path) -> pd.DataFrame:
    """Load events from JSONL file with flexible timestamp parsing."""
    events = []
    with open(path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if line:
                events.append(pd.read_json(io.StringIO(line), typ="series"))
    
    if not events:
        logger.warning(f"No events found in {path}")
        return pd.DataFrame()
    
    df = pd.DataFrame(events)
    
    try:
        df["timestamp"] = pd.to_datetime(df["timestamp"], format='ISO8601', utc=True)
    except Exception as e:
        logger.warning(f"ISO8601 parsing failed, trying mixed format: {e}")
        df["timestamp"] = pd.to_datetime(df["timestamp"], format='mixed', utc=True)
    
    return df


def run_analytics(events_df, auto_summary=True):
    if events_df.empty:
        logger.error("No events to analyze")
        return None, None, None
    
    logger.info(f"Loaded {len(events_df)} events")

    logger.info("Computing realized PnL (truth engine)")
    positions_df, pnl_df, open_positions_df = compute_realized_pnl(events_df)  # âœ… NOW RETURNS 3 VALUES

    # Build all analytics outputs
    logger.info("Building comprehensive analytics tables...")
    builder = AnalyticsBuilder(positions_df, pnl_df, open_positions_df, ANALYTICS_OUTPUT_DIR)  # âœ… PASS OPEN POSITIONS
    builder.build_all()

    if not positions_df.empty and auto_summary:
        summary = compute_executive_summary(positions_df, pnl_df)
        
        print("\n" + "=" * 50)
        print("EXECUTIVE SUMMARY")
        print("=" * 50)
        print(f"Total Realized PnL:  ${summary['total_pnl']:,.2f}")
        print(f"Total Fees Paid:     ${summary['total_fees']:,.2f}")
        print(f"Total Trades:        {summary['trade_count']}")
        print(f"Win Rate:            {summary['win_rate']:.1%}")
        print(f"Avg Win:             ${summary['avg_win']:,.2f}")
        print(f"Avg Loss:            ${summary['avg_loss']:,.2f}")
        print(f"Best Trade:          ${summary['best_trade']:,.2f}")
        print(f"Worst Trade:         ${summary['worst_trade']:,.2f}")
        print(f"Avg Duration:        {summary['avg_duration']}")
        print(f"Long Ratio:          {summary['long_ratio']:.1%}")
        print(f"Short Ratio:         {summary['short_ratio']:.1%}")
        print(f"Max Drawdown:        ${summary['max_drawdown']:,.2f}")
        
        if 'sharpe_ratio' in summary:
            print(f"Sharpe Ratio:        {summary['sharpe_ratio']:.2f}")
        if 'sortino_ratio' in summary:
            print(f"Sortino Ratio:       {summary['sortino_ratio']:.2f}")
        
        print("=" * 50 + "\n")
    
    # âœ… Show open positions summary
    if not open_positions_df.empty:
        print(f"ðŸ“Š OPEN POSITIONS: {len(open_positions_df)} positions still active")
        for _, pos in open_positions_df.iterrows():
            trader_short = pos['trader_id'][:8] + "..." if len(pos['trader_id']) > 12 else pos['trader_id']
            print(f"  â€¢ {trader_short} | {pos['market_id']:20} | {pos['side']:5} | ${pos['entry_price']:>8,.2f} Ã— {pos['size']:.2f}")

    logger.info("Analytics run complete âœ…")
    return positions_df, pnl_df, open_positions_df


def main():
    logger.info("=" * 60)
    logger.info("Starting Deriverse Analytics Pipeline")
    logger.info("=" * 60)

    if not NORMALIZED_EVENTS_PATH.exists():
        logger.error(f"Normalized events not found at {NORMALIZED_EVENTS_PATH}")
        logger.error("Run 'python -m scripts.generate_mock_data' first")
        return

    events_df = load_events(NORMALIZED_EVENTS_PATH)
    run_analytics(events_df)


if __name__ == "__main__":
    main()


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\scripts\run_ingestion.py =====


# scripts/run_ingestion.py
import logging
from src.ingestion.pipelines import IngestionPipeline
from configs.loader import load_config

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def main():
    logger.info("Starting incremental ingestion")

    config = load_config("configs/ingestion.yaml")
    
    pipeline = IngestionPipeline(
        raw_path=config["raw_data_path"],
        output_path=config["normalized_output_path"],
        checkpoint_path=config["checkpoint_path"],
    )

    count = pipeline.run()
    logger.info(f"Ingested {count} new events")


if __name__ == "__main__":
    main()


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\scripts\validate_analytics.py =====

# scripts/validate_analytics.py
"""
Validation script to verify analytics output quality and correctness.
Run after python -m scripts.run_analytics
"""

import pandas as pd
from pathlib import Path
import sys

OUTPUT_DIR = Path("data/analytics_output")

class bcolors:
    OK = '\033[92m'
    FAIL = '\033[91m'
    WARN = '\033[93m'
    END = '\033[0m'

def validate_file_exists(filename):
    """Check if required file exists."""
    path = OUTPUT_DIR / filename
    if path.exists():
        print(f"{bcolors.OK}âœ“{bcolors.END} {filename} exists")
        return True
    else:
        print(f"{bcolors.FAIL}âœ—{bcolors.END} {filename} missing")
        return False

def validate_positions():
    """Validate positions.csv structure and data quality."""
    df = pd.read_csv(OUTPUT_DIR / "positions.csv")
    
    required_cols = [
        'position_id', 'trader_id', 'market_id', 'product_type', 'side',
        'open_time', 'close_time', 'duration_seconds',
        'entry_price', 'exit_price', 'size', 'gross_pnl', 'fees', 'realized_pnl'
    ]
    
    issues = []
    
    # Check columns
    missing_cols = set(required_cols) - set(df.columns)
    if missing_cols:
        issues.append(f"Missing columns: {missing_cols}")
    
    # Check data quality
    if not df.empty:
        if (df['duration_seconds'] < 0).any():
            issues.append("Negative duration_seconds found")
        
        if (df['fees'] < 0).any():
            issues.append("Negative fees found")
        
        # PnL consistency check
        expected_pnl = df['gross_pnl'] - df['fees']
        if not expected_pnl.equals(df['realized_pnl']):
            max_diff = abs(expected_pnl - df['realized_pnl']).max()
            if max_diff > 0.01:  # Allow for rounding
                issues.append(f"PnL inconsistency detected (max diff: {max_diff:.4f})")
    
    if issues:
        print(f"{bcolors.WARN}âš {bcolors.END} positions.csv has issues:")
        for issue in issues:
            print(f"  - {issue}")
        return False
    else:
        print(f"{bcolors.OK}âœ“{bcolors.END} positions.csv is valid ({len(df)} rows)")
        return True

def validate_summary_metrics():
    """Validate summary_metrics.csv calculations."""
    positions = pd.read_csv(OUTPUT_DIR / "positions.csv")
    summary = pd.read_csv(OUTPUT_DIR / "summary_metrics.csv")
    
    issues = []
    
    for _, row in summary.iterrows():
        trader = row['trader_id']
        trader_pos = positions[positions['trader_id'] == trader]
        
        # Validate win rate
        actual_wins = (trader_pos['realized_pnl'] > 0).sum()
        actual_total = len(trader_pos)
        expected_win_rate = actual_wins / actual_total if actual_total > 0 else 0
        
        if abs(row['win_rate'] - expected_win_rate) > 0.01:
            issues.append(f"{trader}: win_rate mismatch ({row['win_rate']:.2f} vs {expected_win_rate:.2f})")
        
        # Validate long/short ratio
        if abs(row['long_ratio'] + row['short_ratio'] - 1.0) > 0.01:
            issues.append(f"{trader}: long_ratio + short_ratio != 1.0")
        
        # Validate total_pnl
        expected_total = trader_pos['realized_pnl'].sum()
        if abs(row['total_pnl'] - expected_total) > 0.01:
            issues.append(f"{trader}: total_pnl mismatch")
    
    if issues:
        print(f"{bcolors.WARN}âš {bcolors.END} summary_metrics.csv has issues:")
        for issue in issues:
            print(f"  - {issue}")
        return False
    else:
        print(f"{bcolors.OK}âœ“{bcolors.END} summary_metrics.csv is valid")
        return True

def validate_equity_curve():
    """Validate equity_curve.csv drawdown calculations."""
    df = pd.read_csv(OUTPUT_DIR / "equity_curve.csv")
    
    issues = []
    
    for trader in df['trader_id'].unique():
        trader_data = df[df['trader_id'] == trader].sort_values('timestamp')
        
        # Validate drawdown is always <= 0
        if (trader_data['drawdown'] > 0.01).any():
            issues.append(f"{trader}: Positive drawdown found")
        
        # Validate cumulative PnL is monotonic sum
        if not trader_data['cumulative_pnl'].is_monotonic_increasing and not trader_data['cumulative_pnl'].is_monotonic_decreasing:
            # This is actually OK - cumulative can go up and down
            pass
    
    if issues:
        print(f"{bcolors.WARN}âš {bcolors.END} equity_curve.csv has issues:")
        for issue in issues:
            print(f"  - {issue}")
        return False
    else:
        print(f"{bcolors.OK}âœ“{bcolors.END} equity_curve.csv is valid")
        return True

def validate_directional_bias():
    """Validate directional_bias.csv calculations."""
    df = pd.read_csv(OUTPUT_DIR / "directional_bias.csv")
    
    issues = []
    
    for _, row in df.iterrows():
        total = row['long_trades'] + row['short_trades']
        
        if total == 0:
            issues.append(f"{row['trader_id']}: No trades")
            continue
        
        expected_long_ratio = row['long_trades'] / total
        expected_short_ratio = row['short_trades'] / total
        
        if abs(row['long_ratio'] - expected_long_ratio) > 0.01:
            issues.append(f"{row['trader_id']}: long_ratio calculation error")
        
        if abs(row['short_ratio'] - expected_short_ratio) > 0.01:
            issues.append(f"{row['trader_id']}: short_ratio calculation error")
        
        if abs(row['long_ratio'] + row['short_ratio'] - 1.0) > 0.01:
            issues.append(f"{row['trader_id']}: ratios don't sum to 1.0")
    
    if issues:
        print(f"{bcolors.WARN}âš {bcolors.END} directional_bias.csv has issues:")
        for issue in issues:
            print(f"  - {issue}")
        return False
    else:
        print(f"{bcolors.OK}âœ“{bcolors.END} directional_bias.csv is valid")
        return True

def main():
    print("\n" + "=" * 60)
    print("DERIVERSE ANALYTICS VALIDATION")
    print("=" * 60 + "\n")
    
    if not OUTPUT_DIR.exists():
        print(f"{bcolors.FAIL}âœ—{bcolors.END} Output directory not found: {OUTPUT_DIR}")
        print("Run: python -m scripts.run_analytics")
        sys.exit(1)
    
    # Check file existence
    print("Checking required files...")
    required_files = [
        'positions.csv',
        'realized_pnl.csv',
        'equity_curve.csv',
        'summary_metrics.csv',
        'volume_by_market.csv',
        'fees_breakdown.csv',
        'pnl_by_day.csv',
        'pnl_by_hour.csv',
        'directional_bias.csv',
        'order_type_performance.csv'
    ]
    
    all_exist = all(validate_file_exists(f) for f in required_files)
    
    if not all_exist:
        print(f"\n{bcolors.FAIL}âœ— Some files are missing{bcolors.END}")
        sys.exit(1)
    
    print("\nValidating data quality...")
    
    validations = [
        validate_positions(),
        validate_summary_metrics(),
        validate_equity_curve(),
        validate_directional_bias()
    ]
    
    print("\n" + "=" * 60)
    if all(validations):
        print(f"{bcolors.OK}âœ“ ALL VALIDATIONS PASSED{bcolors.END}")
        print("=" * 60 + "\n")
        sys.exit(0)
    else:
        print(f"{bcolors.WARN}âš  SOME VALIDATIONS FAILED{bcolors.END}")
        print("=" * 60 + "\n")
        sys.exit(1)

if __name__ == "__main__":
    main()


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\trades\__init__.py =====



===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\analytics_builder.py =====

# src/analytics/analytics_builder.py - WITH OPEN POSITIONS SUPPORT
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
import logging

logger = logging.getLogger(__name__)


class AnalyticsBuilder:
    """Build all required analytics tables from canonical PnL engine outputs."""
    
    def __init__(self, positions_df: pd.DataFrame, pnl_df: pd.DataFrame, 
                 open_positions_df: pd.DataFrame, output_dir: Path):
        self.positions = positions_df.copy() if not positions_df.empty else pd.DataFrame()
        self.pnl = pnl_df.copy() if not pnl_df.empty else pd.DataFrame()
        self.open_positions = open_positions_df.copy() if not open_positions_df.empty else pd.DataFrame()
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # Ensure timestamps are datetime
        if not self.positions.empty:
            self.positions['open_time'] = pd.to_datetime(self.positions['open_time'])
            self.positions['close_time'] = pd.to_datetime(self.positions['close_time'])
            self.positions['duration_seconds'] = (
                self.positions['close_time'] - self.positions['open_time']
            ).dt.total_seconds()
    
    def build_all(self):
        """Generate all required analytics outputs."""
        logger.info("Building core truth tables...")
        self._build_positions()
        self._build_realized_pnl()
        self._build_open_positions()  # âœ… NEW
        
        if self.positions.empty:
            logger.warning("No closed positions - generating empty analytics")
            self._generate_empty_outputs()
            return
        
        logger.info("Building performance metrics...")
        self._build_equity_curve()
        self._build_summary_metrics()
        
        logger.info("Building volume & fees analytics...")
        self._build_volume_by_market()
        self._build_fees_breakdown()
        
        logger.info("Building time-based analytics...")
        self._build_pnl_by_day()
        self._build_pnl_by_hour()
        
        logger.info("Building behavioral analytics...")
        self._build_directional_bias()
        self._build_order_type_performance()
        
        logger.info("Building options Greeks...")
        self._build_greeks_exposure()
        
        logger.info(f"âœ… All analytics saved to {self.output_dir}")
    
    def _build_positions(self):
        """1. Core Truth: positions.csv"""
        if self.positions.empty:
            pd.DataFrame().to_csv(self.output_dir / 'positions.csv', index=False)
            return
        
        output = self.positions[[
            'position_id', 'trader_id', 'market_id', 'product_type', 'side',
            'open_time', 'close_time', 'duration_seconds',
            'entry_price', 'exit_price', 'size', 'gross_pnl', 'fees', 'realized_pnl',
            'close_reason' 
        ]].copy()
        output.to_csv(self.output_dir / 'positions.csv', index=False)
    
    def _build_realized_pnl(self):
        """2. Core Truth: realized_pnl.csv"""
        if self.positions.empty:
            pd.DataFrame().to_csv(self.output_dir / 'realized_pnl.csv', index=False)
            return
            
        output = self.positions[[
            'close_time', 'trader_id', 'market_id', 'realized_pnl', 'fees'
        ]].copy()
        output.rename(columns={'close_time': 'timestamp'}, inplace=True)
        output['net_pnl'] = output['realized_pnl'] - output['fees']
        output = output[['timestamp', 'trader_id', 'market_id', 'realized_pnl', 'fees', 'net_pnl']]
        output.to_csv(self.output_dir / 'realized_pnl.csv', index=False)
    
    def _build_open_positions(self):
        """âœ… NEW: open_positions.csv - Currently active positions"""
        if self.open_positions.empty:
            pd.DataFrame().to_csv(self.output_dir / 'open_positions.csv', index=False)
            logger.info("No open positions")
            return
        
        output = self.open_positions[[
            'position_id', 'trader_id', 'market_id', 'product_type', 'side',
            'entry_price', 'size', 'fees_paid', 'open_time', 'time_held_seconds'
        ]].copy()
        
        output.to_csv(self.output_dir / 'open_positions.csv', index=False)
        logger.info(f"Saved {len(output)} open positions")
    
    def _build_equity_curve(self):
        """3. Performance: equity_curve.csv"""
        equity = self.positions.copy()
        equity = equity.sort_values('close_time')
        
        result = []
        for trader in equity['trader_id'].unique():
            trader_data = equity[equity['trader_id'] == trader].copy()
            trader_data['cumulative_pnl'] = trader_data['realized_pnl'].cumsum()
            trader_data['rolling_max'] = trader_data['cumulative_pnl'].cummax()
            trader_data['drawdown'] = trader_data['cumulative_pnl'] - trader_data['rolling_max']
            
            for _, row in trader_data.iterrows():
                result.append({
                    'timestamp': row['close_time'],
                    'trader_id': row['trader_id'],
                    'net_realized_pnl': row['realized_pnl'],
                    'cumulative_pnl': row['cumulative_pnl'],
                    'drawdown': row['drawdown']
                })
        
        df = pd.DataFrame(result)
        df.to_csv(self.output_dir / 'equity_curve.csv', index=False)
    
    def _build_summary_metrics(self):
        """4. Performance: summary_metrics.csv"""
        result = []
        
        for trader in self.positions['trader_id'].unique():
            trader_pos = self.positions[self.positions['trader_id'] == trader]
            
            winning = trader_pos[trader_pos['realized_pnl'] > 0]
            losing = trader_pos[trader_pos['realized_pnl'] < 0]
            
            total_pnl = trader_pos['realized_pnl'].sum()
            total_fees = trader_pos['fees'].sum()
            trade_count = len(trader_pos)
            win_rate = len(winning) / trade_count if trade_count > 0 else 0
            avg_win = winning['realized_pnl'].mean() if len(winning) > 0 else 0
            avg_loss = losing['realized_pnl'].mean() if len(losing) > 0 else 0
            best_trade = trader_pos['realized_pnl'].max()
            worst_trade = trader_pos['realized_pnl'].min()
            avg_duration = trader_pos['duration_seconds'].mean()
            
            long_trades = trader_pos[trader_pos['side'].isin(['long', 'buy'])]
            short_trades = trader_pos[trader_pos['side'].isin(['short', 'sell'])]
            long_ratio = len(long_trades) / trade_count if trade_count > 0 else 0
            short_ratio = len(short_trades) / trade_count if trade_count > 0 else 0
            
            trader_sorted = trader_pos.sort_values('close_time')
            cum_pnl = trader_sorted['realized_pnl'].cumsum()
            rolling_max = cum_pnl.cummax()
            drawdown = cum_pnl - rolling_max
            max_drawdown = drawdown.min()
            
            if len(trader_pos) > 1:
                trader_daily = trader_pos.copy()
                trader_daily['date'] = trader_daily['close_time'].dt.date
                daily_returns = trader_daily.groupby('date')['realized_pnl'].sum()
                
                mean_return = daily_returns.mean()
                std_return = daily_returns.std()
                sharpe_ratio = mean_return / std_return if std_return > 0 else 0
                
                downside_returns = daily_returns[daily_returns < 0]
                downside_std = downside_returns.std() if len(downside_returns) > 0 else std_return
                sortino_ratio = mean_return / downside_std if downside_std > 0 else 0
            else:
                sharpe_ratio = 0
                sortino_ratio = 0
            
            result.append({
                'trader_id': trader,
                'total_pnl': total_pnl,
                'total_fees': total_fees,
                'trade_count': trade_count,
                'win_rate': win_rate,
                'avg_win': avg_win,
                'avg_loss': avg_loss,
                'best_trade': best_trade,
                'worst_trade': worst_trade,
                'avg_duration_seconds': avg_duration,
                'long_ratio': long_ratio,
                'short_ratio': short_ratio,
                'max_drawdown': max_drawdown,
                'sharpe_ratio': sharpe_ratio,
                'sortino_ratio': sortino_ratio
            })
        
        df = pd.DataFrame(result)
        df.to_csv(self.output_dir / 'summary_metrics.csv', index=False)
    
    def _build_volume_by_market(self):
        """5. Volume: volume_by_market.csv"""
        result = []
        
        for (market, product), group in self.positions.groupby(['market_id', 'product_type']):
            total_volume = (group['exit_price'] * group['size']).sum()
            trade_count = len(group)
            
            result.append({
                'market_id': market,
                'product_type': product,
                'total_volume': total_volume,
                'trade_count': trade_count
            })
        
        df = pd.DataFrame(result)
        df.to_csv(self.output_dir / 'volume_by_market.csv', index=False)
    
    def _build_fees_breakdown(self):
        """6. Fees: fees_breakdown.csv"""
        result = []
        
        for (trader, product), group in self.positions.groupby(['trader_id', 'product_type']):
            total_fees = group['fees'].sum()
            
            result.append({
                'trader_id': trader,
                'product_type': product,
                'total_fees': total_fees
            })
        
        df = pd.DataFrame(result)
        df.to_csv(self.output_dir / 'fees_breakdown.csv', index=False)
    
    def _build_pnl_by_day(self):
        """7. Time Analytics: pnl_by_day.csv"""
        df = self.positions.copy()
        df['date'] = df['close_time'].dt.date
        
        result = []
        for (date, trader), group in df.groupby(['date', 'trader_id']):
            daily_pnl = group['realized_pnl'].sum()
            
            trader_data = df[df['trader_id'] == trader]
            trader_data = trader_data[trader_data['date'] <= date]
            cumulative_pnl = trader_data['realized_pnl'].sum()
            
            result.append({
                'date': date,
                'trader_id': trader,
                'daily_pnl': daily_pnl,
                'cumulative_pnl': cumulative_pnl
            })
        
        output = pd.DataFrame(result)
        output.to_csv(self.output_dir / 'pnl_by_day.csv', index=False)
    
    def _build_pnl_by_hour(self):
        """8. Time Analytics: pnl_by_hour.csv"""
        df = self.positions.copy()
        df['hour_of_day'] = df['close_time'].dt.hour
        
        result = []
        for (hour, trader), group in df.groupby(['hour_of_day', 'trader_id']):
            avg_pnl = group['realized_pnl'].mean()
            trade_count = len(group)
            
            result.append({
                'hour_of_day': hour,
                'trader_id': trader,
                'avg_pnl': avg_pnl,
                'trade_count': trade_count
            })
        
        output = pd.DataFrame(result)
        output.to_csv(self.output_dir / 'pnl_by_hour.csv', index=False)
    
    def _build_directional_bias(self):
        """9. Behavioral: directional_bias.csv"""
        result = []
        
        for trader, group in self.positions.groupby('trader_id'):
            long_trades = len(group[group['side'].isin(['long', 'buy'])])
            short_trades = len(group[group['side'].isin(['short', 'sell'])])
            total = long_trades + short_trades
            
            result.append({
                'trader_id': trader,
                'long_trades': long_trades,
                'short_trades': short_trades,
                'long_ratio': long_trades / total if total > 0 else 0,
                'short_ratio': short_trades / total if total > 0 else 0
            })
        
        df = pd.DataFrame(result)
        df.to_csv(self.output_dir / 'directional_bias.csv', index=False)
    
    def _build_order_type_performance(self):
        """10. Behavioral: order_type_performance.csv"""
        df = self.positions.copy()
        
        df['order_type'] = df['duration_seconds'].apply(lambda x:
            'market' if x < 300 else
            'limit' if x < 3600 else
            'stop'
        )
        
        result = []
        for order_type, group in df.groupby('order_type'):
            trade_count = len(group)
            avg_pnl = group['realized_pnl'].mean()
            win_rate = (group['realized_pnl'] > 0).mean()
            
            result.append({
                'order_type': order_type,
                'trade_count': trade_count,
                'avg_pnl': avg_pnl,
                'win_rate': win_rate
            })
        
        output = pd.DataFrame(result)
        output.to_csv(self.output_dir / 'order_type_performance.csv', index=False)
    
    def _build_greeks_exposure(self):
        """11. Greeks: greeks_exposure.csv (options only)"""
        options = self.positions[self.positions['product_type'] == 'option'].copy()
        
        if options.empty:
            pd.DataFrame().to_csv(self.output_dir / 'greeks_exposure.csv', index=False)
            return
        
        result = []
        for trader in options['trader_id'].unique():
            trader_opts = options[options['trader_id'] == trader]
            
            net_delta = 0
            for _, opt in trader_opts.iterrows():
                if opt['side'] in ['buy', 'long']:
                    delta_sign = 1
                else:
                    delta_sign = -1
                net_delta += delta_sign * opt['size'] * 0.5
            
            result.append({
                'trader_id': trader,
                'total_option_positions': len(trader_opts),
                'net_delta': net_delta,
                'gamma_exposure': 0,
                'theta_decay': 0
            })
        
        df = pd.DataFrame(result)
        df.to_csv(self.output_dir / 'greeks_exposure.csv', index=False)
    
    def _generate_empty_outputs(self):
        """Generate empty CSV files when no data available."""
        empty_files = [
            'equity_curve.csv', 'summary_metrics.csv', 'volume_by_market.csv',
            'fees_breakdown.csv', 'pnl_by_day.csv', 'pnl_by_hour.csv',
            'directional_bias.csv', 'order_type_performance.csv', 'greeks_exposure.csv'
        ]
        
        for filename in empty_files:
            pd.DataFrame().to_csv(self.output_dir / filename, index=False)


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\debug.py =====

import json
from pathlib import Path
from collections import Counter

def inspect_normalized_data():
    normalized_path = Path("data/normalized/events.jsonl")

    if not normalized_path.exists():
        print("âŒ No normalized data file found.")
        return

    if normalized_path.stat().st_size == 0:
        print("âš ï¸ Normalized file exists but is empty.")
        return

    all_fields = set()
    event_types = Counter()
    sample_events = []

    with normalized_path.open() as f:
        for i, line in enumerate(f):
            event = json.loads(line)
            all_fields.update(event.keys())
            event_types[event.get("event_type")] += 1

            if i < 3:
                sample_events.append(event)

    print("\nðŸ“Š Normalized Data Overview")
    print(f"Total events: {sum(event_types.values())}")

    print("\nEvent types:")
    for et, c in event_types.items():
        print(f"  - {et}: {c}")

    print("\nColumns present:")
    for field in sorted(all_fields):
        print(f"  - {field}")

    print("\nSample events:")
    for i, ev in enumerate(sample_events, 1):
        print(f"\nEvent {i}")
        for k, v in ev.items():
            print(f"  {k}: {v}")


if __name__ == "__main__":
    inspect_normalized_data()


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\pnl_engine.py =====

# src/analytics/pnl_engine.py
import pandas as pd
import hashlib
import logging
from datetime import datetime, timezone

logger = logging.getLogger(__name__)


def compute_realized_pnl(events: pd.DataFrame):
    """
    Canonical PnL engine with full options lifecycle support.
    NOW RETURNS OPEN POSITIONS TOO!
    
    Returns:
        positions_df: Closed positions with realized PnL
        pnl_df: Daily PnL aggregates
        open_positions_df: Currently open positions (NEW!)
    """

    required_cols = {
        "event_type", "timestamp", "trader_id",
        "market_id", "product_type", "side",
        "price", "size", "fee"
    }

    missing = required_cols - set(events.columns)
    if missing:
        raise ValueError(f"Missing required columns: {missing}")

    events = events.sort_values("timestamp")

    open_positions = {}
    closed_positions = []

    # Validation stats
    stats = {
        "duplicate_opens": 0,
        "close_without_open": 0,
        "oversized_closes": 0,
    }

    for _, event in events.iterrows():

        if event["product_type"] == "perp":
            key = (
                event["trader_id"],
                event["market_id"],
                event["product_type"],
                event["side"]
            )
        elif event["product_type"] == "option":
            key = (
                event["trader_id"],
                event["market_id"],
                event["product_type"]
            )
        else:  # spot
            key = (
                event["trader_id"],
                event["market_id"],
                event["product_type"]
            )

        # OPEN POSITION
        if event["event_type"] == "open":
            if key in open_positions:
                stats["duplicate_opens"] += 1
                continue

            position_data = (
                f"{event['trader_id']}|{event['market_id']}|"
                f"{event['timestamp']}|{event.get('side', '')}"
            )
            position_id = hashlib.sha256(position_data.encode()).hexdigest()[:16]

            open_positions[key] = {
                "position_id": position_id,
                "open_time": event["timestamp"],
                "entry_price": event["price"],
                "size": event["size"],
                "fees": event["fee"],
                "trader_id": event["trader_id"],
                "market_id": event["market_id"],
                "product_type": event["product_type"],
                "side": event["side"],
            }
            
            if event["product_type"] == "option":
                open_positions[key]["option_type"] = event.get("option_type")
                open_positions[key]["strike"] = event.get("strike")
                open_positions[key]["expiry"] = event.get("expiry")

        # CLOSE POSITION
        elif event["event_type"] in {"close", "liquidation", "exercise", "expire"}:
            if key not in open_positions:
                stats["close_without_open"] += 1
                continue

            pos = open_positions[key]
            close_size = event["size"]

            if close_size > pos["size"]:
                stats["oversized_closes"] += 1
                continue

            # Calculate fees
            fee_ratio = close_size / pos["size"]
            allocated_open_fee = pos["fees"] * fee_ratio
            close_fee = event.get("fee", 0)
            total_fees = allocated_open_fee + close_fee

            # OPTIONS PNL
            if pos["product_type"] == "option":
                gross_pnl = calculate_option_pnl(
                    event_type=event["event_type"],
                    option_type=pos.get("option_type"),
                    side=pos["side"],
                    entry_price=pos["entry_price"],
                    exit_price=event.get("price", 0),
                    strike=pos.get("strike"),
                    underlying_price=event.get("underlying_price"),
                    size=close_size
                )
                net_pnl = gross_pnl - total_fees
                exit_price = event.get("price", 0)

            # SPOT/PERP PNL
            else:
                exit_price = event["price"]

                if pd.notna(event.get("pnl")):
                    net_pnl = event["pnl"]
                    gross_pnl = net_pnl + total_fees
                else:
                    if pos["side"] in {"long", "buy"}:
                        gross_pnl = (exit_price - pos["entry_price"]) * close_size
                    else:
                        gross_pnl = (pos["entry_price"] - exit_price) * close_size

                    net_pnl = gross_pnl - total_fees

            # Record closed position
            closed_positions.append({
                "position_id": pos["position_id"],
                "open_time": pos["open_time"],
                "close_time": event["timestamp"],
                "trader_id": pos["trader_id"],
                "market_id": pos["market_id"],
                "product_type": pos["product_type"],
                "side": pos["side"],
                "entry_price": pos["entry_price"],
                "exit_price": exit_price,
                "size": close_size,
                "gross_pnl": round(gross_pnl, 4),
                "net_pnl": round(net_pnl, 4),
                "realized_pnl": round(net_pnl, 4),
                "fees": round(total_fees, 4),
                "close_reason": event["event_type"],
            })

            # Update or remove position
            pos["size"] -= close_size
            pos["fees"] -= allocated_open_fee

            if pos["size"] <= 0:
                open_positions.pop(key)

    positions_df = pd.DataFrame(closed_positions)

    # Log validation summary
    logger.info(
        "PnL validation summary | "
        f"duplicate_opens={stats['duplicate_opens']} | "
        f"close_without_open={stats['close_without_open']} | "
        f"oversized_closes={stats['oversized_closes']}"
    )

    if positions_df.empty:
        positions_df = pd.DataFrame()
        pnl_df = pd.DataFrame()
    else:
        # Build daily PnL aggregates
        pnl_df = (
            positions_df
            .assign(date=lambda df: pd.to_datetime(df["close_time"]).dt.date)
            .groupby(
                ["date", "trader_id", "market_id", "product_type"],
                as_index=False
            )
            .agg(
                net_pnl=("net_pnl", "sum"),
                realized_pnl=("realized_pnl", "sum"),
                fees=("fees", "sum"),
                trade_count=("position_id", "count")
            )
        )

    # âœ… NEW: Build open positions dataframe
    open_positions_list = []
    for key, pos in open_positions.items():
        # Calculate time held
        now = datetime.now(timezone.utc)
        open_time = pd.to_datetime(pos["open_time"])
        if open_time.tzinfo is None:
            open_time = open_time.tz_localize(timezone.utc)
        
        time_held = (now - open_time).total_seconds()
        
        open_positions_list.append({
            "position_id": pos["position_id"],
            "trader_id": pos["trader_id"],
            "market_id": pos["market_id"],
            "product_type": pos["product_type"],
            "side": pos["side"],
            "entry_price": pos["entry_price"],
            "size": pos["size"],
            "fees_paid": pos["fees"],
            "open_time": pos["open_time"],
            "time_held_seconds": time_held
        })
    
    open_positions_df = pd.DataFrame(open_positions_list)

    logger.info(
        f"PnL engine results: {len(positions_df)} closed positions, "
        f"{len(open_positions_df)} still open"
    )

    return positions_df, pnl_df, open_positions_df


def calculate_option_pnl(
    event_type: str,
    option_type: str,
    side: str,
    entry_price: float,
    exit_price: float,
    strike: float,
    underlying_price: float,
    size: float
) -> float:
    """Calculate options PnL based on event type."""
    
    if event_type == "close":
        if side == "buy":
            gross_pnl = (exit_price - entry_price) * size
        else:
            gross_pnl = (entry_price - exit_price) * size
        return gross_pnl
    
    elif event_type == "exercise":
        if side == "buy":
            if option_type == "call":
                intrinsic_value = max(0, underlying_price - strike)
            else:
                intrinsic_value = max(0, strike - underlying_price)
            gross_pnl = (intrinsic_value - entry_price) * size
        else:
            if option_type == "call":
                intrinsic_value = max(0, underlying_price - strike)
            else:
                intrinsic_value = max(0, strike - underlying_price)
            gross_pnl = (entry_price - intrinsic_value) * size
        
        return gross_pnl
    
    elif event_type == "expire":
        if side == "buy":
            gross_pnl = -entry_price * size
        else:
            gross_pnl = entry_price * size
        
        return gross_pnl
    
    return 0.0


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\summary.py =====

# src/analytics/summary.py
import pandas as pd

def compute_executive_summary(positions: pd.DataFrame, pnl: pd.DataFrame) -> dict:
    """
    Compute high-level KPIs from canonical PnL outputs.
    
    Args:
        positions: Output from compute_realized_pnl (positions_df)
        pnl: Output from compute_realized_pnl (pnl_df)
    
    Returns:
        Dictionary of KPI metrics
    """
    if positions.empty:
        return {"status": "no_data"}
    
    summary = {}
    
    # Core PnL
    summary["total_pnl"] = pnl["net_pnl"].sum()
    summary["total_fees"] = pnl["fees"].sum()
    summary["trade_count"] = len(positions)
    summary["win_rate"] = (positions["net_pnl"] > 0).mean()
    
    # Win/Loss Analysis
    winning_trades = positions[positions["net_pnl"] > 0]
    losing_trades = positions[positions["net_pnl"] < 0]
    
    summary["avg_win"] = winning_trades["net_pnl"].mean() if len(winning_trades) > 0 else 0
    summary["avg_loss"] = losing_trades["net_pnl"].mean() if len(losing_trades) > 0 else 0
    summary["best_trade"] = positions["net_pnl"].max()
    summary["worst_trade"] = positions["net_pnl"].min()
    
    # Duration Analysis
    positions = positions.copy()
    positions["duration"] = (
        pd.to_datetime(positions["close_time"]) - 
        pd.to_datetime(positions["open_time"])
    )
    summary["avg_duration"] = positions["duration"].mean()
    
    # Directional Bias
    summary["long_ratio"] = (positions["side"].isin(["long", "buy"])).mean()
    summary["short_ratio"] = (positions["side"].isin(["short", "sell"])).mean()
    
    # Drawdown
    pnl_sorted = pnl.sort_values("date")
    pnl_sorted["cum_pnl"] = pnl_sorted["net_pnl"].cumsum()
    pnl_sorted["drawdown"] = pnl_sorted["cum_pnl"] - pnl_sorted["cum_pnl"].cummax()
    summary["max_drawdown"] = pnl_sorted["drawdown"].min()
    
    # âœ… NEW: Risk-Adjusted Returns
    if not pnl.empty and len(pnl) > 1:
        daily_returns = pnl.groupby('date')['net_pnl'].sum()
        
        # Sharpe Ratio (assuming risk-free rate = 0)
        mean_return = daily_returns.mean()
        std_return = daily_returns.std()
        sharpe_ratio = mean_return / std_return if std_return > 0 else 0
        summary["sharpe_ratio"] = sharpe_ratio
        
        # Sortino Ratio (downside deviation only)
        downside_returns = daily_returns[daily_returns < 0]
        downside_std = downside_returns.std() if len(downside_returns) > 0 else std_return
        sortino_ratio = mean_return / downside_std if downside_std > 0 else 0
        summary["sortino_ratio"] = sortino_ratio
    else:
        summary["sharpe_ratio"] = 0
        summary["sortino_ratio"] = 0
    
    return summary


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\validate.py =====

# src/analytics/validate.py - WITH LIQUIDATION SUPPORT
from typing import Dict, Any, Set
from datetime import datetime

class EventValidationError(Exception):
    """Raised when event fails validation."""
    pass

# --- Base required fields for ALL events ---
BASE_REQUIRED_FIELDS = {
    "event_id",
    "event_type",
    "timestamp",
    "trader_id",
    "market_id",
    "product_type"
}

# --- Base optional fields for ALL events ---
BASE_OPTIONAL_FIELDS = {
    "side",
    "price",
    "size",
    "fee",
    "pnl",
    "order_type"
}

# --- Option-specific fields ---
OPTION_REQUIRED_FIELDS = {
    "option_type",
    "strike",
    "expiry"
}

OPTION_OPTIONAL_FIELDS = {
    "delta",
    "gamma",
    "theta",
    "vega",
    "implied_vol",
    "underlying_price"
}

# --- Event type schemas ---
EVENT_TYPE_SCHEMAS = {
    "trade": {
        "required": {"side", "price", "size", "fee"},
        "optional": {"pnl"}
    },
    "open": {
        "required": {"side", "price", "size", "fee"},
        "optional": {"pnl", "order_type"}
    },
    "close": {
        "required": {"side", "price", "size", "fee"},
        "optional": {"pnl", "order_type"}
    },
    "liquidation": {  # âœ… NEW: Liquidation event schema
        "required": {"side", "price", "size", "fee"},
        "optional": {"pnl", "order_type"}
    },
    "exercise": {
        "required": {"side", "size", "fee"},
        "optional": {"price", "pnl", "underlying_price"}
    },
    "expire": {
        "required": {"side", "size"},
        "optional": {"price", "fee", "pnl", "underlying_price"}
    }
}


def validate_event(event: dict) -> None:
    """
    Validate event schema and data quality.
    
    Raises:
        EventValidationError: If validation fails
    """
    event_type = event.get("event_type")
    product_type = event.get("product_type")

    # Trade events are informational only - skip position validation
    if event_type == "trade":
        return

    # Validate product type
    valid_products = {"spot", "perp", "option"}
    if product_type not in valid_products:
        raise EventValidationError(
            f"Invalid product_type: {product_type}. Allowed: {valid_products}"
        )

    # Product-specific side validation
    if product_type == "option":
        allowed_sides = {"buy", "sell", "long", "short", "exercise", "expire"}
    elif product_type == "perp":
        allowed_sides = {"long", "short"}
    elif product_type == "spot":
        allowed_sides = {"buy", "sell"}
    
    side = event.get("side")
    if side and side not in allowed_sides:
        raise EventValidationError(
            f"Invalid side '{side}' for product_type '{product_type}'. "
            f"Must be one of: {allowed_sides}"
        )

    # Build allowed fields based on product type
    allowed_fields = BASE_REQUIRED_FIELDS | BASE_OPTIONAL_FIELDS
    
    if product_type == "option":
        allowed_fields |= OPTION_REQUIRED_FIELDS | OPTION_OPTIONAL_FIELDS
    
    # Add event-specific fields
    if event_type in EVENT_TYPE_SCHEMAS:
        schema = EVENT_TYPE_SCHEMAS[event_type]
        allowed_fields |= schema["required"] | schema["optional"]

    # Check for extra fields (schema drift)
    extra_fields = set(event.keys()) - allowed_fields
    if extra_fields:
        raise EventValidationError(
            f"Unexpected fields detected: {extra_fields}. "
            f"Allowed for {product_type}/{event_type}: {allowed_fields}"
        )

    # Check event-type-specific required fields
    if event_type in EVENT_TYPE_SCHEMAS:
        schema = EVENT_TYPE_SCHEMAS[event_type]
        missing_required = schema["required"] - set(event.keys())
        if missing_required:
            raise EventValidationError(
                f"Event type '{event_type}' missing required fields: {missing_required}"
            )

    # Check option-specific required fields
    if product_type == "option":
        missing_option_required = OPTION_REQUIRED_FIELDS - set(event.keys())
        if missing_option_required:
            raise EventValidationError(
                f"Option product missing required fields: {missing_option_required}"
            )

    # Validate timestamp format
    try:
        timestamp_str = event["timestamp"]
        if timestamp_str.endswith("Z"):
            timestamp_str = timestamp_str.replace("Z", "+00:00")
        datetime.fromisoformat(timestamp_str)
    except (ValueError, AttributeError, TypeError) as e:
        raise EventValidationError(f"Invalid timestamp format: {event.get('timestamp')} - {e}")

    # Validate numeric fields
    numeric_fields = {"price", "size", "fee", "pnl", "strike", "delta", "gamma", 
                     "theta", "vega", "implied_vol", "underlying_price"}
    for field in numeric_fields & event.keys():
        value = event[field]
        if value is not None and not isinstance(value, (int, float)):
            raise EventValidationError(
                f"Field '{field}' must be numeric or null, got {type(value)}: {value}"
            )

    # Validate option-specific values
    if product_type == "option":
        # Validate option_type
        option_type = event.get("option_type")
        if option_type not in {"call", "put"}:
            raise EventValidationError(f"Invalid option_type: {option_type}. Must be 'call' or 'put'")
        
        # Validate expiry format
        expiry = event.get("expiry")
        if expiry:
            try:
                if expiry.endswith("Z"):
                    expiry = expiry.replace("Z", "+00:00")
                datetime.fromisoformat(expiry)
            except (ValueError, AttributeError):
                raise EventValidationError(f"Invalid expiry format: {expiry}")


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\__init__.py =====



===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\common\logging.py =====

import logging

def get_logger(name):
    logger = logging.getLogger(name)
    if not logger.handlers:
        handler = logging.StreamHandler()
        formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        logger.setLevel(logging.INFO)
    return logger


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\common\__init__.py =====



===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\ingestion\normalizer.py =====

# src/ingestion/normalizer.py
from typing import Dict, Any
from datetime import datetime, timezone
import hashlib

def normalize_event(raw_event: Dict[str, Any]) -> Dict[str, Any]:
    """
    Normalize raw event data into canonical schema.
    - Convert keys to expected schema names
    - Convert timestamps to ISO 8601
    - Ensure event_id exists
    - Handle option-specific fields
    - Normalize position terminology (longâ†’buy, shortâ†’sell for options/spot)
    """
    event = raw_event.copy()

    # --- Normalize timestamp ---
    ts = event.get("timestamp")
    if isinstance(ts, (int, float)):
        # Convert Unix timestamp (seconds) to ISO 8601 UTC
        event["timestamp"] = datetime.fromtimestamp(ts, tz=timezone.utc).isoformat()
    elif isinstance(ts, datetime):
        # Convert datetime object to ISO string
        event["timestamp"] = ts.isoformat()
    elif isinstance(ts, str):
        # Ensure proper ISO format with timezone
        try:
            # Handle different formats
            ts_clean = ts.replace("Z", "+00:00")
            dt = datetime.fromisoformat(ts_clean)
            # Standardize to UTC with Z suffix
            if dt.tzinfo is None:
                dt = dt.replace(tzinfo=timezone.utc)
            event["timestamp"] = dt.isoformat().replace("+00:00", "Z")
        except ValueError:
            # Leave as-is; validation will catch errors
            pass

    # --- Normalize keys for backward compatibility ---
    key_mappings = {
        "trader": "trader_id",
        "market": "market_id", 
        "type": "event_type",
        "product": "product_type",
        "optionType": "option_type",  # Handle camelCase
        "impliedVol": "implied_vol"
    }
    
    for old_key, new_key in key_mappings.items():
        if old_key in event and new_key not in event:
            event[new_key] = event.pop(old_key)

    # --- Normalize product_type ---
    if "product_type" in event:
        product = event["product_type"].lower()
        if product in ["perpetual", "future", "futures", "perp"]:
            event["product_type"] = "perp"
        elif product in ["options", "option"]:
            event["product_type"] = "option"
        elif product in ["spot", "cash"]:
            event["product_type"] = "spot"

    # --- Normalize side terminology ---
    # Convert position terms (long/short) to trading terms (buy/sell) for spot and options
    # Keep long/short for perps
    if "side" in event and event.get("product_type") in ["spot", "option"]:
        side = event["side"].lower()
        
        # Only normalize for open/close events, not for exercise/expire
        if event.get("event_type") in ["open", "close", "trade"]:
            if side == "long":
                event["side"] = "buy"
            elif side == "short":
                event["side"] = "sell"
            # Already buy/sell stays as-is

    # --- Normalize option-specific fields ---
    if event.get("product_type") == "option":
        # Normalize option_type
        if "option_type" in event:
            event["option_type"] = event["option_type"].lower()
        
        # Normalize expiry timestamp
        if "expiry" in event and event["expiry"]:
            expiry = event["expiry"]
            if isinstance(expiry, str):
                try:
                    expiry_clean = expiry.replace("Z", "+00:00")
                    dt = datetime.fromisoformat(expiry_clean)
                    # Standardize format
                    if dt.tzinfo is None:
                        dt = dt.replace(tzinfo=timezone.utc)
                    event["expiry"] = dt.isoformat().replace("+00:00", "Z")
                except ValueError:
                    # Leave as-is
                    pass

    # --- Ensure event_id exists ---
    if "event_id" not in event:
        # Create deterministic event ID
        raw_parts = [
            str(event.get('event_type', '')),
            str(event.get('timestamp', '')),
            str(event.get('trader_id', '')),
            str(event.get('market_id', '')),
            str(event.get('product_type', ''))
        ]
        raw = "|".join(raw_parts)
        event["event_id"] = hashlib.sha256(raw.encode()).hexdigest()

    # --- Normalize numeric fields ---
    numeric_fields = ["price", "size", "fee", "pnl", "strike", "delta", 
                     "gamma", "theta", "vega", "implied_vol", "underlying_price"]
    
    for field in numeric_fields:
        if field in event and event[field] is not None:
            try:
                event[field] = float(event[field])
            except (ValueError, TypeError):
                # Keep as-is if conversion fails
                pass

    return event


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\ingestion\pipelines.py =====

# src/ingestion/pipelines.py
import json
import hashlib
from pathlib import Path
from src.ingestion.watermark import WatermarkStore
from src.ingestion.normalizer import normalize_event
from src.analytics.validate import validate_event, EventValidationError


class IngestionPipeline:
    def __init__(self, raw_path: str, output_path: str, checkpoint_path: str):
        self.raw_path = Path(raw_path)
        self.output_path = Path(output_path)
        self.watermark = WatermarkStore(checkpoint_path)

    def run(self) -> int:
        """
        Event-driven ingestion: normalize once, append forever.
        Supports both JSON array and JSONL formats.
        """
        if not self.raw_path.exists():
            raise FileNotFoundError(f"Raw data source not found: {self.raw_path}")

        # Load events based on file format
        if self.raw_path.suffix == '.json':
            # JSON array format (e.g., configs/mock_data.json)
            with self.raw_path.open("r", encoding="utf-8") as f:
                raw_events = json.load(f)
        elif self.raw_path.suffix == '.jsonl':
            # JSONL format (one JSON object per line)
            raw_events = []
            with self.raw_path.open("r", encoding="utf-8") as f:
                for line in f:
                    line = line.strip()
                    if line:  # Skip empty lines
                        raw_events.append(json.loads(line))
        else:
            raise ValueError(f"Unsupported file format: {self.raw_path.suffix}")

        new_events = []
        errors = []

        for idx, raw in enumerate(raw_events, 1):
            try:
                # Generate event_id if missing
                if "event_id" not in raw:
                    seed = (
                        f"{raw.get('event_type')}|"
                        f"{raw.get('timestamp')}|"
                        f"{raw.get('trader_id')}|"
                        f"{raw.get('market_id')}|{idx}"
                    )
                    raw["event_id"] = hashlib.sha256(seed.encode()).hexdigest()

                # Skip if already processed
                if not self.watermark.is_new(raw["event_id"]):
                    continue

                # Normalize and validate
                normalized = normalize_event(raw)
                validate_event(normalized)

                new_events.append(normalized)
                self.watermark.mark(raw["event_id"])

            except EventValidationError as e:
                errors.append(f"Event {idx}: Validation failed - {e}")
            except Exception as e:
                errors.append(f"Event {idx}: Unexpected error - {e}")

        # Report errors
        if errors:
            print(f"âš ï¸  {len(errors)} events had issues:")
            for e in errors[:5]:
                print(f"   - {e}")
            if len(errors) > 5:
                print(f"   ... and {len(errors) - 5} more")

        # Write normalized events to output (JSONL format)
        self.output_path.parent.mkdir(parents=True, exist_ok=True)
        with self.output_path.open("a", encoding="utf-8") as f:
            for e in new_events:
                f.write(json.dumps(e) + "\n")

        print(f"âœ… Ingested {len(new_events)} valid events")
        return len(new_events)


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\ingestion\watermark.py =====

# src/ingestion/watermark.py
import json
from pathlib import Path
from typing import Set

class WatermarkStore:
    """
    Persistent watermark store to prevent reprocessing events.
    """

    def __init__(self, path: str):
        self.path = Path(path)
        self.seen: Set[str] = set()
        self._load()

    def _load(self):
        if self.path.exists():
            with open(self.path, "r") as f:
                self.seen = set(json.load(f))

    def _save(self):
        self.path.parent.mkdir(parents=True, exist_ok=True)
        with open(self.path, "w") as f:
            json.dump(list(self.seen), f)

    def is_new(self, event_id: str) -> bool:
        return event_id not in self.seen

    def mark(self, event_id: str):
        self.seen.add(event_id)
        self._save()


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\ingestion\__init__.py =====



===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\__init__.py =====



===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\tests\analytics\test_ingestion.py =====

# Create a test script test_ingestion.py
import json

with open("data/normalized/events.jsonl", "r") as f:
    for i, line in enumerate(f, 1):
        line = line.strip()
        if line:
            try:
                data = json.loads(line)
                print(f"Line {i}: OK - {data.get('event_type', 'N/A')}")
            except json.JSONDecodeError as e:
                print(f"Line {i}: ERROR - {e}")
                print(f"  Content: {line[:50]}...")
        else:
            print(f"Line {i}: EMPTY LINE")


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\tests\analytics\test_pnl_engine.py =====

import pandas as pd
from datetime import datetime, timezone

from src.analytics.pnl_engine import compute_realized_pnl

def test_simple_open_close_pnl():
    events = pd.DataFrame([
        {
            "event_id": "e1",
            "event_type": "open",
            "timestamp": datetime(2026, 1, 1, tzinfo=timezone.utc),
            "trader_id": "T1",
            "market_id": "BTC-PERP",
            "product_type": "perp",
            "side": "long",
            "price": 100.0,
            "size": 1,
            "fee": 0.5,
        },
        {
            "event_id": "e2",
            "event_type": "close",
            "timestamp": datetime(2026, 1, 2, tzinfo=timezone.utc),
            "trader_id": "T1",
            "market_id": "BTC-PERP",
            "product_type": "perp",
            "side": "long",
            "price": 110.0,
            "size": 1,
            "fee": 0.5,
            "pnl": 9.0,  # truth reference
        },
    ])

    positions, pnl = compute_realized_pnl(events)

    assert len(positions) == 1
    assert positions.iloc[0]["realized_pnl"] == 9.0

def test_open_without_close_has_no_pnl():
    events = pd.DataFrame([
        {
            "event_id": "e1",
            "event_type": "open",
            "timestamp": datetime.now(timezone.utc),
            "trader_id": "T1",
            "market_id": "SOL-PERP",
            "product_type": "perp",
            "side": "long",
            "price": 50,
            "size": 2,
            "fee": 0.2,
        }
    ])

    positions, pnl = compute_realized_pnl(events)

    assert positions.empty
    assert pnl.empty

def test_pnl_only_on_close_events():
    events = pd.DataFrame([
        {
            "event_id": "e1",
            "event_type": "trade",
            "timestamp": datetime.now(timezone.utc),
            "trader_id": "T1",
            "market_id": "SOL/USDC",
            "product_type": "spot",
            "side": "buy",
            "price": 100,
            "size": 1,
            "fee": 0.1,
        }
    ])

    positions, pnl = compute_realized_pnl(events)

    assert positions.empty
    assert pnl.empty
def test_pnl_engine_is_deterministic():
    events = pd.DataFrame([
        {
            "event_id": "e1",
            "event_type": "open",
            "timestamp": datetime(2026, 1, 1, tzinfo=timezone.utc),
            "trader_id": "T2",
            "market_id": "ETH-PERP",
            "product_type": "perp",
            "side": "short",
            "price": 200,
            "size": 1,
            "fee": 0.3,
        },
        {
            "event_id": "e2",
            "event_type": "close",
            "timestamp": datetime(2026, 1, 2, tzinfo=timezone.utc),
            "trader_id": "T2",
            "market_id": "ETH-PERP",
            "product_type": "perp",
            "side": "short",
            "price": 180,
            "size": 1,
            "fee": 0.3,
            "pnl": 19.4,
        },
    ])

    p1, pnl1 = compute_realized_pnl(events)
    p2, pnl2 = compute_realized_pnl(events)

    pd.testing.assert_frame_equal(p1, p2)
    pd.testing.assert_frame_equal(pnl1, pnl2)

def test_close_without_open_is_rejected():
    events = pd.DataFrame([
        {
            "event_id": "e1",
            "event_type": "close",
            "timestamp": datetime.now(timezone.utc),
            "trader_id": "T3",
            "market_id": "BTC-PERP",
            "product_type": "perp",
            "side": "long",
            "price": 120,
            "size": 1,
            "fee": 0.4,
            "pnl": 0,
        }
    ])

    positions, pnl = compute_realized_pnl(events)

    assert positions.empty
    assert pnl.empty
def test_partial_close_pnl():
    events = pd.DataFrame([
        {
            "event_id": "e1",
            "event_type": "open",
            "timestamp": datetime(2026, 1, 1, tzinfo=timezone.utc),
            "trader_id": "T1",
            "market_id": "BTC-PERP",
            "product_type": "perp",
            "side": "long",
            "price": 100.0,
            "size": 10,
            "fee": 1.0,
        },
        {
            # partial close (50%)
            "event_id": "e2",
            "event_type": "close",
            "timestamp": datetime(2026, 1, 2, tzinfo=timezone.utc),
            "trader_id": "T1",
            "market_id": "BTC-PERP",
            "product_type": "perp",
            "side": "long",
            "price": 110.0,
            "size": 5,
            "fee": 0.5,
        },
        {
            # final close
            "event_id": "e3",
            "event_type": "close",
            "timestamp": datetime(2026, 1, 3, tzinfo=timezone.utc),
            "trader_id": "T1",
            "market_id": "BTC-PERP",
            "product_type": "perp",
            "side": "long",
            "price": 120.0,
            "size": 5,
            "fee": 0.5,
        },
    ])

    positions, pnl = compute_realized_pnl(events)

    assert len(positions) == 2

    realized = positions["realized_pnl"].sum()
    assert round(realized, 2) == round(
        ((110 - 100) * 5 + (120 - 100) * 5) - 2.0, 2
    )

def test_multiple_partial_closes_order_independent():
    base_events = [
        {
            "event_id": "o1",
            "event_type": "open",
            "timestamp": datetime(2026, 1, 1, tzinfo=timezone.utc),
            "trader_id": "T1",
            "market_id": "BTC-PERP",
            "product_type": "perp",
            "side": "long",
            "price": 100,
            "size": 10,
            "fee": 1.0,
        },
        {
            "event_id": "c1",
            "event_type": "close",
            "timestamp": datetime(2026, 1, 2, tzinfo=timezone.utc),
            "trader_id": "T1",
            "market_id": "BTC-PERP",
            "product_type": "perp",
            "side": "long",
            "price": 110,
            "size": 4,
            "fee": 0.4,
        },
        {
            "event_id": "c2",
            "event_type": "close",
            "timestamp": datetime(2026, 1, 3, tzinfo=timezone.utc),
            "trader_id": "T1",
            "market_id": "BTC-PERP",
            "product_type": "perp",
            "side": "long",
            "price": 120,
            "size": 6,
            "fee": 0.6,
        },
    ]

    df1 = pd.DataFrame(base_events)
    df2 = pd.DataFrame(reversed(base_events))

    p1, pnl1 = compute_realized_pnl(df1)
    p2, pnl2 = compute_realized_pnl(df2)

    pd.testing.assert_frame_equal(p1, p2)
    pd.testing.assert_frame_equal(pnl1, pnl2)
def test_liquidation_is_partial_close():
    events = pd.DataFrame([
        {
            "event_id": "o1",
            "event_type": "open",
            "timestamp": datetime(2026, 1, 1, tzinfo=timezone.utc),
            "trader_id": "T9",
            "market_id": "ETH-PERP",
            "product_type": "perp",
            "side": "long",
            "price": 200,
            "size": 10,
            "fee": 1.0,
        },
        {
            "event_id": "l1",
            "event_type": "liquidation",
            "timestamp": datetime(2026, 1, 2, tzinfo=timezone.utc),
            "trader_id": "T9",
            "market_id": "ETH-PERP",
            "product_type": "perp",
            "side": "long",
            "price": 150,
            "size": 4,
            "fee": 0.5,
        },
    ])

    positions, pnl = compute_realized_pnl(events)

    assert len(positions) == 1
    assert positions.iloc[0]["close_reason"] == "liquidation"


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\tests\analytics\__init__.py =====



===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\tests\__init__.py =====



===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\main.py =====

def main():
    print("Hello from deriverse-data-puller!")


if __name__ == "__main__":
    main()


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\pyproject.toml =====

[project]
name = "deriverse-data-puller"
version = "0.1.0"
description = "Mock on-chain trading analytics system for Deriverse"
readme = "README.md"
requires-python = ">=3.10"

dependencies = [
    "matplotlib>=3.10.8",
    "pandas>=2.3.3",
    "plotly>=6.5.2",
    "pyyaml",
    "requests>=2.32.5",
    "streamlit",
]

