

===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\.vscode\settings.json =====

{
    "python.defaultInterpreterPath": "${workspaceFolder}/.venv/Scripts/python.exe",
    "python.analysis.extraPaths": ["./"],
    "python.autoComplete.extraPaths": [
        "${workspaceFolder}/.venv/Lib/site-packages"
    ]
}


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\configs\analytics.yaml =====

# Path to the normalized events generated by mock data
events_path: "data/normalized/events.jsonl"

# Where analytics output should go
output_path: "data/analytics_output"

# Any additional options your analytics scripts might use
compute_drawdowns: true
compute_exposure: true
compute_win_rate: true
compute_fees: true
time_bucket: "daily"


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\configs\ingestion.yaml =====

# configs/ingestion.yaml

# Path to raw mock protocol events (JSON array)
raw_data_path: configs/mock_data.json

# Append-only normalized output (JSONL format)
normalized_output_path: data/normalized/events.jsonl

# Watermark / checkpoint store for incremental ingestion
checkpoint_path: data/checkpoints/watermark.json

# Allowed lateness for event-time processing (seconds)
allowed_lateness_seconds: 0

# Optional controls (future-safe)
markets: []
traders: []
max_events_per_run: null


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\configs\loader.py =====

# configs/loader.py

import yaml
from pathlib import Path
import logging  # âœ… ADD THIS

logger = logging.getLogger(__name__) 

def load_config(path: str) -> dict:
    with open(Path(path), "r") as f:
        return yaml.safe_load(f)


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\configs\mock_data.json =====

[
  {
    "event_type": "open",
    "timestamp": "2026-02-09T15:40:52.770879+00:00",
    "trader_id": "trader_A",
    "market_id": "SOL-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 100,
    "size": 1,
    "fee": 0.5
  },
  {
    "event_type": "close",
    "timestamp": "2026-02-09T16:40:52.770879+00:00",
    "trader_id": "trader_A",
    "market_id": "SOL-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 120,
    "size": 1,
    "fee": 0.5
  },
  {
    "event_type": "open",
    "timestamp": "2026-02-09T15:50:52.770879+00:00",
    "trader_id": "trader_B",
    "market_id": "ETH-PERP",
    "product_type": "perp",
    "side": "short",
    "price": 2000,
    "size": 1,
    "fee": 1.0
  },
  {
    "event_type": "close",
    "timestamp": "2026-02-09T17:40:52.770879+00:00",
    "trader_id": "trader_B",
    "market_id": "ETH-PERP",
    "product_type": "perp",
    "side": "short",
    "price": 1900,
    "size": 1,
    "fee": 1.0
  },
  {
    "event_type": "open",
    "timestamp": "2026-02-09T16:00:52.770879+00:00",
    "trader_id": "trader_C",
    "market_id": "SOL/USDC",
    "product_type": "spot",
    "side": "buy",
    "price": 100,
    "size": 2,
    "fee": 0.2
  },
  {
    "event_type": "close",
    "timestamp": "2026-02-09T18:40:52.770879+00:00",
    "trader_id": "trader_C",
    "market_id": "SOL/USDC",
    "product_type": "spot",
    "side": "buy",
    "price": 92,
    "size": 2,
    "fee": 0.2
  },
  {
    "event_type": "open",
    "timestamp": "2026-02-09T16:10:52.770879+00:00",
    "trader_id": "trader_A",
    "market_id": "SOL-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 105,
    "size": 1,
    "fee": 0.5
  },
  {
    "event_type": "close",
    "timestamp": "2026-02-09T19:40:52.770879+00:00",
    "trader_id": "ghost_trader",
    "market_id": "BTC-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 30000,
    "size": 1,
    "fee": 2.0
  },
  {
    "event_type": "close",
    "timestamp": "2026-02-09T20:40:52.770879+00:00",
    "trader_id": "trader_B",
    "market_id": "ETH-PERP",
    "product_type": "perp",
    "side": "short",
    "price": 1800,
    "size": 5,
    "fee": 1.5
  },
  {
    "event_type": "trade",
    "timestamp": "2026-02-09T15:45:52.770879+00:00",
    "trader_id": "trader_X",
    "market_id": "SOL-PERP",
    "product_type": "perp",
    "side": "buy",
    "price": 101,
    "size": 0.5,
    "fee": 0.1
  },
  {
    "event_type": "trade",
    "timestamp": "2026-02-09T15:55:52.770879+00:00",
    "trader_id": "trader_Y",
    "market_id": "ETH-PERP",
    "product_type": "perp",
    "side": "sell",
    "price": 1995,
    "size": 0.3,
    "fee": 0.1
  },
  {
    "event_type": "open",
    "timestamp": "2026-02-09T16:05:52.770879+00:00",
    "trader_id": "trader_D",
    "market_id": "ETH-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 2100,
    "size": 1,
    "fee": 1.0
  },
  {
    "event_type": "close",
    "timestamp": "2026-02-09T19:40:52.770879+00:00",
    "trader_id": "trader_D",
    "market_id": "ETH-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 2050,
    "size": 1,
    "fee": 1.0
  },
  {
    "event_type": "open",
    "timestamp": "2026-02-09T16:40:52.770879+00:00",
    "trader_id": "trader_E",
    "market_id": "SOL-CALL-120-20241227",
    "product_type": "option",
    "option_type": "call",
    "strike": 120,
    "expiry": "2024-12-27T23:59:59.000000",
    "side": "buy",
    "price": 5.0,
    "size": 10,
    "fee": 2.5,
    "delta": 0.65,
    "implied_vol": 0.45
  },
  {
    "event_type": "close",
    "timestamp": "2026-02-10T16:40:52.770879+00:00",
    "trader_id": "trader_E",
    "market_id": "SOL-CALL-120-20241227",
    "product_type": "option",
    "option_type": "call",
    "strike": 120,
    "expiry": "2024-12-27T23:59:59.000000",
    "side": "sell",
    "price": 8.0,
    "size": 10,
    "fee": 2.5,
    "delta": 0.85,
    "implied_vol": 0.5
  },
  {
    "event_type": "open",
    "timestamp": "2026-02-09T17:40:52.770879+00:00",
    "trader_id": "trader_F",
    "market_id": "ETH-PUT-1900-20241227",
    "product_type": "option",
    "option_type": "put",
    "strike": 1900,
    "expiry": "2024-12-27T23:59:59.000000",
    "side": "buy",
    "price": 45.0,
    "size": 5,
    "fee": 5.0,
    "delta": -0.35,
    "implied_vol": 0.55
  },
  {
    "event_type": "close",
    "timestamp": "2026-02-11T15:40:52.770879+00:00",
    "trader_id": "trader_F",
    "market_id": "ETH-PUT-1900-20241227",
    "product_type": "option",
    "option_type": "put",
    "strike": 1900,
    "expiry": "2024-12-27T23:59:59.000000",
    "side": "sell",
    "price": 20.0,
    "size": 5,
    "fee": 5.0,
    "delta": -0.15,
    "implied_vol": 0.4
  },
  {
    "event_type": "exercise",
    "timestamp": "2026-03-11T15:40:52.770879+00:00",
    "trader_id": "trader_G",
    "market_id": "BTC-CALL-35000-20241227",
    "product_type": "option",
    "option_type": "call",
    "strike": 35000,
    "expiry": "2024-12-27T23:59:59.000000",
    "side": "exercise",
    "price": 35000,
    "size": 2,
    "fee": 50.0,
    "underlying_price": 38000
  },
  {
    "event_type": "expire",
    "timestamp": "2024-12-27T23:59:59+00:00",
    "trader_id": "trader_H",
    "market_id": "SOL-PUT-80-20241227",
    "product_type": "option",
    "option_type": "put",
    "strike": 80,
    "expiry": "2024-12-27T23:59:59.000000",
    "side": "expire",
    "price": 0.0,
    "size": 3,
    "fee": 0.0,
    "underlying_price": 95
  },
  {
    "event_type": "open",
    "timestamp": "2026-02-09T18:40:52.770879+00:00",
    "trader_id": "trader_I",
    "market_id": "SOL-CALL-110-20241227",
    "product_type": "option",
    "option_type": "call",
    "strike": 110,
    "expiry": "2024-12-27T23:59:59.000000",
    "side": "buy",
    "price": 8.0,
    "size": 20,
    "fee": 8.0
  },
  {
    "event_type": "close",
    "timestamp": "2026-02-10T18:40:52.770879+00:00",
    "trader_id": "trader_I",
    "market_id": "SOL-CALL-110-20241227",
    "product_type": "option",
    "option_type": "call",
    "strike": 110,
    "expiry": "2024-12-27T23:59:59.000000",
    "side": "sell",
    "price": 12.0,
    "size": 10,
    "fee": 6.0
  }
]


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\configs\__init__.py =====



===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\dashboards\app.py =====

import streamlit as st
import pandas as pd
from pathlib import Path

DATA = Path("data/analytics_output")

st.set_page_config(layout="wide")
st.title("Deriverse Trading Analytics")

equity = pd.read_csv(DATA / "equity_curve.csv", parse_dates=["timestamp"])
win_rate = pd.read_csv(DATA / "win_rate.csv")
fees = pd.read_csv(DATA / "fees.csv")

trader = st.selectbox("Select trader", equity["trader_id"].unique())

col1, col2, col3 = st.columns(3)

with col1:
    st.metric(
        "Total PnL",
        f"{equity[equity.trader_id == trader].cumulative_pnl.iloc[-1]:.2f}"
    )

with col2:
    st.metric(
        "Win Rate",
        f"{win_rate[win_rate.trader_id == trader].win_rate.iloc[0]*100:.1f}%"
    )

with col3:
    st.metric(
        "Total Fees",
        f"{fees[fees.trader_id == trader].total_fees.iloc[0]:.2f}"
    )

st.subheader("Equity Curve")
st.line_chart(
    equity[equity.trader_id == trader]
    .set_index("timestamp")["cumulative_pnl"]
)


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\dashboards\__init__.py =====



===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\scripts\generate_mock_data.py =====

import json
import random
import os
import hashlib
from datetime import datetime, timezone, timedelta
from pathlib import Path

# -------------------------------
# CONFIG
# -------------------------------
OUTPUT_PATH = Path("data/normalized/events.jsonl")  # âœ… CORRECT: JSONL format
OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)

SEED = int(os.getenv("MOCK_SEED", "42"))
random.seed(SEED)

# Use timezone-aware datetime
now = datetime.now(timezone.utc)
events = []

def generate_event_id(event_data, index):
    """Generate deterministic event ID."""
    seed_parts = [
        str(event_data.get('event_type', '')),
        str(event_data.get('timestamp', '') if isinstance(event_data.get('timestamp'), str) else ''),
        str(event_data.get('trader_id', '')),
        str(event_data.get('market_id', '')),
        str(index)
    ]
    seed = "|".join(seed_parts)
    return hashlib.sha256(seed.encode()).hexdigest()

def emit(event):
    """Helper to add event with proper formatting and event_id."""
    # Ensure timestamp is ISO string
    if 'timestamp' in event and isinstance(event['timestamp'], datetime):
        event['timestamp'] = event['timestamp'].isoformat().replace("+00:00", "Z")
    
    # Generate event_id if not present
    if 'event_id' not in event:
        event['event_id'] = generate_event_id(event, len(events) + 1)
    
    events.append(event)

# --------------------------------------------------
# 1ï¸âƒ£ CLEAN OPEN â†’ CLOSE PAIRS (3 positions)
# --------------------------------------------------

# --- WINNING LONG ---
emit({
    "event_type": "open",
    "timestamp": now,
    "trader_id": "trader_A",
    "market_id": "SOL-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 100,
    "size": 1,
    "fee": 0.5,
})

emit({
    "event_type": "close",
    "timestamp": now + timedelta(hours=1),
    "trader_id": "trader_A",
    "market_id": "SOL-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 120,
    "size": 1,
    "fee": 0.5,
})

# --- WINNING SHORT ---
emit({
    "event_type": "open",
    "timestamp": now + timedelta(minutes=10),
    "trader_id": "trader_B",
    "market_id": "ETH-PERP",
    "product_type": "perp",
    "side": "short",
    "price": 2000,
    "size": 1,
    "fee": 1.0,
})

emit({
    "event_type": "close",
    "timestamp": now + timedelta(hours=2),
    "trader_id": "trader_B",
    "market_id": "ETH-PERP",
    "product_type": "perp",
    "side": "short",
    "price": 1900,
    "size": 1,
    "fee": 1.0,
})

# --- FORCED LOSING SPOT TRADE ---
emit({
    "event_type": "open",
    "timestamp": now + timedelta(minutes=20),
    "trader_id": "trader_C",
    "market_id": "SOL/USDC",
    "product_type": "spot",
    "side": "buy",
    "price": 100,
    "size": 2,
    "fee": 0.2,
})

emit({
    "event_type": "close",
    "timestamp": now + timedelta(hours=3),
    "trader_id": "trader_C",
    "market_id": "SOL/USDC",
    "product_type": "spot",
    "side": "buy",
    "price": 92,
    "size": 2,
    "fee": 0.2,
})

# --------------------------------------------------
# 2ï¸âƒ£ DUPLICATE OPEN (intentional edge case)
# --------------------------------------------------
emit({
    "event_type": "open",
    "timestamp": now + timedelta(minutes=30),
    "trader_id": "trader_A",
    "market_id": "SOL-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 105,
    "size": 1,
    "fee": 0.5,
})

# --------------------------------------------------
# 3ï¸âƒ£ CLOSE WITHOUT OPEN (intentional edge case)
# --------------------------------------------------
emit({
    "event_type": "close",
    "timestamp": now + timedelta(hours=4),
    "trader_id": "ghost_trader",
    "market_id": "BTC-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 30000,
    "size": 1,
    "fee": 2.0,
})

# --------------------------------------------------
# 4ï¸âƒ£ OVERSIZED CLOSE (intentional edge case)
# --------------------------------------------------
emit({
    "event_type": "close",
    "timestamp": now + timedelta(hours=5),
    "trader_id": "trader_B",
    "market_id": "ETH-PERP",
    "product_type": "perp",
    "side": "short",
    "price": 1800,
    "size": 5,
    "fee": 1.5,
})

# --------------------------------------------------
# 5ï¸âƒ£ TRADE / NOISE EVENTS
# --------------------------------------------------
emit({
    "event_type": "trade",
    "timestamp": now + timedelta(minutes=5),
    "trader_id": "trader_X",
    "market_id": "SOL-PERP",
    "product_type": "perp",
    "side": "buy",
    "price": 101,
    "size": 0.5,
    "fee": 0.1,
})

emit({
    "event_type": "trade",
    "timestamp": now + timedelta(minutes=15),
    "trader_id": "trader_Y",
    "market_id": "ETH-PERP",
    "product_type": "perp",
    "side": "sell",
    "price": 1995,
    "size": 0.3,
    "fee": 0.1,
})

# --- LOSING LONG PERPETUAL TRADE ---
emit({
    "event_type": "open",
    "timestamp": now + timedelta(minutes=25),
    "trader_id": "trader_D",
    "market_id": "ETH-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 2100,
    "size": 1,
    "fee": 1.0,
})

emit({
    "event_type": "close",
    "timestamp": now + timedelta(hours=4),
    "trader_id": "trader_D",
    "market_id": "ETH-PERP",
    "product_type": "perp",
    "side": "long",
    "price": 2050,
    "size": 1,
    "fee": 1.0,
})

# --------------------------------------------------
# 6ï¸âƒ£ OPTIONS TRADES 
# --------------------------------------------------

# --- CALL OPTION: Winning trade ---
emit({
    "event_type": "open",
    "timestamp": now + timedelta(hours=1),
    "trader_id": "trader_E",
    "market_id": "SOL-CALL-120-20241227",
    "product_type": "option",
    "option_type": "call",
    "strike": 120,
    "expiry": "2024-12-27T23:59:59Z",
    "side": "buy",
    "price": 5.0,
    "size": 10,
    "fee": 2.5,
    "delta": 0.65,
    "implied_vol": 0.45,
})

emit({
    "event_type": "close",
    "timestamp": now + timedelta(hours=25),
    "trader_id": "trader_E",
    "market_id": "SOL-CALL-120-20241227",
    "product_type": "option",
    "option_type": "call",
    "strike": 120,
    "expiry": "2024-12-27T23:59:59Z",
    "side": "sell",
    "price": 8.0,
    "size": 10,
    "fee": 2.5,
    "delta": 0.85,
    "implied_vol": 0.50,
})

# --- PUT OPTION: Losing trade ---
emit({
    "event_type": "open",
    "timestamp": now + timedelta(hours=2),
    "trader_id": "trader_F",
    "market_id": "ETH-PUT-1900-20241227",
    "product_type": "option",
    "option_type": "put",
    "strike": 1900,
    "expiry": "2024-12-27T23:59:59Z",
    "side": "buy",
    "price": 45.0,
    "size": 5,
    "fee": 5.0,
    "delta": -0.35,
    "implied_vol": 0.55,
})

emit({
    "event_type": "close",
    "timestamp": now + timedelta(hours=48),
    "trader_id": "trader_F",
    "market_id": "ETH-PUT-1900-20241227",
    "product_type": "option",
    "option_type": "put",
    "strike": 1900,
    "expiry": "2024-12-27T23:59:59Z",
    "side": "sell",
    "price": 20.0,
    "size": 5,
    "fee": 5.0,
    "delta": -0.15,
    "implied_vol": 0.40,
})

# --- OPTION EXERCISE (rare but important) ---
emit({
    "event_type": "exercise",
    "timestamp": now + timedelta(days=30),
    "trader_id": "trader_G",
    "market_id": "BTC-CALL-35000-20241227",
    "product_type": "option",
    "option_type": "call",
    "strike": 35000,
    "expiry": "2024-12-27T23:59:59Z",
    "side": "exercise",
    "price": 35000,
    "size": 2,
    "fee": 50.0,
    "underlying_price": 38000,
})

# --- OPTION EXPIRATION (worthless) ---
emit({
    "event_type": "expire",
    "timestamp": datetime(2024, 12, 27, 23, 59, 59, tzinfo=timezone.utc),
    "trader_id": "trader_H",
    "market_id": "SOL-PUT-80-20241227",
    "product_type": "option",
    "option_type": "put",
    "strike": 80,
    "expiry": "2024-12-27T23:59:59Z",
    "side": "expire",
    "price": 0.0,
    "size": 3,
    "fee": 0.0,
    "underlying_price": 95,
})

# --- PARTIAL CLOSE of options position ---
emit({
    "event_type": "open",
    "timestamp": now + timedelta(hours=3),
    "trader_id": "trader_I",
    "market_id": "SOL-CALL-110-20241227",
    "product_type": "option",
    "option_type": "call",
    "strike": 110,
    "expiry": "2024-12-27T23:59:59Z",
    "side": "buy",
    "price": 8.0,
    "size": 20,
    "fee": 8.0,
})

emit({
    "event_type": "close",
    "timestamp": now + timedelta(hours=27),
    "trader_id": "trader_I",
    "market_id": "SOL-CALL-110-20241227",
    "product_type": "option",
    "option_type": "call",
    "strike": 110,
    "expiry": "2024-12-27T23:59:59Z",
    "side": "sell",
    "price": 12.0,
    "size": 10,
    "fee": 6.0,
})

# --------------------------------------------------
# WRITE OUTPUT AS JSONL (one event per line)
# --------------------------------------------------
with open(OUTPUT_PATH, "w", encoding="utf-8") as f:
    for event in events:
        # Write each event as a separate JSON line
        f.write(json.dumps(event) + "\n")

print(f"âœ… Generated {len(events)} mock events â†’ {OUTPUT_PATH} (seed={SEED})")
print(f"   Includes: Perpetuals, Spot, and OPTIONS trades")
print(f"   Format: JSONL (one event per line)")


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\scripts\launch_dashboard.py =====

# scripts/launch_dashboard.py

import streamlit as st
from dashboards.app import run_app
from src.common.logging import get_logger
from configs.loader import load_config

logger = get_logger(__name__)


def main():
    config = load_config("configs/dashboard.yaml")

    logger.info("Launching analytics dashboard")

    st.set_page_config(
        page_title="Deriverse Trading Analytics",
        layout="wide"
    )

    run_app(config)


if __name__ == "__main__":
    main()


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\scripts\run_analytics.py =====

import pandas as pd
from pathlib import Path
import io
import logging
from datetime import datetime, timedelta, UTC
from src.analytics.pnl_engine import compute_realized_pnl
from src.analytics.summary import compute_executive_summary

now = datetime.now(UTC)
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

NORMALIZED_EVENTS_PATH = Path("data/normalized/events.jsonl")
ANALYTICS_DIR = Path("data/analytics")
POSITIONS_PATH = ANALYTICS_DIR / "positions.csv"
REALIZED_PNL_PATH = ANALYTICS_DIR / "realized_pnl.csv"


def load_events(path: Path) -> pd.DataFrame:
    """Load events from JSONL file with flexible timestamp parsing."""
    events = []
    with open(path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if line:  # Skip empty lines
                events.append(pd.read_json(io.StringIO(line), typ="series"))
    
    if not events:
        logger.warning(f"No events found in {path}")
        return pd.DataFrame()
    
    df = pd.DataFrame(events)
    
    # FIX: Use format='ISO8601' to handle different timestamp formats
    try:
        df["timestamp"] = pd.to_datetime(df["timestamp"], format='ISO8601', utc=True)
    except Exception as e:
        logger.warning(f"ISO8601 parsing failed, trying mixed format: {e}")
        df["timestamp"] = pd.to_datetime(df["timestamp"], format='mixed', utc=True)
    
    return df


def run_analytics(events_df, auto_summary=True, submission_mode=True):
    if events_df.empty:
        logger.error("No events to analyze")
        return None, None
    
    logger.info(f"Loaded {len(events_df)} events")

    if not submission_mode:
        logger.info(
            f"Event counts: {events_df['event_type'].value_counts().to_dict()}"
        )

    logger.info("Computing realized PnL (truth engine)")
    positions_df, pnl_df = compute_realized_pnl(events_df)

    if positions_df.empty:
        logger.warning("No closed positions found â€” analytics skipped")
        return None, None

    ANALYTICS_DIR.mkdir(parents=True, exist_ok=True)
    positions_df.to_csv(POSITIONS_PATH, index=False)
    pnl_df.to_csv(REALIZED_PNL_PATH, index=False)

    summary = compute_executive_summary(positions_df, pnl_df)

    if auto_summary:
        print("\n" + "=" * 50)
        print("EXECUTIVE SUMMARY")
        print("=" * 50)
        print(f"Total Realized PnL:  ${summary['total_pnl']:,.2f}")
        print(f"Total Fees Paid:     ${summary['total_fees']:,.2f}")
        print(f"Total Trades:        {summary['trade_count']}")
        print(f"Win Rate:            {summary['win_rate']:.1%}")
        print(f"Avg Win:             ${summary['avg_win']:,.2f}")
        print(f"Avg Loss:            ${summary['avg_loss']:,.2f}")
        print(f"Best Trade:          ${summary['best_trade']:,.2f}")
        print(f"Worst Trade:         ${summary['worst_trade']:,.2f}")
        print(f"Avg Duration:        {summary['avg_duration']}")
        print(f"Long Ratio:          {summary['long_ratio']:.1%}")
        print(f"Short Ratio:         {summary['short_ratio']:.1%}")
        print(f"Max Drawdown:        ${summary['max_drawdown']:,.2f}")
        print("=" * 50 + "\n")

    logger.info("Analytics run complete âœ…")
    return positions_df, pnl_df


def main():
    logger.info("=" * 60)
    logger.info("Starting Deriverse Analytics Pipeline")
    logger.info("=" * 60)

    if not NORMALIZED_EVENTS_PATH.exists():
        logger.error(f"Normalized events not found at {NORMALIZED_EVENTS_PATH}")
        logger.error("Run 'python -m scripts.generate_mock_data' first")
        return

    events_df = load_events(NORMALIZED_EVENTS_PATH)
    run_analytics(events_df)

    logger.info("=" * 60)


if __name__ == "__main__":
    main()


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\scripts\run_ingestion.py =====


# scripts/run_ingestion.py
import logging
from src.ingestion.pipelines import IngestionPipeline
from configs.loader import load_config

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def main():
    logger.info("Starting incremental ingestion")

    config = load_config("configs/ingestion.yaml")
    
    pipeline = IngestionPipeline(
        raw_path=config["raw_data_path"],
        output_path=config["normalized_output_path"],
        checkpoint_path=config["checkpoint_path"],
    )

    count = pipeline.run()
    logger.info(f"Ingested {count} new events")


if __name__ == "__main__":
    main()


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\metrics\drawdown.py =====

import pandas as pd

def build_drawdowns(equity_df: pd.DataFrame) -> pd.DataFrame:
    out = []

    for trader, df in equity_df.groupby("trader_id"):
        df = df.sort_values("timestamp")
        peak = df["cumulative_pnl"].cummax()
        drawdown = df["cumulative_pnl"] - peak

        out.append({
            "trader_id": trader,
            "max_drawdown": drawdown.min()
        })

    return pd.DataFrame(out)


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\metrics\exposure.py =====

import json
from collections import defaultdict

def build_exposure(events_path: str):
    exposure = defaultdict(lambda: {"long": 0.0, "short": 0.0})

    with open(events_path) as f:
        for line in f:
            e = json.loads(line)
            if e["event_type"] != "trade":
                continue

            side = "long" if e["side"] in ("buy", "long") else "short"
            exposure[e["market"]][side] += abs(e["size"])

    return dict(exposure)


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\metrics\fees.py =====

def build_fees(trades_df):
    return (
        trades_df
        .groupby("trader_id")["fee"]
        .sum()
        .reset_index(name="total_fees")
    )


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\metrics\win_rate.py =====

from typing import List, Dict
from collections import defaultdict

def build_win_rate(realised_df):
    return (
        realised_df
        .assign(win=lambda x: x["realised_pnl"] > 0)
        .groupby("trader_id")["win"]
        .mean()
        .reset_index(name="win_rate")
    )


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\metrics\__init__.py =====



===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\pnl\equity_curve.py =====

def build_equity_curve(realised_df, funding_df):
    df = realised_df.copy()
    df["funding_payment"] = 0.0

    if not funding_df.empty:
        funding_agg = (
            funding_df
            .groupby(["timestamp", "trader_id"])["funding_payment"]
            .sum()
            .reset_index()
        )
        df = df.merge(
            funding_agg,
            on=["timestamp", "trader_id"],
            how="left",
            suffixes=("", "_fund")
        )
        df["funding_payment"] = df["funding_payment_fund"].fillna(0)
        df.drop(columns=["funding_payment_fund"], inplace=True)

    df["net_realised_pnl"] = df["realised_pnl"] + df["funding_payment"]
    df["cumulative_pnl"] = df.groupby("trader_id")["net_realised_pnl"].cumsum()
    return df


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\pnl\funding.py =====

import pandas as pd
import numpy as np
import json

def build_funding(events_path: str) -> pd.DataFrame:
    rows = []

    with open(events_path) as f:
        for line in f:
            e = json.loads(line)
            if e["event_type"] != "funding":
                continue

            rows.append({
                "timestamp": e["ts"],
                "trader_id": e["trader_id"],
                "market": e["market"],
                "funding_payment": e["funding_payment"],
            })

    return pd.DataFrame(rows)


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\pnl\pnl_calculator.py =====

def calculate_trade_pnl(row):
    if row["product_type"] == "option":
        return row["exercise_pnl"] - row["premium"] - row["fees"]

    direction = 1 if row["side"].lower() == "long" else -1
    gross_pnl = (row["exit_price"] - row["entry_price"]) * row["size"] * direction
    return gross_pnl - row["fees"]


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\pnl\pnl_timeseries.py =====

import pandas as pd
from .pnl_calculator import calculate_trade_pnl


def build_pnl_timeseries(trades_df: pd.DataFrame) -> pd.DataFrame:
    """
    Build daily and cumulative PnL series.
    """
    trades_df["pnl"] = trades_df.apply(calculate_trade_pnl, axis=1)

    daily_pnl = (
        trades_df
        .groupby("trade_date", as_index=False)["pnl"]
        .sum()
        .sort_values("trade_date")
    )

    daily_pnl["cumulative_pnl"] = daily_pnl["pnl"].cumsum()
    return daily_pnl


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\pnl\realised_pnl.py =====

import json
import pandas as pd

def build_realised_pnl(events_path: str) -> pd.DataFrame:
    rows = []

    with open(events_path) as f:
        for line in f:
            e = json.loads(line)
            if e["event_type"] != "settle_pnl":
                continue

            rows.append({
                "timestamp": e["ts"],
                "trader_id": e["trader_id"],
                "market": e["market"],
                "realised_pnl": e["realised_pnl"],
            })

    df = pd.DataFrame(rows)
    df["timestamp"] = pd.to_datetime(df["timestamp"])
    return df.sort_values("timestamp")


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\pnl\__init__.py =====



===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\reports\pnl_overview.py =====

import os
import json
import pandas as pd
import matplotlib.pyplot as plt

from src.analytics.pnl.pnl_timeseries import build_pnl_timeseries
from src.analytics.metrics.drawdown import compute_drawdown


DATA_PATH = "data/processed/trades.csv"
REPORT_DIR = "data/reports"


def main():
    os.makedirs(REPORT_DIR, exist_ok=True)

    # Load trades
    trades_df = pd.read_csv(DATA_PATH, parse_dates=["trade_date"])

    # Build PnL series
    pnl_df = build_pnl_timeseries(trades_df)
    pnl_df["drawdown"] = compute_drawdown(pnl_df["cumulative_pnl"])

    # Save outputs
    pnl_df.to_csv(f"{REPORT_DIR}/pnl_timeseries.csv", index=False)
    pnl_df.to_json(f"{REPORT_DIR}/pnl_timeseries.json", orient="records")

    summary = {
        "total_pnl": round(pnl_df["pnl"].sum(), 2),
        "max_drawdown": round(pnl_df["drawdown"].min(), 2),
        "trading_days": int(pnl_df.shape[0])
    }

    with open(f"{REPORT_DIR}/pnl_summary.json", "w") as f:
        json.dump(summary, f, indent=2)

    # Plot (saved, no blocking)
    plt.figure(figsize=(10, 5))
    plt.plot(pnl_df["trade_date"], pnl_df["cumulative_pnl"], label="Cumulative PnL")
    plt.fill_between(
        pnl_df["trade_date"],
        pnl_df["drawdown"],
        0,
        alpha=0.3,
        label="Drawdown"
    )
    plt.title("Protocol PnL Performance")
    plt.xlabel("Date")
    plt.ylabel("PnL")
    plt.legend()
    plt.tight_layout()
    plt.savefig(f"{REPORT_DIR}/pnl_curve.png")
    plt.close()

    print("âœ… PnL analytics generated successfully")
    print(summary)


if __name__ == "__main__":
    main()


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\trades\activity.py =====


import pandas as pd
import json

def build_trade_activity(events_path: str):
    rows = []

    with open(events_path) as f:
        for line in f:
            e = json.loads(line)
            if e["event_type"] != "trade":
                continue

            rows.append({
                "timestamp": e["ts"],
                "trader_id": e["trader_id"],
                "market": e["market"],
                "side": e["side"],
                "price": e["price"],
                "size": e["size"],
                "fee": e["fee"],
            })

    return pd.DataFrame(rows)


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\trades\__init__.py =====



===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\contract.py =====

PRODUCT_TYPES = {"spot", "perp", "option"}

REQUIRED_FIELDS = {
    "event_id": str,
    "product_type": str,    # spot | perp | option
    "event_type": str,      # trade, open, close, exercise, expiry
    "timestamp": int,

    "market": str,
    "trader_id": str,

    "side": str,            # buy/sell OR long/short
    "price": float,
    "size": float,
}

OPTIONAL_FIELDS = {
    # common
    "fee": float,

    # perp-specific
    "pnl": float,
    "funding_rate": float,

    # option-specific
    "option_type": str,     # call / put
    "strike": float,
    "expiry": int,
    "premium": float,
    "exercise_pnl": float,
}


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\debug.py =====

import json
from pathlib import Path
from collections import Counter

def inspect_normalized_data():
    normalized_path = Path("data/normalized/events.jsonl")

    if not normalized_path.exists():
        print("âŒ No normalized data file found.")
        return

    if normalized_path.stat().st_size == 0:
        print("âš ï¸ Normalized file exists but is empty.")
        return

    all_fields = set()
    event_types = Counter()
    sample_events = []

    with normalized_path.open() as f:
        for i, line in enumerate(f):
            event = json.loads(line)
            all_fields.update(event.keys())
            event_types[event.get("event_type")] += 1

            if i < 3:
                sample_events.append(event)

    print("\nðŸ“Š Normalized Data Overview")
    print(f"Total events: {sum(event_types.values())}")

    print("\nEvent types:")
    for et, c in event_types.items():
        print(f"  - {et}: {c}")

    print("\nColumns present:")
    for field in sorted(all_fields):
        print(f"  - {field}")

    print("\nSample events:")
    for i, ev in enumerate(sample_events, 1):
        print(f"\nEvent {i}")
        for k, v in ev.items():
            print(f"  {k}: {v}")


if __name__ == "__main__":
    inspect_normalized_data()


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\pnl_engine.py =====

# src/analytics/pnl_engine.py
import pandas as pd
import hashlib
import logging

logger = logging.getLogger(__name__)


def compute_realized_pnl(events: pd.DataFrame):
    """
    Canonical PnL engine.
    Produces position-level truth and realized PnL aggregates.
    Supports partial position closes.
    """

    required_cols = {
        "event_type", "timestamp", "trader_id",
        "market_id", "product_type", "side",
        "price", "size", "fee"
    }

    missing = required_cols - set(events.columns)
    if missing:
        raise ValueError(f"Missing required columns: {missing}")

    events = events.sort_values("timestamp")

    open_positions = {}
    closed_positions = []

    # âœ… Aggregated validation stats (submission-safe)
    stats = {
        "duplicate_opens": 0,
        "close_without_open": 0,
        "oversized_closes": 0,
    }

    for _, event in events.iterrows():
        key = (
            event["trader_id"],
            event["market_id"],
            event["product_type"],
            event["side"]
        )

        if event["event_type"] == "open":
            if key in open_positions:
                stats["duplicate_opens"] += 1
                continue

            position_data = (
                f"{event['trader_id']}|{event['market_id']}|"
                f"{event['timestamp']}|{event['side']}"
            )
            position_id = hashlib.sha256(position_data.encode()).hexdigest()[:16]

            open_positions[key] = {
                "position_id": position_id,
                "open_time": event["timestamp"],
                "entry_price": event["price"],
                "size": event["size"],
                "fees": event["fee"],
                "trader_id": event["trader_id"],
                "market_id": event["market_id"],
                "product_type": event["product_type"],
                "side": event["side"],
            }

        elif event["event_type"] in {"close", "liquidation"}:
            if key not in open_positions:
                stats["close_without_open"] += 1
                continue

            pos = open_positions[key]
            close_size = event["size"]

            if close_size > pos["size"]:
                stats["oversized_closes"] += 1
                continue

            exit_price = event["price"]

            fee_ratio = close_size / pos["size"]
            allocated_open_fee = pos["fees"] * fee_ratio
            total_fees = allocated_open_fee + event["fee"]

            if pd.notna(event.get("pnl")):
                net_pnl = event["pnl"]
                gross_pnl = net_pnl + total_fees
            else:
                if pos["side"] in {"long", "buy"}:
                    gross_pnl = (exit_price - pos["entry_price"]) * close_size
                else:
                    gross_pnl = (pos["entry_price"] - exit_price) * close_size

                net_pnl = gross_pnl - total_fees

            closed_positions.append({
                "position_id": pos["position_id"],
                "open_time": pos["open_time"],
                "close_time": event["timestamp"],
                "trader_id": pos["trader_id"],
                "market_id": pos["market_id"],
                "product_type": pos["product_type"],
                "side": pos["side"],
                "entry_price": pos["entry_price"],
                "exit_price": exit_price,
                "size": close_size,
                "gross_pnl": round(gross_pnl, 4),
                "net_pnl": round(net_pnl, 4),
                "realized_pnl": round(net_pnl, 4),
                "fees": round(total_fees, 4),
                "close_reason": event["event_type"],
            })

            pos["size"] -= close_size
            pos["fees"] -= allocated_open_fee

            if pos["size"] <= 0:
                open_positions.pop(key)

    positions_df = pd.DataFrame(closed_positions)

    # âœ… Single validation summary line (reviewer gold)
    logger.info(
        "PnL validation summary | "
        f"duplicate_opens={stats['duplicate_opens']} | "
        f"close_without_open={stats['close_without_open']} | "
        f"oversized_closes={stats['oversized_closes']}"
    )

    if positions_df.empty:
        return positions_df, pd.DataFrame()

    pnl_df = (
        positions_df
        .assign(date=lambda df: pd.to_datetime(df["close_time"]).dt.date)
        .groupby(
            ["date", "trader_id", "market_id", "product_type"],
            as_index=False
        )
        .agg(
            net_pnl=("net_pnl", "sum"),
            realized_pnl=("realized_pnl", "sum"),
            fees=("fees", "sum"),
            trade_count=("position_id", "count")
        )
    )

    logger.info(
        f"PnL engine results: {len(positions_df)} closed positions, "
        f"{len(open_positions)} still open"
    )

    return positions_df, pnl_df


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\summary.py =====

# src/analytics/summary.py
import pandas as pd

def compute_executive_summary(positions: pd.DataFrame, pnl: pd.DataFrame) -> dict:
    """
    Compute high-level KPIs from canonical PnL outputs.
    
    Args:
        positions: Output from compute_realized_pnl (positions_df)
        pnl: Output from compute_realized_pnl (pnl_df)
    
    Returns:
        Dictionary of KPI metrics
    """
    if positions.empty:
        return {"status": "no_data"}
    
    summary = {}
    
    # Core PnL
    summary["total_pnl"] = pnl["net_pnl"].sum()
    summary["total_fees"] = pnl["fees"].sum()
    summary["trade_count"] = len(positions)
    summary["win_rate"] = (positions["net_pnl"] > 0).mean()
    
    # Win/Loss Analysis
    winning_trades = positions[positions["net_pnl"] > 0]
    losing_trades = positions[positions["net_pnl"] < 0]
    
    summary["avg_win"] = winning_trades["net_pnl"].mean() if len(winning_trades) > 0 else 0
    summary["avg_loss"] = losing_trades["net_pnl"].mean() if len(losing_trades) > 0 else 0
    summary["best_trade"] = positions["net_pnl"].max()
    summary["worst_trade"] = positions["net_pnl"].min()
    
    # Duration Analysis
    positions = positions.copy()
    positions["duration"] = (
        pd.to_datetime(positions["close_time"]) - 
        pd.to_datetime(positions["open_time"])
    )
    summary["avg_duration"] = positions["duration"].mean()
    
    # Directional Bias
    summary["long_ratio"] = (positions["side"].isin(["long", "buy"])).mean()
    summary["short_ratio"] = (positions["side"].isin(["short", "sell"])).mean()
    
    # Drawdown
    pnl_sorted = pnl.sort_values("date")
    pnl_sorted["cum_pnl"] = pnl_sorted["net_pnl"].cumsum()
    pnl_sorted["drawdown"] = pnl_sorted["cum_pnl"] - pnl_sorted["cum_pnl"].cummax()
    summary["max_drawdown"] = pnl_sorted["drawdown"].min()
    
    return summary


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\validate.py =====

# src/analytics/validate.py
from typing import Dict, Any, Set
from datetime import datetime

class EventValidationError(Exception):
    """Raised when event fails validation."""
    pass

# --- Base required fields for ALL events ---
BASE_REQUIRED_FIELDS = {
    "event_id",
    "event_type",
    "timestamp",
    "trader_id",
    "market_id",
    "product_type"
}

# --- Base optional fields for ALL events ---
BASE_OPTIONAL_FIELDS = {
    "side",
    "price",
    "size",
    "fee",
    "pnl"
}

# --- Option-specific fields ---
OPTION_REQUIRED_FIELDS = {
    "option_type",
    "strike",
    "expiry"
}

OPTION_OPTIONAL_FIELDS = {
    "delta",
    "gamma",
    "theta",
    "vega",
    "implied_vol",
    "underlying_price"
}

# --- Event type schemas (open, trade, close, exercise, expire) ---
EVENT_TYPE_SCHEMAS = {
    "trade": {
        "required": {"side", "price", "size", "fee"},
        "optional": {"pnl"}
    },
    "open": {
        "required": {"side", "price", "size", "fee"},
        "optional": {"pnl"}
    },
    "close": {
        "required": {"side", "price", "size", "fee"},
        "optional": {"pnl"}
    },
    "exercise": {
        "required": {"side", "price", "size", "fee"},
        "optional": {"pnl", "underlying_price"}
    },
    "expire": {
        "required": {"side", "price", "size", "fee"},
        "optional": {"pnl", "underlying_price"}
    }
}

def validate_event(event: dict) -> None:
    event_type = event.get("event_type")
    product_type = event.get("product_type")

    # --------------------------------------------------
    # 1ï¸âƒ£ Trade events are informational only
    # --------------------------------------------------
    if event_type == "trade":
        return  # Skip position validation entirely

    # --------------------------------------------------
    # 2ï¸âƒ£ Position-affecting events
    # --------------------------------------------------
    if product_type == "perp":
        allowed_sides = {"long", "short"}
    elif product_type in {"spot", "option"}:
        allowed_sides = {"buy", "sell"}
    else:
        raise EventValidationError(f"Unknown product_type: {product_type}")

    side = event.get("side")
    if side not in allowed_sides:
        raise EventValidationError(
            f"Invalid side '{side}' for product_type '{product_type}'. "
            f"Must be one of: {allowed_sides}"
        )

    # 3ï¸âƒ£ Get product type and determine allowed fields
    product_type = event.get("product_type")
    valid_products = {"spot", "perp", "option"}
    if product_type not in valid_products:
        raise EventValidationError(
            f"Invalid product_type: {product_type}. Allowed: {valid_products}"
        )

    # 4ï¸âƒ£ Build allowed fields based on product type
    allowed_fields = BASE_REQUIRED_FIELDS | BASE_OPTIONAL_FIELDS
    
    if product_type == "option":
        allowed_fields |= OPTION_REQUIRED_FIELDS | OPTION_OPTIONAL_FIELDS
    
    # Add event-specific fields
    schema = EVENT_TYPE_SCHEMAS[event_type]
    allowed_fields |= schema["required"] | schema["optional"]

    # 5ï¸âƒ£ Check for extra fields (schema drift)
    extra_fields = set(event.keys()) - allowed_fields
    if extra_fields:
        raise EventValidationError(
            f"Unexpected fields detected: {extra_fields}. "
            f"Allowed for {product_type}/{event_type}: {allowed_fields}"
        )

    # 6ï¸âƒ£ Check event-type-specific required fields
    missing_event_required = schema["required"] - set(event.keys())
    if missing_event_required:
        raise EventValidationError(
            f"Event type '{event_type}' missing required fields: {missing_event_required}"
        )

    # 7ï¸âƒ£ Check option-specific required fields (if product is option)
    if product_type == "option":
        missing_option_required = OPTION_REQUIRED_FIELDS - set(event.keys())
        if missing_option_required:
            raise EventValidationError(
                f"Option product missing required fields: {missing_option_required}"
            )

    # 8ï¸âƒ£ Validate timestamp
    try:
        timestamp_str = event["timestamp"]
        # Handle different timestamp formats
        if timestamp_str.endswith("Z"):
            timestamp_str = timestamp_str.replace("Z", "+00:00")
        datetime.fromisoformat(timestamp_str)
    except (ValueError, AttributeError, TypeError) as e:
        raise EventValidationError(f"Invalid timestamp format: {event.get('timestamp')} - {e}")

    # 9ï¸âƒ£ Validate numeric fields
    numeric_fields = {"price", "size", "fee", "pnl", "strike", "delta", "gamma", 
                     "theta", "vega", "implied_vol", "underlying_price"}
    for field in numeric_fields & event.keys():
        value = event[field]
        if value is not None and not isinstance(value, (int, float)):
            raise EventValidationError(
                f"Field '{field}' must be numeric or null, got {type(value)}: {value}"
            )

    # ðŸ”Ÿ Validate side values (context-aware)
    if "side" in event:
        side = event["side"]
        if product_type in {"spot", "option"}:
            valid_sides = {"buy", "sell", "exercise", "expire", "assign"}
        else:  # perp
            valid_sides = {"long", "short"}
        
        if side not in valid_sides:
            raise EventValidationError(
                f"Invalid side '{side}' for product_type '{product_type}'. "
                f"Must be one of: {valid_sides}"
            )

    # 1ï¸âƒ£1ï¸âƒ£ Validate option-specific values
    if product_type == "option":
        # Validate option_type
        option_type = event.get("option_type")
        if option_type not in {"call", "put"}:
            raise EventValidationError(f"Invalid option_type: {option_type}. Must be 'call' or 'put'")
        
        # Validate expiry format
        expiry = event.get("expiry")
        if expiry:
            try:
                if expiry.endswith("Z"):
                    expiry = expiry.replace("Z", "+00:00")
                datetime.fromisoformat(expiry)
            except (ValueError, AttributeError):
                raise EventValidationError(f"Invalid expiry format: {expiry}")


def get_allowed_fields(product_type: str, event_type: str) -> Set[str]:
    """Get allowed fields for a specific product and event type."""
    allowed = BASE_REQUIRED_FIELDS | BASE_OPTIONAL_FIELDS
    
    if product_type == "option":
        allowed |= OPTION_REQUIRED_FIELDS | OPTION_OPTIONAL_FIELDS
    
    if event_type in EVENT_TYPE_SCHEMAS:
        allowed |= EVENT_TYPE_SCHEMAS[event_type]["required"]
        allowed |= EVENT_TYPE_SCHEMAS[event_type]["optional"]
    
    return allowed


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\analytics\__init__.py =====



===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\common\logging.py =====

import logging

def get_logger(name):
    logger = logging.getLogger(name)
    if not logger.handlers:
        handler = logging.StreamHandler()
        formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        logger.setLevel(logging.INFO)
    return logger


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\common\__init__.py =====



===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\ingestion\normalizer.py =====

# src/ingestion/normalizer.py
from typing import Dict, Any
from datetime import datetime, timezone
import hashlib

def normalize_event(raw_event: Dict[str, Any]) -> Dict[str, Any]:
    """
    Normalize raw event data into canonical schema.
    - Convert keys to expected schema names
    - Convert timestamps to ISO 8601
    - Ensure event_id exists
    - Handle option-specific fields
    """
    event = raw_event.copy()

    # --- Normalize timestamp ---
    ts = event.get("timestamp")
    if isinstance(ts, (int, float)):
        # Convert Unix timestamp (seconds) to ISO 8601 UTC
        event["timestamp"] = datetime.fromtimestamp(ts, tz=timezone.utc).isoformat()
    elif isinstance(ts, datetime):
        # Convert datetime object to ISO string
        event["timestamp"] = ts.isoformat()
    elif isinstance(ts, str):
        # Ensure proper ISO format with timezone
        try:
            # Handle different formats
            ts_clean = ts.replace("Z", "+00:00")
            dt = datetime.fromisoformat(ts_clean)
            # Standardize to UTC with Z suffix
            if dt.tzinfo is None:
                dt = dt.replace(tzinfo=timezone.utc)
            event["timestamp"] = dt.isoformat().replace("+00:00", "Z")
        except ValueError:
            # Leave as-is; validation will catch errors
            pass

    # --- Normalize keys for backward compatibility ---
    key_mappings = {
        "trader": "trader_id",
        "market": "market_id", 
        "type": "event_type",
        "product": "product_type",
        "optionType": "option_type",  # Handle camelCase
        "impliedVol": "implied_vol"
    }
    
    for old_key, new_key in key_mappings.items():
        if old_key in event and new_key not in event:
            event[new_key] = event.pop(old_key)

    # --- Normalize product_type ---
    if "product_type" in event:
        product = event["product_type"].lower()
        if product in ["perpetual", "future", "futures", "perp"]:
            event["product_type"] = "perp"
        elif product in ["options", "option"]:
            event["product_type"] = "option"
        elif product in ["spot", "cash"]:
            event["product_type"] = "spot"

    # --- Normalize option-specific fields ---
    if event.get("product_type") == "option":
        # Normalize option_type
        if "option_type" in event:
            event["option_type"] = event["option_type"].lower()
        
        # Normalize expiry timestamp
        if "expiry" in event and event["expiry"]:
            expiry = event["expiry"]
            if isinstance(expiry, str):
                try:
                    expiry_clean = expiry.replace("Z", "+00:00")
                    dt = datetime.fromisoformat(expiry_clean)
                    # Standardize format
                    if dt.tzinfo is None:
                        dt = dt.replace(tzinfo=timezone.utc)
                    event["expiry"] = dt.isoformat().replace("+00:00", "Z")
                except ValueError:
                    # Leave as-is
                    pass

    # --- Ensure event_id exists ---
    if "event_id" not in event:
        # Create deterministic event ID
        raw_parts = [
            str(event.get('event_type', '')),
            str(event.get('timestamp', '')),
            str(event.get('trader_id', '')),
            str(event.get('market_id', '')),
            str(event.get('product_type', ''))
        ]
        raw = "|".join(raw_parts)
        event["event_id"] = hashlib.sha256(raw.encode()).hexdigest()

    # --- Normalize numeric fields ---
    numeric_fields = ["price", "size", "fee", "pnl", "strike", "delta", 
                     "gamma", "theta", "vega", "implied_vol", "underlying_price"]
    
    for field in numeric_fields:
        if field in event and event[field] is not None:
            try:
                event[field] = float(event[field])
            except (ValueError, TypeError):
                # Keep as-is if conversion fails
                pass

    return event


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\ingestion\pipelines.py =====

# src/ingestion/pipelines.py
import json
import hashlib
from pathlib import Path
from src.ingestion.watermark import WatermarkStore
from src.ingestion.normalizer import normalize_event
from src.analytics.validate import validate_event, EventValidationError


class IngestionPipeline:
    def __init__(self, raw_path: str, output_path: str, checkpoint_path: str):
        self.raw_path = Path(raw_path)
        self.output_path = Path(output_path)
        self.watermark = WatermarkStore(checkpoint_path)

    def run(self) -> int:
        """
        Event-driven ingestion: normalize once, append forever.
        Supports both JSON array and JSONL formats.
        """
        if not self.raw_path.exists():
            raise FileNotFoundError(f"Raw data source not found: {self.raw_path}")

        # Load events based on file format
        if self.raw_path.suffix == '.json':
            # JSON array format (e.g., configs/mock_data.json)
            with self.raw_path.open("r", encoding="utf-8") as f:
                raw_events = json.load(f)
        elif self.raw_path.suffix == '.jsonl':
            # JSONL format (one JSON object per line)
            raw_events = []
            with self.raw_path.open("r", encoding="utf-8") as f:
                for line in f:
                    line = line.strip()
                    if line:  # Skip empty lines
                        raw_events.append(json.loads(line))
        else:
            raise ValueError(f"Unsupported file format: {self.raw_path.suffix}")

        new_events = []
        errors = []

        for idx, raw in enumerate(raw_events, 1):
            try:
                # Generate event_id if missing
                if "event_id" not in raw:
                    seed = (
                        f"{raw.get('event_type')}|"
                        f"{raw.get('timestamp')}|"
                        f"{raw.get('trader_id')}|"
                        f"{raw.get('market_id')}|{idx}"
                    )
                    raw["event_id"] = hashlib.sha256(seed.encode()).hexdigest()

                # Skip if already processed
                if not self.watermark.is_new(raw["event_id"]):
                    continue

                # Normalize and validate
                normalized = normalize_event(raw)
                validate_event(normalized)

                new_events.append(normalized)
                self.watermark.mark(raw["event_id"])

            except EventValidationError as e:
                errors.append(f"Event {idx}: Validation failed - {e}")
            except Exception as e:
                errors.append(f"Event {idx}: Unexpected error - {e}")

        # Report errors
        if errors:
            print(f"âš ï¸  {len(errors)} events had issues:")
            for e in errors[:5]:
                print(f"   - {e}")
            if len(errors) > 5:
                print(f"   ... and {len(errors) - 5} more")

        # Write normalized events to output (JSONL format)
        self.output_path.parent.mkdir(parents=True, exist_ok=True)
        with self.output_path.open("a", encoding="utf-8") as f:
            for e in new_events:
                f.write(json.dumps(e) + "\n")

        print(f"âœ… Ingested {len(new_events)} valid events")
        return len(new_events)


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\ingestion\watermark.py =====

# src/ingestion/watermark.py
import json
from pathlib import Path
from typing import Set

class WatermarkStore:
    """
    Persistent watermark store to prevent reprocessing events.
    """

    def __init__(self, path: str):
        self.path = Path(path)
        self.seen: Set[str] = set()
        self._load()

    def _load(self):
        if self.path.exists():
            with open(self.path, "r") as f:
                self.seen = set(json.load(f))

    def _save(self):
        self.path.parent.mkdir(parents=True, exist_ok=True)
        with open(self.path, "w") as f:
            json.dump(list(self.seen), f)

    def is_new(self, event_id: str) -> bool:
        return event_id not in self.seen

    def mark(self, event_id: str):
        self.seen.add(event_id)
        self._save()


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\ingestion\__init__.py =====



===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\mock\market_simulator.py =====

import random

class MarketSimulator:
    def __init__(self, name: str, tick_size: float):
        self.name = name
        self.tick_size = tick_size
        self.price = 100.0  # starting price

    def step(self):
        """Simulate a single market tick"""
        move = random.choice([-1, 1]) * self.tick_size
        self.price += move
        return round(self.price, 2)


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\mock\trader_simulator.py =====

class TraderSimulator:
    def __init__(self, config):
        self.config = config

    def simulate_trade(self, market_data):
        # Example: random trade based on market price
        import random
        trade = {
            "price": market_data["price"],
            "side": random.choice(["buy", "sell"]),
            "quantity": round(random.uniform(1, 10), 2),
            "timestamp": market_data["timestamp"]
        }
        return trade


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\mock\__init__.py =====



===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\storage\writer.py =====

class EventWriter:
    def __init__(self, config):
        self.config = config

    def write(self, events):
        # Example: write to a local JSON file
        import json
        with open("mock_events.json", "w") as f:
            json.dump(events, f, indent=2)


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\storage\__init__.py =====



===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\src\__init__.py =====



===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\tests\analytics\test_ingestion.py =====

# Create a test script test_ingestion.py
import json

with open("data/normalized/events.jsonl", "r") as f:
    for i, line in enumerate(f, 1):
        line = line.strip()
        if line:
            try:
                data = json.loads(line)
                print(f"Line {i}: OK - {data.get('event_type', 'N/A')}")
            except json.JSONDecodeError as e:
                print(f"Line {i}: ERROR - {e}")
                print(f"  Content: {line[:50]}...")
        else:
            print(f"Line {i}: EMPTY LINE")


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\tests\analytics\test_pnl_engine.py =====

import pandas as pd
from datetime import datetime, timezone

from src.analytics.pnl_engine import compute_realized_pnl

def test_simple_open_close_pnl():
    events = pd.DataFrame([
        {
            "event_id": "e1",
            "event_type": "open",
            "timestamp": datetime(2026, 1, 1, tzinfo=timezone.utc),
            "trader_id": "T1",
            "market_id": "BTC-PERP",
            "product_type": "perp",
            "side": "long",
            "price": 100.0,
            "size": 1,
            "fee": 0.5,
        },
        {
            "event_id": "e2",
            "event_type": "close",
            "timestamp": datetime(2026, 1, 2, tzinfo=timezone.utc),
            "trader_id": "T1",
            "market_id": "BTC-PERP",
            "product_type": "perp",
            "side": "long",
            "price": 110.0,
            "size": 1,
            "fee": 0.5,
            "pnl": 9.0,  # truth reference
        },
    ])

    positions, pnl = compute_realized_pnl(events)

    assert len(positions) == 1
    assert positions.iloc[0]["realized_pnl"] == 9.0

def test_open_without_close_has_no_pnl():
    events = pd.DataFrame([
        {
            "event_id": "e1",
            "event_type": "open",
            "timestamp": datetime.now(timezone.utc),
            "trader_id": "T1",
            "market_id": "SOL-PERP",
            "product_type": "perp",
            "side": "long",
            "price": 50,
            "size": 2,
            "fee": 0.2,
        }
    ])

    positions, pnl = compute_realized_pnl(events)

    assert positions.empty
    assert pnl.empty

def test_pnl_only_on_close_events():
    events = pd.DataFrame([
        {
            "event_id": "e1",
            "event_type": "trade",
            "timestamp": datetime.now(timezone.utc),
            "trader_id": "T1",
            "market_id": "SOL/USDC",
            "product_type": "spot",
            "side": "buy",
            "price": 100,
            "size": 1,
            "fee": 0.1,
        }
    ])

    positions, pnl = compute_realized_pnl(events)

    assert positions.empty
    assert pnl.empty
def test_pnl_engine_is_deterministic():
    events = pd.DataFrame([
        {
            "event_id": "e1",
            "event_type": "open",
            "timestamp": datetime(2026, 1, 1, tzinfo=timezone.utc),
            "trader_id": "T2",
            "market_id": "ETH-PERP",
            "product_type": "perp",
            "side": "short",
            "price": 200,
            "size": 1,
            "fee": 0.3,
        },
        {
            "event_id": "e2",
            "event_type": "close",
            "timestamp": datetime(2026, 1, 2, tzinfo=timezone.utc),
            "trader_id": "T2",
            "market_id": "ETH-PERP",
            "product_type": "perp",
            "side": "short",
            "price": 180,
            "size": 1,
            "fee": 0.3,
            "pnl": 19.4,
        },
    ])

    p1, pnl1 = compute_realized_pnl(events)
    p2, pnl2 = compute_realized_pnl(events)

    pd.testing.assert_frame_equal(p1, p2)
    pd.testing.assert_frame_equal(pnl1, pnl2)

def test_close_without_open_is_rejected():
    events = pd.DataFrame([
        {
            "event_id": "e1",
            "event_type": "close",
            "timestamp": datetime.now(timezone.utc),
            "trader_id": "T3",
            "market_id": "BTC-PERP",
            "product_type": "perp",
            "side": "long",
            "price": 120,
            "size": 1,
            "fee": 0.4,
            "pnl": 0,
        }
    ])

    positions, pnl = compute_realized_pnl(events)

    assert positions.empty
    assert pnl.empty
def test_partial_close_pnl():
    events = pd.DataFrame([
        {
            "event_id": "e1",
            "event_type": "open",
            "timestamp": datetime(2026, 1, 1, tzinfo=timezone.utc),
            "trader_id": "T1",
            "market_id": "BTC-PERP",
            "product_type": "perp",
            "side": "long",
            "price": 100.0,
            "size": 10,
            "fee": 1.0,
        },
        {
            # partial close (50%)
            "event_id": "e2",
            "event_type": "close",
            "timestamp": datetime(2026, 1, 2, tzinfo=timezone.utc),
            "trader_id": "T1",
            "market_id": "BTC-PERP",
            "product_type": "perp",
            "side": "long",
            "price": 110.0,
            "size": 5,
            "fee": 0.5,
        },
        {
            # final close
            "event_id": "e3",
            "event_type": "close",
            "timestamp": datetime(2026, 1, 3, tzinfo=timezone.utc),
            "trader_id": "T1",
            "market_id": "BTC-PERP",
            "product_type": "perp",
            "side": "long",
            "price": 120.0,
            "size": 5,
            "fee": 0.5,
        },
    ])

    positions, pnl = compute_realized_pnl(events)

    assert len(positions) == 2

    realized = positions["realized_pnl"].sum()
    assert round(realized, 2) == round(
        ((110 - 100) * 5 + (120 - 100) * 5) - 2.0, 2
    )

def test_multiple_partial_closes_order_independent():
    base_events = [
        {
            "event_id": "o1",
            "event_type": "open",
            "timestamp": datetime(2026, 1, 1, tzinfo=timezone.utc),
            "trader_id": "T1",
            "market_id": "BTC-PERP",
            "product_type": "perp",
            "side": "long",
            "price": 100,
            "size": 10,
            "fee": 1.0,
        },
        {
            "event_id": "c1",
            "event_type": "close",
            "timestamp": datetime(2026, 1, 2, tzinfo=timezone.utc),
            "trader_id": "T1",
            "market_id": "BTC-PERP",
            "product_type": "perp",
            "side": "long",
            "price": 110,
            "size": 4,
            "fee": 0.4,
        },
        {
            "event_id": "c2",
            "event_type": "close",
            "timestamp": datetime(2026, 1, 3, tzinfo=timezone.utc),
            "trader_id": "T1",
            "market_id": "BTC-PERP",
            "product_type": "perp",
            "side": "long",
            "price": 120,
            "size": 6,
            "fee": 0.6,
        },
    ]

    df1 = pd.DataFrame(base_events)
    df2 = pd.DataFrame(reversed(base_events))

    p1, pnl1 = compute_realized_pnl(df1)
    p2, pnl2 = compute_realized_pnl(df2)

    pd.testing.assert_frame_equal(p1, p2)
    pd.testing.assert_frame_equal(pnl1, pnl2)
def test_liquidation_is_partial_close():
    events = pd.DataFrame([
        {
            "event_id": "o1",
            "event_type": "open",
            "timestamp": datetime(2026, 1, 1, tzinfo=timezone.utc),
            "trader_id": "T9",
            "market_id": "ETH-PERP",
            "product_type": "perp",
            "side": "long",
            "price": 200,
            "size": 10,
            "fee": 1.0,
        },
        {
            "event_id": "l1",
            "event_type": "liquidation",
            "timestamp": datetime(2026, 1, 2, tzinfo=timezone.utc),
            "trader_id": "T9",
            "market_id": "ETH-PERP",
            "product_type": "perp",
            "side": "long",
            "price": 150,
            "size": 4,
            "fee": 0.5,
        },
    ])

    positions, pnl = compute_realized_pnl(events)

    assert len(positions) == 1
    assert positions.iloc[0]["close_reason"] == "liquidation"


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\tests\analytics\__init__.py =====



===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\tests\__init__.py =====



===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\main.py =====

def main():
    print("Hello from deriverse-data-puller!")


if __name__ == "__main__":
    main()


===== FILE: C:\Users\HP\Direverse\Deriverse-Trading-System-Analysis\deriverse-data-puller\pyproject.toml =====

[project]
name = "deriverse-data-puller"
version = "0.1.0"
description = "Mock on-chain trading analytics system for Deriverse"
readme = "README.md"
requires-python = ">=3.10"

dependencies = [
    "matplotlib>=3.10.8",
    "pandas>=2.3.3",
    "pyyaml",
    "requests>=2.32.5",
    "streamlit",
]

